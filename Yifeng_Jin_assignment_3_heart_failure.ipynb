{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yifeng_Jin_assignment_3_heart_failure.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8M0GQJcvXQ7"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yifengjin89/yifengjin89-AI_assingment_3_Machine-Learning-in-Action/blob/main/Yifeng_Jin_assignment_3_heart_failure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cYJy3TK8V6n"
      },
      "source": [
        "Heart failure is a serious condition, and usually thereâ€™s no cure. Heart failure may be close to us, but we all ignore it. My friend's cousin just pass away by heart failure in a few month ago, and there was no specific symptoms of it. So I found Heart Failure Prediction dataset, which included 12 clinical features for predicting death events. I will use a nerual network to predict death events and use random forest to select top 5 important features to predict it again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sDtmOlOQcJ2"
      },
      "source": [
        "# Import Libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "WyNInXAQRLOe",
        "outputId": "bb75807a-db71-41b8-e160-3dde21987c7b"
      },
      "source": [
        "# load the data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cca3e511-cb12-45de-813d-1f8f95216597\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cca3e511-cb12-45de-813d-1f8f95216597\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving heart_failure_clinical_records_dataset.csv to heart_failure_clinical_records_dataset (2).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "e7-lDJkuRgVC",
        "outputId": "afe11b1e-3042-446a-ed00-11c10e1bfa4b"
      },
      "source": [
        "# store the data into a data frame\n",
        "dataset = pd.read_csv('heart_failure_clinical_records_dataset.csv')\n",
        "dataset.head(15)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>90.0</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>204000.00</td>\n",
              "      <td>2.1</td>\n",
              "      <td>132</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>75.0</td>\n",
              "      <td>1</td>\n",
              "      <td>246</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>127000.00</td>\n",
              "      <td>1.2</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>60.0</td>\n",
              "      <td>1</td>\n",
              "      <td>315</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>454000.00</td>\n",
              "      <td>1.1</td>\n",
              "      <td>131</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>157</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.5</td>\n",
              "      <td>138</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>123</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>388000.00</td>\n",
              "      <td>9.4</td>\n",
              "      <td>133</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>75.0</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>368000.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>131</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>231</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>253000.00</td>\n",
              "      <td>0.9</td>\n",
              "      <td>140</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>45.0</td>\n",
              "      <td>1</td>\n",
              "      <td>981</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>136000.00</td>\n",
              "      <td>1.1</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>276000.00</td>\n",
              "      <td>1.1</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>49.0</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>427000.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>138</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  anaemia  creatinine_phosphokinase  ...  smoking  time  DEATH_EVENT\n",
              "0   75.0        0                       582  ...        0     4            1\n",
              "1   55.0        0                      7861  ...        0     6            1\n",
              "2   65.0        0                       146  ...        1     7            1\n",
              "3   50.0        1                       111  ...        0     7            1\n",
              "4   65.0        1                       160  ...        0     8            1\n",
              "5   90.0        1                        47  ...        1     8            1\n",
              "6   75.0        1                       246  ...        0    10            1\n",
              "7   60.0        1                       315  ...        1    10            1\n",
              "8   65.0        0                       157  ...        0    10            1\n",
              "9   80.0        1                       123  ...        1    10            1\n",
              "10  75.0        1                        81  ...        1    10            1\n",
              "11  62.0        0                       231  ...        1    10            1\n",
              "12  45.0        1                       981  ...        0    11            1\n",
              "13  50.0        1                       168  ...        0    11            1\n",
              "14  49.0        1                        80  ...        0    12            0\n",
              "\n",
              "[15 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNrwKVIxRAgM"
      },
      "source": [
        "Data Explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo5oXUTXQQTC"
      },
      "source": [
        "![data_explain.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g51Qb7J9R9Wl",
        "outputId": "a1f87865-4dea-4ede-9c1f-cc704dfc84f8"
      },
      "source": [
        "# check the data if has Na data\n",
        "dataset.isna().sum()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                         0\n",
              "anaemia                     0\n",
              "creatinine_phosphokinase    0\n",
              "diabetes                    0\n",
              "ejection_fraction           0\n",
              "high_blood_pressure         0\n",
              "platelets                   0\n",
              "serum_creatinine            0\n",
              "serum_sodium                0\n",
              "sex                         0\n",
              "smoking                     0\n",
              "time                        0\n",
              "DEATH_EVENT                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU9PKz9JS03C"
      },
      "source": [
        "# check for duplicates and remove\n",
        "dataset.drop_duplicates(inplace= True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY-37YQ8LA5Y"
      },
      "source": [
        "Since I am gonna use a neural network to predicit death events. So I have to convert the data into correct datatype, then separate features into numerical group and catigorical group. Next, use a MinMaxScaler to scale the data for the nerual network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGEAe7jQoodR"
      },
      "source": [
        "# convert the data into correct datatype\n",
        "dataset['anaemia'] = dataset['anaemia'].astype('category')\n",
        "dataset['diabetes'] = dataset['diabetes'].astype('category')\n",
        "dataset['high_blood_pressure'] = dataset['high_blood_pressure'].astype('category')\n",
        "dataset['sex'] = dataset['sex'].astype('category')\n",
        "dataset['smoking'] = dataset['smoking'].astype('category')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmDbjZhKSDCp",
        "outputId": "74b28579-629e-4c51-b519-8654149da155"
      },
      "source": [
        "# display data info\n",
        "dataset.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 299 entries, 0 to 298\n",
            "Data columns (total 13 columns):\n",
            " #   Column                    Non-Null Count  Dtype   \n",
            "---  ------                    --------------  -----   \n",
            " 0   age                       299 non-null    float64 \n",
            " 1   anaemia                   299 non-null    category\n",
            " 2   creatinine_phosphokinase  299 non-null    int64   \n",
            " 3   diabetes                  299 non-null    category\n",
            " 4   ejection_fraction         299 non-null    int64   \n",
            " 5   high_blood_pressure       299 non-null    category\n",
            " 6   platelets                 299 non-null    float64 \n",
            " 7   serum_creatinine          299 non-null    float64 \n",
            " 8   serum_sodium              299 non-null    int64   \n",
            " 9   sex                       299 non-null    category\n",
            " 10  smoking                   299 non-null    category\n",
            " 11  time                      299 non-null    int64   \n",
            " 12  DEATH_EVENT               299 non-null    int64   \n",
            "dtypes: category(5), float64(3), int64(5)\n",
            "memory usage: 23.0 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvSZ1a4sruGo",
        "outputId": "919221e7-f652-4386-fb55-30a2a9c4cad6"
      },
      "source": [
        "#Separate features into numerical group and catigorical group\n",
        "num_data = dataset.select_dtypes(include=[np.number])\n",
        "del num_data['DEATH_EVENT']\n",
        "\n",
        "\n",
        "cat_data = dataset.select_dtypes(exclude=[np.number])\n",
        "\n",
        "# Idenity the predited value\n",
        "df = dataset.values\n",
        "y = df[:, 12]\n",
        "print (\"There are {} numeric and {} categorical columns in data. The predicted value is DEATH_EVENT\".format(num_data.shape[1],cat_data.shape[1]))\n",
        "y"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 7 numeric and 5 categorical columns in data. The predicted value is DEATH_EVENT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "CKE1KhNmSKH_",
        "outputId": "f379ba46-4e2d-4822-a1b5-fd950885fc86"
      },
      "source": [
        "# display numeric data \n",
        "dataset.describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.00000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>60.833893</td>\n",
              "      <td>581.839465</td>\n",
              "      <td>38.083612</td>\n",
              "      <td>263358.029264</td>\n",
              "      <td>1.39388</td>\n",
              "      <td>136.625418</td>\n",
              "      <td>130.260870</td>\n",
              "      <td>0.32107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>11.894809</td>\n",
              "      <td>970.287881</td>\n",
              "      <td>11.834841</td>\n",
              "      <td>97804.236869</td>\n",
              "      <td>1.03451</td>\n",
              "      <td>4.412477</td>\n",
              "      <td>77.614208</td>\n",
              "      <td>0.46767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>40.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>25100.000000</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>51.000000</td>\n",
              "      <td>116.500000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>212500.000000</td>\n",
              "      <td>0.90000</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>262000.000000</td>\n",
              "      <td>1.10000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>70.000000</td>\n",
              "      <td>582.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>303500.000000</td>\n",
              "      <td>1.40000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>203.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>95.000000</td>\n",
              "      <td>7861.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>850000.000000</td>\n",
              "      <td>9.40000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>285.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age  creatinine_phosphokinase  ...        time  DEATH_EVENT\n",
              "count  299.000000                299.000000  ...  299.000000    299.00000\n",
              "mean    60.833893                581.839465  ...  130.260870      0.32107\n",
              "std     11.894809                970.287881  ...   77.614208      0.46767\n",
              "min     40.000000                 23.000000  ...    4.000000      0.00000\n",
              "25%     51.000000                116.500000  ...   73.000000      0.00000\n",
              "50%     60.000000                250.000000  ...  115.000000      0.00000\n",
              "75%     70.000000                582.000000  ...  203.000000      1.00000\n",
              "max     95.000000               7861.000000  ...  285.000000      1.00000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V97j5QItKBu",
        "outputId": "261ff61e-af37-4043-fe46-38ca00de3739"
      },
      "source": [
        "# Process the numeric data\n",
        "from sklearn import  preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_num_scale = min_max_scaler.fit_transform(num_data)\n",
        "X_num_scale"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.63636364, 0.07131921, 0.09090909, ..., 0.15730337, 0.48571429,\n",
              "        0.        ],\n",
              "       [0.27272727, 1.        , 0.36363636, ..., 0.06741573, 0.65714286,\n",
              "        0.00711744],\n",
              "       [0.45454545, 0.01569278, 0.09090909, ..., 0.08988764, 0.45714286,\n",
              "        0.01067616],\n",
              "       ...,\n",
              "       [0.09090909, 0.25988773, 0.6969697 , ..., 0.03370787, 0.71428571,\n",
              "        0.97508897],\n",
              "       [0.09090909, 0.30492473, 0.36363636, ..., 0.1011236 , 0.77142857,\n",
              "        0.98220641],\n",
              "       [0.18181818, 0.02207196, 0.46969697, ..., 0.12359551, 0.65714286,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDmV_dgAtZqY",
        "outputId": "a96a04fd-9823-46cd-b63e-edb62dac8d67"
      },
      "source": [
        "X_scale = pd.concat([pd.DataFrame(X_num_scale),cat_data],axis = 1)\n",
        "X_scale.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(299, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab4gOeC4hOhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b635865-26b4-4b3b-aab5-88f34ab476af"
      },
      "source": [
        "# split the data into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size = 0.2, random_state = 4)\n",
        "y_test"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       1., 0., 1., 0., 0., 0., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCVVNJX2MoBF"
      },
      "source": [
        "In the neural network, I am using two hidden layers of 12 and 15 neurons respectively. The input shape will be 12 (features) and output will be 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3K8UjTuhv8z"
      },
      "source": [
        "# build the model\n",
        "model = Sequential([\n",
        "        Dense(12, activation='relu', input_shape=(12,)),\n",
        "        Dense(15, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')                   \n",
        "]    \n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHel02HciEuT"
      },
      "source": [
        "# compile the model\n",
        "model.compile(\n",
        "      optimizer = 'sgd',\n",
        "      loss = 'binary_crossentropy',\n",
        "      metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRMautlAif9z",
        "outputId": "9695af28-eff0-445e-805c-290058c0b8eb"
      },
      "source": [
        "# Train the model, set 1000 epochs and break up data into 20% validation dataset.\n",
        "hist = model.fit(X_train, y_train, epochs=1000, validation_split=0.2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 0.7079 - accuracy: 0.3940 - val_loss: 0.6880 - val_accuracy: 0.4792\n",
            "Epoch 2/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7119 - accuracy: 0.4233 - val_loss: 0.6816 - val_accuracy: 0.5208\n",
            "Epoch 3/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7007 - accuracy: 0.5151 - val_loss: 0.6755 - val_accuracy: 0.5625\n",
            "Epoch 4/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6897 - accuracy: 0.5456 - val_loss: 0.6700 - val_accuracy: 0.6042\n",
            "Epoch 5/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6816 - accuracy: 0.6174 - val_loss: 0.6651 - val_accuracy: 0.6875\n",
            "Epoch 6/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5772 - val_loss: 0.6608 - val_accuracy: 0.7083\n",
            "Epoch 7/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.5928 - val_loss: 0.6570 - val_accuracy: 0.7500\n",
            "Epoch 8/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6650 - accuracy: 0.6974 - val_loss: 0.6535 - val_accuracy: 0.7500\n",
            "Epoch 9/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6619 - accuracy: 0.6679 - val_loss: 0.6504 - val_accuracy: 0.7708\n",
            "Epoch 10/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6543 - accuracy: 0.6995 - val_loss: 0.6475 - val_accuracy: 0.7708\n",
            "Epoch 11/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6484 - accuracy: 0.7387 - val_loss: 0.6449 - val_accuracy: 0.7708\n",
            "Epoch 12/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6488 - accuracy: 0.7290 - val_loss: 0.6424 - val_accuracy: 0.7083\n",
            "Epoch 13/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6442 - accuracy: 0.7374 - val_loss: 0.6402 - val_accuracy: 0.7083\n",
            "Epoch 14/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6415 - accuracy: 0.7006 - val_loss: 0.6383 - val_accuracy: 0.6875\n",
            "Epoch 15/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6341 - accuracy: 0.7203 - val_loss: 0.6366 - val_accuracy: 0.6458\n",
            "Epoch 16/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6396 - accuracy: 0.7074 - val_loss: 0.6350 - val_accuracy: 0.6458\n",
            "Epoch 17/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6139 - accuracy: 0.7583 - val_loss: 0.6337 - val_accuracy: 0.6458\n",
            "Epoch 18/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6100 - accuracy: 0.7743 - val_loss: 0.6326 - val_accuracy: 0.6667\n",
            "Epoch 19/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6258 - accuracy: 0.6979 - val_loss: 0.6316 - val_accuracy: 0.6667\n",
            "Epoch 20/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6112 - accuracy: 0.7356 - val_loss: 0.6308 - val_accuracy: 0.6250\n",
            "Epoch 21/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6110 - accuracy: 0.7270 - val_loss: 0.6300 - val_accuracy: 0.6250\n",
            "Epoch 22/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6335 - accuracy: 0.6770 - val_loss: 0.6293 - val_accuracy: 0.6250\n",
            "Epoch 23/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6062 - accuracy: 0.7058 - val_loss: 0.6288 - val_accuracy: 0.6250\n",
            "Epoch 24/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6250 - accuracy: 0.6554 - val_loss: 0.6283 - val_accuracy: 0.6250\n",
            "Epoch 25/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6257 - accuracy: 0.6667 - val_loss: 0.6279 - val_accuracy: 0.6250\n",
            "Epoch 26/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5945 - accuracy: 0.7326 - val_loss: 0.6275 - val_accuracy: 0.6250\n",
            "Epoch 27/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6044 - accuracy: 0.7032 - val_loss: 0.6272 - val_accuracy: 0.6250\n",
            "Epoch 28/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6020 - accuracy: 0.7022 - val_loss: 0.6270 - val_accuracy: 0.6250\n",
            "Epoch 29/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5891 - accuracy: 0.7168 - val_loss: 0.6267 - val_accuracy: 0.6250\n",
            "Epoch 30/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6046 - accuracy: 0.6873 - val_loss: 0.6266 - val_accuracy: 0.6250\n",
            "Epoch 31/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6011 - accuracy: 0.6969 - val_loss: 0.6264 - val_accuracy: 0.6250\n",
            "Epoch 32/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6000 - accuracy: 0.6720 - val_loss: 0.6263 - val_accuracy: 0.6250\n",
            "Epoch 33/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6143 - accuracy: 0.6637 - val_loss: 0.6263 - val_accuracy: 0.6250\n",
            "Epoch 34/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6141 - accuracy: 0.6777 - val_loss: 0.6262 - val_accuracy: 0.6250\n",
            "Epoch 35/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6015 - accuracy: 0.6762 - val_loss: 0.6261 - val_accuracy: 0.6250\n",
            "Epoch 36/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5838 - accuracy: 0.7057 - val_loss: 0.6260 - val_accuracy: 0.6250\n",
            "Epoch 37/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5896 - accuracy: 0.6965 - val_loss: 0.6258 - val_accuracy: 0.6250\n",
            "Epoch 38/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5959 - accuracy: 0.6883 - val_loss: 0.6256 - val_accuracy: 0.6250\n",
            "Epoch 39/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6107 - accuracy: 0.6576 - val_loss: 0.6255 - val_accuracy: 0.6250\n",
            "Epoch 40/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5920 - accuracy: 0.6857 - val_loss: 0.6253 - val_accuracy: 0.6250\n",
            "Epoch 41/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5760 - accuracy: 0.6948 - val_loss: 0.6250 - val_accuracy: 0.6250\n",
            "Epoch 42/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6085 - accuracy: 0.6745 - val_loss: 0.6248 - val_accuracy: 0.6250\n",
            "Epoch 43/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5869 - accuracy: 0.6807 - val_loss: 0.6245 - val_accuracy: 0.6250\n",
            "Epoch 44/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5817 - accuracy: 0.6913 - val_loss: 0.6243 - val_accuracy: 0.6250\n",
            "Epoch 45/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5926 - accuracy: 0.6782 - val_loss: 0.6241 - val_accuracy: 0.6250\n",
            "Epoch 46/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5818 - accuracy: 0.6942 - val_loss: 0.6239 - val_accuracy: 0.6250\n",
            "Epoch 47/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5924 - accuracy: 0.6702 - val_loss: 0.6237 - val_accuracy: 0.6250\n",
            "Epoch 48/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5864 - accuracy: 0.6789 - val_loss: 0.6234 - val_accuracy: 0.6250\n",
            "Epoch 49/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5894 - accuracy: 0.6886 - val_loss: 0.6231 - val_accuracy: 0.6250\n",
            "Epoch 50/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5775 - accuracy: 0.6843 - val_loss: 0.6228 - val_accuracy: 0.6250\n",
            "Epoch 51/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5965 - accuracy: 0.6741 - val_loss: 0.6225 - val_accuracy: 0.6250\n",
            "Epoch 52/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6252 - accuracy: 0.6305 - val_loss: 0.6222 - val_accuracy: 0.6250\n",
            "Epoch 53/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5938 - accuracy: 0.6851 - val_loss: 0.6219 - val_accuracy: 0.6250\n",
            "Epoch 54/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5883 - accuracy: 0.6733 - val_loss: 0.6215 - val_accuracy: 0.6250\n",
            "Epoch 55/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5881 - accuracy: 0.6707 - val_loss: 0.6212 - val_accuracy: 0.6250\n",
            "Epoch 56/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5906 - accuracy: 0.6852 - val_loss: 0.6208 - val_accuracy: 0.6250\n",
            "Epoch 57/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5858 - accuracy: 0.6782 - val_loss: 0.6205 - val_accuracy: 0.6250\n",
            "Epoch 58/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5664 - accuracy: 0.6978 - val_loss: 0.6201 - val_accuracy: 0.6250\n",
            "Epoch 59/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5992 - accuracy: 0.6754 - val_loss: 0.6196 - val_accuracy: 0.6250\n",
            "Epoch 60/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5591 - accuracy: 0.7156 - val_loss: 0.6191 - val_accuracy: 0.6250\n",
            "Epoch 61/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5942 - accuracy: 0.6665 - val_loss: 0.6187 - val_accuracy: 0.6250\n",
            "Epoch 62/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5937 - accuracy: 0.6568 - val_loss: 0.6182 - val_accuracy: 0.6250\n",
            "Epoch 63/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5855 - accuracy: 0.6952 - val_loss: 0.6177 - val_accuracy: 0.6250\n",
            "Epoch 64/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5679 - accuracy: 0.6969 - val_loss: 0.6172 - val_accuracy: 0.6250\n",
            "Epoch 65/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5887 - accuracy: 0.6820 - val_loss: 0.6168 - val_accuracy: 0.6250\n",
            "Epoch 66/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5498 - accuracy: 0.7371 - val_loss: 0.6162 - val_accuracy: 0.6250\n",
            "Epoch 67/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5761 - accuracy: 0.6891 - val_loss: 0.6157 - val_accuracy: 0.6250\n",
            "Epoch 68/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5818 - accuracy: 0.6903 - val_loss: 0.6152 - val_accuracy: 0.6250\n",
            "Epoch 69/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5650 - accuracy: 0.7078 - val_loss: 0.6148 - val_accuracy: 0.6250\n",
            "Epoch 70/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5878 - accuracy: 0.6817 - val_loss: 0.6143 - val_accuracy: 0.6250\n",
            "Epoch 71/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5717 - accuracy: 0.6955 - val_loss: 0.6139 - val_accuracy: 0.6250\n",
            "Epoch 72/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5625 - accuracy: 0.7115 - val_loss: 0.6135 - val_accuracy: 0.6250\n",
            "Epoch 73/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5466 - accuracy: 0.7255 - val_loss: 0.6130 - val_accuracy: 0.6250\n",
            "Epoch 74/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5601 - accuracy: 0.7275 - val_loss: 0.6125 - val_accuracy: 0.6250\n",
            "Epoch 75/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5638 - accuracy: 0.7117 - val_loss: 0.6121 - val_accuracy: 0.6250\n",
            "Epoch 76/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5716 - accuracy: 0.7147 - val_loss: 0.6117 - val_accuracy: 0.6250\n",
            "Epoch 77/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5492 - accuracy: 0.7221 - val_loss: 0.6111 - val_accuracy: 0.6250\n",
            "Epoch 78/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5753 - accuracy: 0.6910 - val_loss: 0.6107 - val_accuracy: 0.6250\n",
            "Epoch 79/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5442 - accuracy: 0.7255 - val_loss: 0.6102 - val_accuracy: 0.6458\n",
            "Epoch 80/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5688 - accuracy: 0.7045 - val_loss: 0.6097 - val_accuracy: 0.6458\n",
            "Epoch 81/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5509 - accuracy: 0.7114 - val_loss: 0.6091 - val_accuracy: 0.6458\n",
            "Epoch 82/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5273 - accuracy: 0.7455 - val_loss: 0.6085 - val_accuracy: 0.6458\n",
            "Epoch 83/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5665 - accuracy: 0.6903 - val_loss: 0.6081 - val_accuracy: 0.6458\n",
            "Epoch 84/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5609 - accuracy: 0.6921 - val_loss: 0.6077 - val_accuracy: 0.6458\n",
            "Epoch 85/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5516 - accuracy: 0.6889 - val_loss: 0.6073 - val_accuracy: 0.6458\n",
            "Epoch 86/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5396 - accuracy: 0.7257 - val_loss: 0.6068 - val_accuracy: 0.6458\n",
            "Epoch 87/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5767 - accuracy: 0.6718 - val_loss: 0.6065 - val_accuracy: 0.6458\n",
            "Epoch 88/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5430 - accuracy: 0.7220 - val_loss: 0.6061 - val_accuracy: 0.6458\n",
            "Epoch 89/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5640 - accuracy: 0.6898 - val_loss: 0.6058 - val_accuracy: 0.6458\n",
            "Epoch 90/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5640 - accuracy: 0.7042 - val_loss: 0.6055 - val_accuracy: 0.6458\n",
            "Epoch 91/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5203 - accuracy: 0.7326 - val_loss: 0.6051 - val_accuracy: 0.6458\n",
            "Epoch 92/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5298 - accuracy: 0.7353 - val_loss: 0.6047 - val_accuracy: 0.6458\n",
            "Epoch 93/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5835 - accuracy: 0.6889 - val_loss: 0.6044 - val_accuracy: 0.6458\n",
            "Epoch 94/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5592 - accuracy: 0.7087 - val_loss: 0.6041 - val_accuracy: 0.6458\n",
            "Epoch 95/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5379 - accuracy: 0.7190 - val_loss: 0.6037 - val_accuracy: 0.6667\n",
            "Epoch 96/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5249 - accuracy: 0.7492 - val_loss: 0.6034 - val_accuracy: 0.6667\n",
            "Epoch 97/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5339 - accuracy: 0.7228 - val_loss: 0.6031 - val_accuracy: 0.6667\n",
            "Epoch 98/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5138 - accuracy: 0.7499 - val_loss: 0.6028 - val_accuracy: 0.6667\n",
            "Epoch 99/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5301 - accuracy: 0.7399 - val_loss: 0.6025 - val_accuracy: 0.6875\n",
            "Epoch 100/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5211 - accuracy: 0.7476 - val_loss: 0.6022 - val_accuracy: 0.6875\n",
            "Epoch 101/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5444 - accuracy: 0.7189 - val_loss: 0.6019 - val_accuracy: 0.6875\n",
            "Epoch 102/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5242 - accuracy: 0.7473 - val_loss: 0.6016 - val_accuracy: 0.6875\n",
            "Epoch 103/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5322 - accuracy: 0.7354 - val_loss: 0.6013 - val_accuracy: 0.6875\n",
            "Epoch 104/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5142 - accuracy: 0.7439 - val_loss: 0.6011 - val_accuracy: 0.6875\n",
            "Epoch 105/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5277 - accuracy: 0.7171 - val_loss: 0.6008 - val_accuracy: 0.6875\n",
            "Epoch 106/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5195 - accuracy: 0.7279 - val_loss: 0.6005 - val_accuracy: 0.6875\n",
            "Epoch 107/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5538 - accuracy: 0.7159 - val_loss: 0.6004 - val_accuracy: 0.6875\n",
            "Epoch 108/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5408 - accuracy: 0.7301 - val_loss: 0.6001 - val_accuracy: 0.6875\n",
            "Epoch 109/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5198 - accuracy: 0.7326 - val_loss: 0.5997 - val_accuracy: 0.7083\n",
            "Epoch 110/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5312 - accuracy: 0.7131 - val_loss: 0.5995 - val_accuracy: 0.7083\n",
            "Epoch 111/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5164 - accuracy: 0.7226 - val_loss: 0.5993 - val_accuracy: 0.7083\n",
            "Epoch 112/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5168 - accuracy: 0.7357 - val_loss: 0.5990 - val_accuracy: 0.7083\n",
            "Epoch 113/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5132 - accuracy: 0.7428 - val_loss: 0.5988 - val_accuracy: 0.7083\n",
            "Epoch 114/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4948 - accuracy: 0.7671 - val_loss: 0.5984 - val_accuracy: 0.7083\n",
            "Epoch 115/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5038 - accuracy: 0.7420 - val_loss: 0.5982 - val_accuracy: 0.7083\n",
            "Epoch 116/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5217 - accuracy: 0.7449 - val_loss: 0.5979 - val_accuracy: 0.7083\n",
            "Epoch 117/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5061 - accuracy: 0.7621 - val_loss: 0.5977 - val_accuracy: 0.7083\n",
            "Epoch 118/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5150 - accuracy: 0.7355 - val_loss: 0.5974 - val_accuracy: 0.7083\n",
            "Epoch 119/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5435 - accuracy: 0.6975 - val_loss: 0.5973 - val_accuracy: 0.7083\n",
            "Epoch 120/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5255 - accuracy: 0.7280 - val_loss: 0.5971 - val_accuracy: 0.7083\n",
            "Epoch 121/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4851 - accuracy: 0.7652 - val_loss: 0.5968 - val_accuracy: 0.7083\n",
            "Epoch 122/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4986 - accuracy: 0.7468 - val_loss: 0.5966 - val_accuracy: 0.7083\n",
            "Epoch 123/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4842 - accuracy: 0.7742 - val_loss: 0.5961 - val_accuracy: 0.7083\n",
            "Epoch 124/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4786 - accuracy: 0.7732 - val_loss: 0.5958 - val_accuracy: 0.7083\n",
            "Epoch 125/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5186 - accuracy: 0.7364 - val_loss: 0.5955 - val_accuracy: 0.7083\n",
            "Epoch 126/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5110 - accuracy: 0.7661 - val_loss: 0.5952 - val_accuracy: 0.7083\n",
            "Epoch 127/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4706 - accuracy: 0.7747 - val_loss: 0.5949 - val_accuracy: 0.7083\n",
            "Epoch 128/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5129 - accuracy: 0.7211 - val_loss: 0.5947 - val_accuracy: 0.7083\n",
            "Epoch 129/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4862 - accuracy: 0.7644 - val_loss: 0.5945 - val_accuracy: 0.7083\n",
            "Epoch 130/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4880 - accuracy: 0.7510 - val_loss: 0.5941 - val_accuracy: 0.7083\n",
            "Epoch 131/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5100 - accuracy: 0.7424 - val_loss: 0.5940 - val_accuracy: 0.7292\n",
            "Epoch 132/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4961 - accuracy: 0.7739 - val_loss: 0.5938 - val_accuracy: 0.7292\n",
            "Epoch 133/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4771 - accuracy: 0.7965 - val_loss: 0.5936 - val_accuracy: 0.7292\n",
            "Epoch 134/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4939 - accuracy: 0.7778 - val_loss: 0.5934 - val_accuracy: 0.7292\n",
            "Epoch 135/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4985 - accuracy: 0.7671 - val_loss: 0.5933 - val_accuracy: 0.7292\n",
            "Epoch 136/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5148 - accuracy: 0.7383 - val_loss: 0.5932 - val_accuracy: 0.7292\n",
            "Epoch 137/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4859 - accuracy: 0.7660 - val_loss: 0.5930 - val_accuracy: 0.7292\n",
            "Epoch 138/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5009 - accuracy: 0.7610 - val_loss: 0.5929 - val_accuracy: 0.7292\n",
            "Epoch 139/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4889 - accuracy: 0.7845 - val_loss: 0.5928 - val_accuracy: 0.7292\n",
            "Epoch 140/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4863 - accuracy: 0.7804 - val_loss: 0.5927 - val_accuracy: 0.7292\n",
            "Epoch 141/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4900 - accuracy: 0.7663 - val_loss: 0.5926 - val_accuracy: 0.7292\n",
            "Epoch 142/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4917 - accuracy: 0.7737 - val_loss: 0.5926 - val_accuracy: 0.7292\n",
            "Epoch 143/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4780 - accuracy: 0.7865 - val_loss: 0.5926 - val_accuracy: 0.7292\n",
            "Epoch 144/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4856 - accuracy: 0.7799 - val_loss: 0.5924 - val_accuracy: 0.7292\n",
            "Epoch 145/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4597 - accuracy: 0.8088 - val_loss: 0.5923 - val_accuracy: 0.7292\n",
            "Epoch 146/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4907 - accuracy: 0.7904 - val_loss: 0.5923 - val_accuracy: 0.7292\n",
            "Epoch 147/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4538 - accuracy: 0.8141 - val_loss: 0.5921 - val_accuracy: 0.7292\n",
            "Epoch 148/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4961 - accuracy: 0.7598 - val_loss: 0.5921 - val_accuracy: 0.7292\n",
            "Epoch 149/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4834 - accuracy: 0.7848 - val_loss: 0.5921 - val_accuracy: 0.7292\n",
            "Epoch 150/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4865 - accuracy: 0.7739 - val_loss: 0.5922 - val_accuracy: 0.7292\n",
            "Epoch 151/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4556 - accuracy: 0.8046 - val_loss: 0.5920 - val_accuracy: 0.7292\n",
            "Epoch 152/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4790 - accuracy: 0.7624 - val_loss: 0.5920 - val_accuracy: 0.7292\n",
            "Epoch 153/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4756 - accuracy: 0.7891 - val_loss: 0.5918 - val_accuracy: 0.7292\n",
            "Epoch 154/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4489 - accuracy: 0.8121 - val_loss: 0.5915 - val_accuracy: 0.7292\n",
            "Epoch 155/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4757 - accuracy: 0.7863 - val_loss: 0.5916 - val_accuracy: 0.7292\n",
            "Epoch 156/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4612 - accuracy: 0.7906 - val_loss: 0.5915 - val_accuracy: 0.7292\n",
            "Epoch 157/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5059 - accuracy: 0.7470 - val_loss: 0.5917 - val_accuracy: 0.7292\n",
            "Epoch 158/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4765 - accuracy: 0.8079 - val_loss: 0.5915 - val_accuracy: 0.7292\n",
            "Epoch 159/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4403 - accuracy: 0.8329 - val_loss: 0.5915 - val_accuracy: 0.7292\n",
            "Epoch 160/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4634 - accuracy: 0.8157 - val_loss: 0.5914 - val_accuracy: 0.7292\n",
            "Epoch 161/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4800 - accuracy: 0.7996 - val_loss: 0.5914 - val_accuracy: 0.7292\n",
            "Epoch 162/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4628 - accuracy: 0.7906 - val_loss: 0.5913 - val_accuracy: 0.7500\n",
            "Epoch 163/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4844 - accuracy: 0.7868 - val_loss: 0.5914 - val_accuracy: 0.7500\n",
            "Epoch 164/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4226 - accuracy: 0.8468 - val_loss: 0.5912 - val_accuracy: 0.7500\n",
            "Epoch 165/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4726 - accuracy: 0.8102 - val_loss: 0.5912 - val_accuracy: 0.7500\n",
            "Epoch 166/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4779 - accuracy: 0.8127 - val_loss: 0.5912 - val_accuracy: 0.7500\n",
            "Epoch 167/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4505 - accuracy: 0.8306 - val_loss: 0.5912 - val_accuracy: 0.7500\n",
            "Epoch 168/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4569 - accuracy: 0.8072 - val_loss: 0.5912 - val_accuracy: 0.7500\n",
            "Epoch 169/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4772 - accuracy: 0.8070 - val_loss: 0.5911 - val_accuracy: 0.7500\n",
            "Epoch 170/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4517 - accuracy: 0.8184 - val_loss: 0.5912 - val_accuracy: 0.7500\n",
            "Epoch 171/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4268 - accuracy: 0.8456 - val_loss: 0.5913 - val_accuracy: 0.7500\n",
            "Epoch 172/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4519 - accuracy: 0.8256 - val_loss: 0.5913 - val_accuracy: 0.7500\n",
            "Epoch 173/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4703 - accuracy: 0.8052 - val_loss: 0.5913 - val_accuracy: 0.7500\n",
            "Epoch 174/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4660 - accuracy: 0.7990 - val_loss: 0.5913 - val_accuracy: 0.7500\n",
            "Epoch 175/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4739 - accuracy: 0.8044 - val_loss: 0.5913 - val_accuracy: 0.7500\n",
            "Epoch 176/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4243 - accuracy: 0.8419 - val_loss: 0.5913 - val_accuracy: 0.7500\n",
            "Epoch 177/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4556 - accuracy: 0.8465 - val_loss: 0.5911 - val_accuracy: 0.7500\n",
            "Epoch 178/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4554 - accuracy: 0.8153 - val_loss: 0.5910 - val_accuracy: 0.7500\n",
            "Epoch 179/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4325 - accuracy: 0.8506 - val_loss: 0.5910 - val_accuracy: 0.7500\n",
            "Epoch 180/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4403 - accuracy: 0.8258 - val_loss: 0.5909 - val_accuracy: 0.7292\n",
            "Epoch 181/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4136 - accuracy: 0.8396 - val_loss: 0.5906 - val_accuracy: 0.7292\n",
            "Epoch 182/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4531 - accuracy: 0.8077 - val_loss: 0.5908 - val_accuracy: 0.7292\n",
            "Epoch 183/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4511 - accuracy: 0.8185 - val_loss: 0.5909 - val_accuracy: 0.7292\n",
            "Epoch 184/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4415 - accuracy: 0.8307 - val_loss: 0.5909 - val_accuracy: 0.7500\n",
            "Epoch 185/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4368 - accuracy: 0.8179 - val_loss: 0.5909 - val_accuracy: 0.7500\n",
            "Epoch 186/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4244 - accuracy: 0.8435 - val_loss: 0.5907 - val_accuracy: 0.7500\n",
            "Epoch 187/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4439 - accuracy: 0.8137 - val_loss: 0.5911 - val_accuracy: 0.7500\n",
            "Epoch 188/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3994 - accuracy: 0.8544 - val_loss: 0.5909 - val_accuracy: 0.7500\n",
            "Epoch 189/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4257 - accuracy: 0.8224 - val_loss: 0.5909 - val_accuracy: 0.7500\n",
            "Epoch 190/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4416 - accuracy: 0.8237 - val_loss: 0.5912 - val_accuracy: 0.7500\n",
            "Epoch 191/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4183 - accuracy: 0.8468 - val_loss: 0.5910 - val_accuracy: 0.7500\n",
            "Epoch 192/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4674 - accuracy: 0.8094 - val_loss: 0.5911 - val_accuracy: 0.7500\n",
            "Epoch 193/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4252 - accuracy: 0.8283 - val_loss: 0.5910 - val_accuracy: 0.7500\n",
            "Epoch 194/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4088 - accuracy: 0.8467 - val_loss: 0.5909 - val_accuracy: 0.7500\n",
            "Epoch 195/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4211 - accuracy: 0.8377 - val_loss: 0.5911 - val_accuracy: 0.7500\n",
            "Epoch 196/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4043 - accuracy: 0.8489 - val_loss: 0.5911 - val_accuracy: 0.7500\n",
            "Epoch 197/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4727 - accuracy: 0.7878 - val_loss: 0.5915 - val_accuracy: 0.7500\n",
            "Epoch 198/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4353 - accuracy: 0.8172 - val_loss: 0.5917 - val_accuracy: 0.7500\n",
            "Epoch 199/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4005 - accuracy: 0.8463 - val_loss: 0.5917 - val_accuracy: 0.7500\n",
            "Epoch 200/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4390 - accuracy: 0.8180 - val_loss: 0.5920 - val_accuracy: 0.7500\n",
            "Epoch 201/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4173 - accuracy: 0.8305 - val_loss: 0.5920 - val_accuracy: 0.7500\n",
            "Epoch 202/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3912 - accuracy: 0.8535 - val_loss: 0.5919 - val_accuracy: 0.7500\n",
            "Epoch 203/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4321 - accuracy: 0.8269 - val_loss: 0.5921 - val_accuracy: 0.7500\n",
            "Epoch 204/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4860 - accuracy: 0.7733 - val_loss: 0.5926 - val_accuracy: 0.7500\n",
            "Epoch 205/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4381 - accuracy: 0.8365 - val_loss: 0.5924 - val_accuracy: 0.7500\n",
            "Epoch 206/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4108 - accuracy: 0.8453 - val_loss: 0.5924 - val_accuracy: 0.7292\n",
            "Epoch 207/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4276 - accuracy: 0.8289 - val_loss: 0.5927 - val_accuracy: 0.7292\n",
            "Epoch 208/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4117 - accuracy: 0.8358 - val_loss: 0.5931 - val_accuracy: 0.7292\n",
            "Epoch 209/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4445 - accuracy: 0.8306 - val_loss: 0.5929 - val_accuracy: 0.7292\n",
            "Epoch 210/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4037 - accuracy: 0.8370 - val_loss: 0.5929 - val_accuracy: 0.7292\n",
            "Epoch 211/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4082 - accuracy: 0.8330 - val_loss: 0.5927 - val_accuracy: 0.7292\n",
            "Epoch 212/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4378 - accuracy: 0.8321 - val_loss: 0.5933 - val_accuracy: 0.7292\n",
            "Epoch 213/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4230 - accuracy: 0.8455 - val_loss: 0.5935 - val_accuracy: 0.7292\n",
            "Epoch 214/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3844 - accuracy: 0.8798 - val_loss: 0.5934 - val_accuracy: 0.7292\n",
            "Epoch 215/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4388 - accuracy: 0.8246 - val_loss: 0.5937 - val_accuracy: 0.7292\n",
            "Epoch 216/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4285 - accuracy: 0.8287 - val_loss: 0.5936 - val_accuracy: 0.7292\n",
            "Epoch 217/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4105 - accuracy: 0.8400 - val_loss: 0.5936 - val_accuracy: 0.7292\n",
            "Epoch 218/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3960 - accuracy: 0.8557 - val_loss: 0.5938 - val_accuracy: 0.7292\n",
            "Epoch 219/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4117 - accuracy: 0.8518 - val_loss: 0.5939 - val_accuracy: 0.7292\n",
            "Epoch 220/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4186 - accuracy: 0.8525 - val_loss: 0.5941 - val_accuracy: 0.7292\n",
            "Epoch 221/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3904 - accuracy: 0.8612 - val_loss: 0.5944 - val_accuracy: 0.7292\n",
            "Epoch 222/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4505 - accuracy: 0.8470 - val_loss: 0.5949 - val_accuracy: 0.7292\n",
            "Epoch 223/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4122 - accuracy: 0.8577 - val_loss: 0.5948 - val_accuracy: 0.7292\n",
            "Epoch 224/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4054 - accuracy: 0.8489 - val_loss: 0.5951 - val_accuracy: 0.7292\n",
            "Epoch 225/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3906 - accuracy: 0.8819 - val_loss: 0.5951 - val_accuracy: 0.7292\n",
            "Epoch 226/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3859 - accuracy: 0.8600 - val_loss: 0.5952 - val_accuracy: 0.7292\n",
            "Epoch 227/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4438 - accuracy: 0.8211 - val_loss: 0.5954 - val_accuracy: 0.7292\n",
            "Epoch 228/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4051 - accuracy: 0.8602 - val_loss: 0.5957 - val_accuracy: 0.7292\n",
            "Epoch 229/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3886 - accuracy: 0.8600 - val_loss: 0.5962 - val_accuracy: 0.7292\n",
            "Epoch 230/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3994 - accuracy: 0.8637 - val_loss: 0.5959 - val_accuracy: 0.7292\n",
            "Epoch 231/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4129 - accuracy: 0.8465 - val_loss: 0.5961 - val_accuracy: 0.7500\n",
            "Epoch 232/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3785 - accuracy: 0.8586 - val_loss: 0.5960 - val_accuracy: 0.7500\n",
            "Epoch 233/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4315 - accuracy: 0.8368 - val_loss: 0.5968 - val_accuracy: 0.7500\n",
            "Epoch 234/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3528 - accuracy: 0.8948 - val_loss: 0.5964 - val_accuracy: 0.7500\n",
            "Epoch 235/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4045 - accuracy: 0.8415 - val_loss: 0.5964 - val_accuracy: 0.7500\n",
            "Epoch 236/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3842 - accuracy: 0.8477 - val_loss: 0.5969 - val_accuracy: 0.7500\n",
            "Epoch 237/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4244 - accuracy: 0.8164 - val_loss: 0.5970 - val_accuracy: 0.7500\n",
            "Epoch 238/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3877 - accuracy: 0.8542 - val_loss: 0.5967 - val_accuracy: 0.7500\n",
            "Epoch 239/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3963 - accuracy: 0.8572 - val_loss: 0.5969 - val_accuracy: 0.7500\n",
            "Epoch 240/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4088 - accuracy: 0.8446 - val_loss: 0.5975 - val_accuracy: 0.7500\n",
            "Epoch 241/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3709 - accuracy: 0.8802 - val_loss: 0.5978 - val_accuracy: 0.7500\n",
            "Epoch 242/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3790 - accuracy: 0.8689 - val_loss: 0.5978 - val_accuracy: 0.7500\n",
            "Epoch 243/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.8164 - val_loss: 0.5978 - val_accuracy: 0.7500\n",
            "Epoch 244/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3802 - accuracy: 0.8527 - val_loss: 0.5973 - val_accuracy: 0.7500\n",
            "Epoch 245/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3862 - accuracy: 0.8474 - val_loss: 0.5977 - val_accuracy: 0.7500\n",
            "Epoch 246/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4160 - accuracy: 0.8371 - val_loss: 0.5979 - val_accuracy: 0.7500\n",
            "Epoch 247/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4117 - accuracy: 0.8506 - val_loss: 0.5978 - val_accuracy: 0.7500\n",
            "Epoch 248/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3903 - accuracy: 0.8455 - val_loss: 0.5981 - val_accuracy: 0.7500\n",
            "Epoch 249/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3656 - accuracy: 0.8786 - val_loss: 0.5983 - val_accuracy: 0.7500\n",
            "Epoch 250/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3965 - accuracy: 0.8499 - val_loss: 0.5982 - val_accuracy: 0.7500\n",
            "Epoch 251/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4108 - accuracy: 0.8372 - val_loss: 0.5989 - val_accuracy: 0.7500\n",
            "Epoch 252/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3584 - accuracy: 0.8898 - val_loss: 0.5992 - val_accuracy: 0.7500\n",
            "Epoch 253/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3946 - accuracy: 0.8476 - val_loss: 0.5994 - val_accuracy: 0.7500\n",
            "Epoch 254/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3757 - accuracy: 0.8689 - val_loss: 0.5993 - val_accuracy: 0.7500\n",
            "Epoch 255/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3687 - accuracy: 0.8813 - val_loss: 0.5990 - val_accuracy: 0.7292\n",
            "Epoch 256/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3953 - accuracy: 0.8376 - val_loss: 0.5995 - val_accuracy: 0.7292\n",
            "Epoch 257/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3789 - accuracy: 0.8366 - val_loss: 0.5997 - val_accuracy: 0.7292\n",
            "Epoch 258/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4087 - accuracy: 0.8480 - val_loss: 0.6000 - val_accuracy: 0.7292\n",
            "Epoch 259/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4259 - accuracy: 0.8176 - val_loss: 0.6003 - val_accuracy: 0.7292\n",
            "Epoch 260/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4063 - accuracy: 0.8203 - val_loss: 0.6005 - val_accuracy: 0.7292\n",
            "Epoch 261/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3801 - accuracy: 0.8468 - val_loss: 0.6005 - val_accuracy: 0.7292\n",
            "Epoch 262/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4108 - accuracy: 0.8307 - val_loss: 0.6007 - val_accuracy: 0.7292\n",
            "Epoch 263/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4140 - accuracy: 0.8456 - val_loss: 0.6015 - val_accuracy: 0.7292\n",
            "Epoch 264/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3638 - accuracy: 0.8641 - val_loss: 0.6014 - val_accuracy: 0.7292\n",
            "Epoch 265/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3702 - accuracy: 0.8373 - val_loss: 0.6010 - val_accuracy: 0.7292\n",
            "Epoch 266/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3671 - accuracy: 0.8739 - val_loss: 0.6007 - val_accuracy: 0.7292\n",
            "Epoch 267/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3803 - accuracy: 0.8509 - val_loss: 0.6010 - val_accuracy: 0.7292\n",
            "Epoch 268/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3818 - accuracy: 0.8524 - val_loss: 0.6009 - val_accuracy: 0.7292\n",
            "Epoch 269/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3755 - accuracy: 0.8610 - val_loss: 0.6011 - val_accuracy: 0.7292\n",
            "Epoch 270/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3741 - accuracy: 0.8423 - val_loss: 0.6014 - val_accuracy: 0.7292\n",
            "Epoch 271/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3653 - accuracy: 0.8714 - val_loss: 0.6011 - val_accuracy: 0.7292\n",
            "Epoch 272/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4051 - accuracy: 0.8275 - val_loss: 0.6019 - val_accuracy: 0.7292\n",
            "Epoch 273/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3798 - accuracy: 0.8515 - val_loss: 0.6015 - val_accuracy: 0.7292\n",
            "Epoch 274/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3748 - accuracy: 0.8563 - val_loss: 0.6025 - val_accuracy: 0.7292\n",
            "Epoch 275/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3842 - accuracy: 0.8378 - val_loss: 0.6029 - val_accuracy: 0.7292\n",
            "Epoch 276/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3615 - accuracy: 0.8645 - val_loss: 0.6027 - val_accuracy: 0.7292\n",
            "Epoch 277/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4022 - accuracy: 0.8330 - val_loss: 0.6025 - val_accuracy: 0.7292\n",
            "Epoch 278/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3860 - accuracy: 0.8568 - val_loss: 0.6029 - val_accuracy: 0.7292\n",
            "Epoch 279/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3766 - accuracy: 0.8469 - val_loss: 0.6026 - val_accuracy: 0.7292\n",
            "Epoch 280/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3613 - accuracy: 0.8516 - val_loss: 0.6028 - val_accuracy: 0.7292\n",
            "Epoch 281/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3549 - accuracy: 0.8631 - val_loss: 0.6027 - val_accuracy: 0.7292\n",
            "Epoch 282/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3860 - accuracy: 0.8471 - val_loss: 0.6029 - val_accuracy: 0.7292\n",
            "Epoch 283/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3505 - accuracy: 0.8730 - val_loss: 0.6026 - val_accuracy: 0.7292\n",
            "Epoch 284/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3303 - accuracy: 0.8700 - val_loss: 0.6026 - val_accuracy: 0.7292\n",
            "Epoch 285/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3620 - accuracy: 0.8646 - val_loss: 0.6032 - val_accuracy: 0.7292\n",
            "Epoch 286/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3427 - accuracy: 0.8708 - val_loss: 0.6030 - val_accuracy: 0.7292\n",
            "Epoch 287/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3336 - accuracy: 0.8662 - val_loss: 0.6028 - val_accuracy: 0.7292\n",
            "Epoch 288/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4151 - accuracy: 0.8262 - val_loss: 0.6033 - val_accuracy: 0.7292\n",
            "Epoch 289/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3525 - accuracy: 0.8755 - val_loss: 0.6034 - val_accuracy: 0.7292\n",
            "Epoch 290/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4087 - accuracy: 0.8045 - val_loss: 0.6036 - val_accuracy: 0.7292\n",
            "Epoch 291/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4110 - accuracy: 0.8301 - val_loss: 0.6040 - val_accuracy: 0.7292\n",
            "Epoch 292/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3569 - accuracy: 0.8728 - val_loss: 0.6036 - val_accuracy: 0.7292\n",
            "Epoch 293/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3743 - accuracy: 0.8386 - val_loss: 0.6039 - val_accuracy: 0.7292\n",
            "Epoch 294/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3555 - accuracy: 0.8546 - val_loss: 0.6042 - val_accuracy: 0.7292\n",
            "Epoch 295/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3610 - accuracy: 0.8582 - val_loss: 0.6049 - val_accuracy: 0.7292\n",
            "Epoch 296/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3790 - accuracy: 0.8577 - val_loss: 0.6047 - val_accuracy: 0.7292\n",
            "Epoch 297/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3573 - accuracy: 0.8695 - val_loss: 0.6047 - val_accuracy: 0.7292\n",
            "Epoch 298/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3743 - accuracy: 0.8557 - val_loss: 0.6048 - val_accuracy: 0.7292\n",
            "Epoch 299/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3687 - accuracy: 0.8682 - val_loss: 0.6044 - val_accuracy: 0.7292\n",
            "Epoch 300/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3517 - accuracy: 0.8551 - val_loss: 0.6046 - val_accuracy: 0.7292\n",
            "Epoch 301/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3580 - accuracy: 0.8768 - val_loss: 0.6046 - val_accuracy: 0.7292\n",
            "Epoch 302/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3614 - accuracy: 0.8624 - val_loss: 0.6045 - val_accuracy: 0.7292\n",
            "Epoch 303/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3657 - accuracy: 0.8660 - val_loss: 0.6047 - val_accuracy: 0.7292\n",
            "Epoch 304/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3342 - accuracy: 0.8932 - val_loss: 0.6047 - val_accuracy: 0.7292\n",
            "Epoch 305/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3723 - accuracy: 0.8352 - val_loss: 0.6053 - val_accuracy: 0.7292\n",
            "Epoch 306/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3682 - accuracy: 0.8578 - val_loss: 0.6050 - val_accuracy: 0.7292\n",
            "Epoch 307/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3880 - accuracy: 0.8342 - val_loss: 0.6053 - val_accuracy: 0.7292\n",
            "Epoch 308/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3836 - accuracy: 0.8289 - val_loss: 0.6055 - val_accuracy: 0.7292\n",
            "Epoch 309/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3606 - accuracy: 0.8624 - val_loss: 0.6064 - val_accuracy: 0.7292\n",
            "Epoch 310/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3417 - accuracy: 0.8846 - val_loss: 0.6056 - val_accuracy: 0.7292\n",
            "Epoch 311/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3761 - accuracy: 0.8453 - val_loss: 0.6055 - val_accuracy: 0.7292\n",
            "Epoch 312/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3579 - accuracy: 0.8552 - val_loss: 0.6059 - val_accuracy: 0.7292\n",
            "Epoch 313/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3422 - accuracy: 0.8878 - val_loss: 0.6052 - val_accuracy: 0.7292\n",
            "Epoch 314/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3862 - accuracy: 0.8355 - val_loss: 0.6051 - val_accuracy: 0.7292\n",
            "Epoch 315/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3702 - accuracy: 0.8557 - val_loss: 0.6062 - val_accuracy: 0.7292\n",
            "Epoch 316/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3251 - accuracy: 0.8610 - val_loss: 0.6060 - val_accuracy: 0.7292\n",
            "Epoch 317/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3307 - accuracy: 0.8578 - val_loss: 0.6053 - val_accuracy: 0.7292\n",
            "Epoch 318/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3629 - accuracy: 0.8696 - val_loss: 0.6053 - val_accuracy: 0.7292\n",
            "Epoch 319/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3354 - accuracy: 0.8621 - val_loss: 0.6051 - val_accuracy: 0.7292\n",
            "Epoch 320/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3812 - accuracy: 0.8456 - val_loss: 0.6050 - val_accuracy: 0.7292\n",
            "Epoch 321/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3503 - accuracy: 0.8568 - val_loss: 0.6057 - val_accuracy: 0.7292\n",
            "Epoch 322/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3432 - accuracy: 0.8766 - val_loss: 0.6050 - val_accuracy: 0.7292\n",
            "Epoch 323/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3608 - accuracy: 0.8526 - val_loss: 0.6054 - val_accuracy: 0.7292\n",
            "Epoch 324/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3449 - accuracy: 0.8579 - val_loss: 0.6057 - val_accuracy: 0.7292\n",
            "Epoch 325/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3402 - accuracy: 0.8498 - val_loss: 0.6064 - val_accuracy: 0.7292\n",
            "Epoch 326/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3571 - accuracy: 0.8688 - val_loss: 0.6060 - val_accuracy: 0.7292\n",
            "Epoch 327/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3488 - accuracy: 0.8562 - val_loss: 0.6052 - val_accuracy: 0.7292\n",
            "Epoch 328/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3881 - accuracy: 0.8167 - val_loss: 0.6060 - val_accuracy: 0.7292\n",
            "Epoch 329/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3533 - accuracy: 0.8374 - val_loss: 0.6067 - val_accuracy: 0.7292\n",
            "Epoch 330/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3535 - accuracy: 0.8636 - val_loss: 0.6059 - val_accuracy: 0.7292\n",
            "Epoch 331/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3385 - accuracy: 0.8545 - val_loss: 0.6059 - val_accuracy: 0.7292\n",
            "Epoch 332/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3339 - accuracy: 0.8741 - val_loss: 0.6068 - val_accuracy: 0.7292\n",
            "Epoch 333/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3200 - accuracy: 0.8815 - val_loss: 0.6063 - val_accuracy: 0.7292\n",
            "Epoch 334/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3485 - accuracy: 0.8628 - val_loss: 0.6061 - val_accuracy: 0.7292\n",
            "Epoch 335/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3386 - accuracy: 0.8631 - val_loss: 0.6057 - val_accuracy: 0.7292\n",
            "Epoch 336/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3624 - accuracy: 0.8513 - val_loss: 0.6048 - val_accuracy: 0.7292\n",
            "Epoch 337/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3424 - accuracy: 0.8703 - val_loss: 0.6047 - val_accuracy: 0.7292\n",
            "Epoch 338/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3624 - accuracy: 0.8394 - val_loss: 0.6063 - val_accuracy: 0.7292\n",
            "Epoch 339/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4193 - accuracy: 0.8171 - val_loss: 0.6068 - val_accuracy: 0.7292\n",
            "Epoch 340/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3594 - accuracy: 0.8506 - val_loss: 0.6069 - val_accuracy: 0.7292\n",
            "Epoch 341/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3566 - accuracy: 0.8581 - val_loss: 0.6066 - val_accuracy: 0.7292\n",
            "Epoch 342/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3672 - accuracy: 0.8493 - val_loss: 0.6062 - val_accuracy: 0.7292\n",
            "Epoch 343/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3668 - accuracy: 0.8453 - val_loss: 0.6062 - val_accuracy: 0.7292\n",
            "Epoch 344/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3185 - accuracy: 0.8801 - val_loss: 0.6056 - val_accuracy: 0.7292\n",
            "Epoch 345/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3444 - accuracy: 0.8751 - val_loss: 0.6062 - val_accuracy: 0.7292\n",
            "Epoch 346/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3437 - accuracy: 0.8586 - val_loss: 0.6074 - val_accuracy: 0.7292\n",
            "Epoch 347/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3504 - accuracy: 0.8607 - val_loss: 0.6063 - val_accuracy: 0.7292\n",
            "Epoch 348/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3813 - accuracy: 0.8476 - val_loss: 0.6068 - val_accuracy: 0.7292\n",
            "Epoch 349/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3562 - accuracy: 0.8660 - val_loss: 0.6065 - val_accuracy: 0.7292\n",
            "Epoch 350/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3918 - accuracy: 0.8374 - val_loss: 0.6069 - val_accuracy: 0.7292\n",
            "Epoch 351/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3042 - accuracy: 0.8897 - val_loss: 0.6069 - val_accuracy: 0.7292\n",
            "Epoch 352/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3650 - accuracy: 0.8509 - val_loss: 0.6055 - val_accuracy: 0.7292\n",
            "Epoch 353/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3574 - accuracy: 0.8412 - val_loss: 0.6060 - val_accuracy: 0.7292\n",
            "Epoch 354/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3332 - accuracy: 0.8630 - val_loss: 0.6061 - val_accuracy: 0.7292\n",
            "Epoch 355/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3440 - accuracy: 0.8679 - val_loss: 0.6061 - val_accuracy: 0.7292\n",
            "Epoch 356/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3027 - accuracy: 0.8909 - val_loss: 0.6066 - val_accuracy: 0.7292\n",
            "Epoch 357/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3572 - accuracy: 0.8668 - val_loss: 0.6059 - val_accuracy: 0.7292\n",
            "Epoch 358/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3220 - accuracy: 0.8626 - val_loss: 0.6055 - val_accuracy: 0.7292\n",
            "Epoch 359/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3667 - accuracy: 0.8363 - val_loss: 0.6058 - val_accuracy: 0.7292\n",
            "Epoch 360/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3609 - accuracy: 0.8467 - val_loss: 0.6062 - val_accuracy: 0.7292\n",
            "Epoch 361/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3434 - accuracy: 0.8563 - val_loss: 0.6064 - val_accuracy: 0.7292\n",
            "Epoch 362/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3469 - accuracy: 0.8522 - val_loss: 0.6061 - val_accuracy: 0.7292\n",
            "Epoch 363/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3480 - accuracy: 0.8693 - val_loss: 0.6062 - val_accuracy: 0.7292\n",
            "Epoch 364/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3549 - accuracy: 0.8535 - val_loss: 0.6061 - val_accuracy: 0.7292\n",
            "Epoch 365/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3393 - accuracy: 0.8541 - val_loss: 0.6057 - val_accuracy: 0.7292\n",
            "Epoch 366/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3405 - accuracy: 0.8494 - val_loss: 0.6060 - val_accuracy: 0.7292\n",
            "Epoch 367/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3229 - accuracy: 0.8803 - val_loss: 0.6052 - val_accuracy: 0.7292\n",
            "Epoch 368/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3432 - accuracy: 0.8638 - val_loss: 0.6049 - val_accuracy: 0.7292\n",
            "Epoch 369/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3473 - accuracy: 0.8480 - val_loss: 0.6059 - val_accuracy: 0.7292\n",
            "Epoch 370/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3435 - accuracy: 0.8749 - val_loss: 0.6052 - val_accuracy: 0.7292\n",
            "Epoch 371/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3460 - accuracy: 0.8502 - val_loss: 0.6055 - val_accuracy: 0.7292\n",
            "Epoch 372/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3054 - accuracy: 0.8739 - val_loss: 0.6056 - val_accuracy: 0.7292\n",
            "Epoch 373/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3668 - accuracy: 0.8380 - val_loss: 0.6071 - val_accuracy: 0.7292\n",
            "Epoch 374/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3149 - accuracy: 0.8811 - val_loss: 0.6061 - val_accuracy: 0.7292\n",
            "Epoch 375/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3190 - accuracy: 0.8710 - val_loss: 0.6057 - val_accuracy: 0.7292\n",
            "Epoch 376/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3354 - accuracy: 0.8755 - val_loss: 0.6054 - val_accuracy: 0.7500\n",
            "Epoch 377/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3382 - accuracy: 0.8693 - val_loss: 0.6053 - val_accuracy: 0.7500\n",
            "Epoch 378/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3700 - accuracy: 0.8361 - val_loss: 0.6062 - val_accuracy: 0.7500\n",
            "Epoch 379/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3565 - accuracy: 0.8620 - val_loss: 0.6069 - val_accuracy: 0.7292\n",
            "Epoch 380/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3289 - accuracy: 0.8714 - val_loss: 0.6056 - val_accuracy: 0.7500\n",
            "Epoch 381/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3506 - accuracy: 0.8637 - val_loss: 0.6056 - val_accuracy: 0.7500\n",
            "Epoch 382/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3327 - accuracy: 0.8772 - val_loss: 0.6053 - val_accuracy: 0.7500\n",
            "Epoch 383/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3350 - accuracy: 0.8452 - val_loss: 0.6063 - val_accuracy: 0.7500\n",
            "Epoch 384/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3617 - accuracy: 0.8471 - val_loss: 0.6070 - val_accuracy: 0.7500\n",
            "Epoch 385/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3875 - accuracy: 0.8415 - val_loss: 0.6070 - val_accuracy: 0.7500\n",
            "Epoch 386/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3596 - accuracy: 0.8568 - val_loss: 0.6055 - val_accuracy: 0.7500\n",
            "Epoch 387/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3477 - accuracy: 0.8578 - val_loss: 0.6057 - val_accuracy: 0.7500\n",
            "Epoch 388/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3275 - accuracy: 0.8775 - val_loss: 0.6060 - val_accuracy: 0.7500\n",
            "Epoch 389/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3659 - accuracy: 0.8499 - val_loss: 0.6066 - val_accuracy: 0.7500\n",
            "Epoch 390/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3922 - accuracy: 0.8289 - val_loss: 0.6066 - val_accuracy: 0.7500\n",
            "Epoch 391/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2879 - accuracy: 0.8944 - val_loss: 0.6053 - val_accuracy: 0.7500\n",
            "Epoch 392/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3333 - accuracy: 0.8671 - val_loss: 0.6041 - val_accuracy: 0.7500\n",
            "Epoch 393/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3612 - accuracy: 0.8456 - val_loss: 0.6044 - val_accuracy: 0.7500\n",
            "Epoch 394/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3417 - accuracy: 0.8474 - val_loss: 0.6049 - val_accuracy: 0.7500\n",
            "Epoch 395/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3787 - accuracy: 0.8458 - val_loss: 0.6064 - val_accuracy: 0.7500\n",
            "Epoch 396/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3365 - accuracy: 0.8580 - val_loss: 0.6058 - val_accuracy: 0.7500\n",
            "Epoch 397/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3454 - accuracy: 0.8549 - val_loss: 0.6043 - val_accuracy: 0.7500\n",
            "Epoch 398/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2940 - accuracy: 0.8853 - val_loss: 0.6040 - val_accuracy: 0.7500\n",
            "Epoch 399/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3183 - accuracy: 0.8755 - val_loss: 0.6043 - val_accuracy: 0.7500\n",
            "Epoch 400/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3499 - accuracy: 0.8589 - val_loss: 0.6050 - val_accuracy: 0.7500\n",
            "Epoch 401/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3757 - accuracy: 0.8285 - val_loss: 0.6046 - val_accuracy: 0.7500\n",
            "Epoch 402/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3535 - accuracy: 0.8576 - val_loss: 0.6056 - val_accuracy: 0.7500\n",
            "Epoch 403/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3155 - accuracy: 0.8750 - val_loss: 0.6044 - val_accuracy: 0.7500\n",
            "Epoch 404/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2959 - accuracy: 0.8973 - val_loss: 0.6049 - val_accuracy: 0.7500\n",
            "Epoch 405/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3542 - accuracy: 0.8441 - val_loss: 0.6043 - val_accuracy: 0.7500\n",
            "Epoch 406/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2913 - accuracy: 0.8906 - val_loss: 0.6036 - val_accuracy: 0.7500\n",
            "Epoch 407/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3236 - accuracy: 0.8586 - val_loss: 0.6041 - val_accuracy: 0.7500\n",
            "Epoch 408/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3398 - accuracy: 0.8449 - val_loss: 0.6037 - val_accuracy: 0.7500\n",
            "Epoch 409/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3533 - accuracy: 0.8492 - val_loss: 0.6040 - val_accuracy: 0.7500\n",
            "Epoch 410/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3773 - accuracy: 0.8517 - val_loss: 0.6047 - val_accuracy: 0.7500\n",
            "Epoch 411/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3222 - accuracy: 0.8680 - val_loss: 0.6045 - val_accuracy: 0.7500\n",
            "Epoch 412/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3691 - accuracy: 0.8345 - val_loss: 0.6053 - val_accuracy: 0.7708\n",
            "Epoch 413/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3176 - accuracy: 0.8557 - val_loss: 0.6033 - val_accuracy: 0.7500\n",
            "Epoch 414/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3464 - accuracy: 0.8619 - val_loss: 0.6024 - val_accuracy: 0.7500\n",
            "Epoch 415/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3320 - accuracy: 0.8696 - val_loss: 0.6017 - val_accuracy: 0.7500\n",
            "Epoch 416/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4078 - accuracy: 0.8164 - val_loss: 0.6027 - val_accuracy: 0.7500\n",
            "Epoch 417/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3573 - accuracy: 0.8615 - val_loss: 0.6025 - val_accuracy: 0.7500\n",
            "Epoch 418/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3350 - accuracy: 0.8521 - val_loss: 0.6031 - val_accuracy: 0.7500\n",
            "Epoch 419/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3414 - accuracy: 0.8694 - val_loss: 0.6037 - val_accuracy: 0.7708\n",
            "Epoch 420/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3510 - accuracy: 0.8586 - val_loss: 0.6038 - val_accuracy: 0.7708\n",
            "Epoch 421/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3081 - accuracy: 0.8871 - val_loss: 0.6036 - val_accuracy: 0.7708\n",
            "Epoch 422/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3415 - accuracy: 0.8720 - val_loss: 0.6043 - val_accuracy: 0.7708\n",
            "Epoch 423/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3220 - accuracy: 0.8902 - val_loss: 0.6035 - val_accuracy: 0.7708\n",
            "Epoch 424/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3213 - accuracy: 0.8772 - val_loss: 0.6013 - val_accuracy: 0.7500\n",
            "Epoch 425/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3602 - accuracy: 0.8524 - val_loss: 0.6032 - val_accuracy: 0.7708\n",
            "Epoch 426/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3087 - accuracy: 0.8715 - val_loss: 0.6028 - val_accuracy: 0.7708\n",
            "Epoch 427/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2949 - accuracy: 0.8967 - val_loss: 0.6029 - val_accuracy: 0.7708\n",
            "Epoch 428/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3603 - accuracy: 0.8574 - val_loss: 0.6036 - val_accuracy: 0.7708\n",
            "Epoch 429/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3216 - accuracy: 0.8717 - val_loss: 0.6032 - val_accuracy: 0.7708\n",
            "Epoch 430/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2977 - accuracy: 0.8890 - val_loss: 0.6040 - val_accuracy: 0.7708\n",
            "Epoch 431/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3206 - accuracy: 0.8742 - val_loss: 0.6028 - val_accuracy: 0.7708\n",
            "Epoch 432/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3340 - accuracy: 0.8633 - val_loss: 0.6034 - val_accuracy: 0.7708\n",
            "Epoch 433/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3612 - accuracy: 0.8566 - val_loss: 0.6035 - val_accuracy: 0.7708\n",
            "Epoch 434/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3291 - accuracy: 0.8563 - val_loss: 0.6012 - val_accuracy: 0.7708\n",
            "Epoch 435/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3488 - accuracy: 0.8547 - val_loss: 0.6017 - val_accuracy: 0.7708\n",
            "Epoch 436/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3445 - accuracy: 0.8499 - val_loss: 0.6021 - val_accuracy: 0.7708\n",
            "Epoch 437/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3042 - accuracy: 0.8773 - val_loss: 0.6014 - val_accuracy: 0.7708\n",
            "Epoch 438/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3193 - accuracy: 0.8612 - val_loss: 0.6010 - val_accuracy: 0.7708\n",
            "Epoch 439/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3463 - accuracy: 0.8607 - val_loss: 0.6012 - val_accuracy: 0.7708\n",
            "Epoch 440/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3033 - accuracy: 0.8860 - val_loss: 0.6004 - val_accuracy: 0.7708\n",
            "Epoch 441/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3816 - accuracy: 0.8352 - val_loss: 0.6015 - val_accuracy: 0.7708\n",
            "Epoch 442/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3589 - accuracy: 0.8544 - val_loss: 0.6004 - val_accuracy: 0.7708\n",
            "Epoch 443/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3770 - accuracy: 0.8284 - val_loss: 0.6017 - val_accuracy: 0.7708\n",
            "Epoch 444/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3311 - accuracy: 0.8602 - val_loss: 0.6011 - val_accuracy: 0.7708\n",
            "Epoch 445/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3211 - accuracy: 0.8761 - val_loss: 0.6022 - val_accuracy: 0.7708\n",
            "Epoch 446/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3555 - accuracy: 0.8425 - val_loss: 0.6017 - val_accuracy: 0.7708\n",
            "Epoch 447/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3609 - accuracy: 0.8410 - val_loss: 0.6017 - val_accuracy: 0.7708\n",
            "Epoch 448/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3308 - accuracy: 0.8682 - val_loss: 0.6007 - val_accuracy: 0.7708\n",
            "Epoch 449/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3243 - accuracy: 0.8450 - val_loss: 0.6008 - val_accuracy: 0.7708\n",
            "Epoch 450/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3274 - accuracy: 0.8728 - val_loss: 0.6007 - val_accuracy: 0.7708\n",
            "Epoch 451/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3201 - accuracy: 0.8726 - val_loss: 0.6003 - val_accuracy: 0.7708\n",
            "Epoch 452/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3504 - accuracy: 0.8609 - val_loss: 0.6016 - val_accuracy: 0.7708\n",
            "Epoch 453/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3183 - accuracy: 0.8738 - val_loss: 0.6009 - val_accuracy: 0.7708\n",
            "Epoch 454/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3196 - accuracy: 0.8630 - val_loss: 0.6018 - val_accuracy: 0.7708\n",
            "Epoch 455/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3125 - accuracy: 0.8630 - val_loss: 0.6001 - val_accuracy: 0.7708\n",
            "Epoch 456/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3218 - accuracy: 0.8524 - val_loss: 0.5993 - val_accuracy: 0.7708\n",
            "Epoch 457/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3320 - accuracy: 0.8575 - val_loss: 0.6006 - val_accuracy: 0.7708\n",
            "Epoch 458/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3218 - accuracy: 0.8717 - val_loss: 0.6000 - val_accuracy: 0.7708\n",
            "Epoch 459/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3387 - accuracy: 0.8496 - val_loss: 0.6007 - val_accuracy: 0.7708\n",
            "Epoch 460/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3210 - accuracy: 0.8507 - val_loss: 0.6014 - val_accuracy: 0.7708\n",
            "Epoch 461/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3756 - accuracy: 0.8406 - val_loss: 0.6008 - val_accuracy: 0.7708\n",
            "Epoch 462/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3439 - accuracy: 0.8550 - val_loss: 0.6017 - val_accuracy: 0.7708\n",
            "Epoch 463/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3189 - accuracy: 0.8528 - val_loss: 0.6023 - val_accuracy: 0.7708\n",
            "Epoch 464/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3500 - accuracy: 0.8491 - val_loss: 0.6019 - val_accuracy: 0.7708\n",
            "Epoch 465/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3109 - accuracy: 0.8746 - val_loss: 0.5999 - val_accuracy: 0.7708\n",
            "Epoch 466/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3638 - accuracy: 0.8502 - val_loss: 0.6008 - val_accuracy: 0.7708\n",
            "Epoch 467/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3465 - accuracy: 0.8549 - val_loss: 0.6010 - val_accuracy: 0.7708\n",
            "Epoch 468/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3592 - accuracy: 0.8257 - val_loss: 0.6029 - val_accuracy: 0.7708\n",
            "Epoch 469/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3426 - accuracy: 0.8450 - val_loss: 0.6022 - val_accuracy: 0.7708\n",
            "Epoch 470/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3278 - accuracy: 0.8743 - val_loss: 0.6039 - val_accuracy: 0.7708\n",
            "Epoch 471/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3190 - accuracy: 0.8773 - val_loss: 0.6029 - val_accuracy: 0.7708\n",
            "Epoch 472/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3270 - accuracy: 0.8571 - val_loss: 0.6023 - val_accuracy: 0.7708\n",
            "Epoch 473/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3116 - accuracy: 0.8685 - val_loss: 0.6032 - val_accuracy: 0.7708\n",
            "Epoch 474/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3150 - accuracy: 0.8537 - val_loss: 0.6018 - val_accuracy: 0.7708\n",
            "Epoch 475/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3301 - accuracy: 0.8594 - val_loss: 0.6022 - val_accuracy: 0.7708\n",
            "Epoch 476/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3328 - accuracy: 0.8485 - val_loss: 0.6024 - val_accuracy: 0.7708\n",
            "Epoch 477/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3370 - accuracy: 0.8534 - val_loss: 0.5998 - val_accuracy: 0.7708\n",
            "Epoch 478/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3590 - accuracy: 0.8523 - val_loss: 0.5997 - val_accuracy: 0.7708\n",
            "Epoch 479/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3236 - accuracy: 0.8732 - val_loss: 0.6010 - val_accuracy: 0.7708\n",
            "Epoch 480/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3317 - accuracy: 0.8362 - val_loss: 0.5996 - val_accuracy: 0.7708\n",
            "Epoch 481/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3151 - accuracy: 0.8816 - val_loss: 0.6005 - val_accuracy: 0.7708\n",
            "Epoch 482/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3504 - accuracy: 0.8593 - val_loss: 0.6020 - val_accuracy: 0.7708\n",
            "Epoch 483/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3194 - accuracy: 0.8759 - val_loss: 0.6010 - val_accuracy: 0.7708\n",
            "Epoch 484/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3113 - accuracy: 0.8622 - val_loss: 0.6015 - val_accuracy: 0.7708\n",
            "Epoch 485/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3711 - accuracy: 0.8314 - val_loss: 0.6017 - val_accuracy: 0.7708\n",
            "Epoch 486/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3185 - accuracy: 0.8713 - val_loss: 0.6022 - val_accuracy: 0.7708\n",
            "Epoch 487/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3344 - accuracy: 0.8633 - val_loss: 0.6033 - val_accuracy: 0.7708\n",
            "Epoch 488/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3139 - accuracy: 0.8691 - val_loss: 0.6025 - val_accuracy: 0.7708\n",
            "Epoch 489/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3091 - accuracy: 0.8679 - val_loss: 0.6013 - val_accuracy: 0.7708\n",
            "Epoch 490/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3307 - accuracy: 0.8572 - val_loss: 0.5999 - val_accuracy: 0.7708\n",
            "Epoch 491/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3165 - accuracy: 0.8709 - val_loss: 0.6001 - val_accuracy: 0.7708\n",
            "Epoch 492/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3517 - accuracy: 0.8341 - val_loss: 0.6018 - val_accuracy: 0.7708\n",
            "Epoch 493/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3055 - accuracy: 0.8767 - val_loss: 0.6018 - val_accuracy: 0.7708\n",
            "Epoch 494/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3193 - accuracy: 0.8557 - val_loss: 0.6010 - val_accuracy: 0.7708\n",
            "Epoch 495/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3192 - accuracy: 0.8585 - val_loss: 0.6009 - val_accuracy: 0.7708\n",
            "Epoch 496/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3093 - accuracy: 0.8685 - val_loss: 0.6009 - val_accuracy: 0.7708\n",
            "Epoch 497/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2985 - accuracy: 0.8793 - val_loss: 0.6003 - val_accuracy: 0.7708\n",
            "Epoch 498/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3140 - accuracy: 0.8764 - val_loss: 0.5997 - val_accuracy: 0.7708\n",
            "Epoch 499/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3180 - accuracy: 0.8610 - val_loss: 0.5996 - val_accuracy: 0.7708\n",
            "Epoch 500/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3181 - accuracy: 0.8595 - val_loss: 0.6003 - val_accuracy: 0.7708\n",
            "Epoch 501/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2914 - accuracy: 0.8860 - val_loss: 0.5997 - val_accuracy: 0.7708\n",
            "Epoch 502/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3133 - accuracy: 0.8749 - val_loss: 0.6010 - val_accuracy: 0.7708\n",
            "Epoch 503/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3307 - accuracy: 0.8684 - val_loss: 0.6027 - val_accuracy: 0.7500\n",
            "Epoch 504/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3085 - accuracy: 0.8749 - val_loss: 0.6030 - val_accuracy: 0.7292\n",
            "Epoch 505/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3023 - accuracy: 0.8705 - val_loss: 0.6020 - val_accuracy: 0.7708\n",
            "Epoch 506/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3401 - accuracy: 0.8345 - val_loss: 0.6029 - val_accuracy: 0.7292\n",
            "Epoch 507/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3114 - accuracy: 0.8669 - val_loss: 0.6012 - val_accuracy: 0.7708\n",
            "Epoch 508/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3381 - accuracy: 0.8548 - val_loss: 0.5997 - val_accuracy: 0.7708\n",
            "Epoch 509/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3454 - accuracy: 0.8459 - val_loss: 0.6003 - val_accuracy: 0.7708\n",
            "Epoch 510/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3091 - accuracy: 0.8645 - val_loss: 0.5998 - val_accuracy: 0.7708\n",
            "Epoch 511/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2880 - accuracy: 0.8796 - val_loss: 0.6005 - val_accuracy: 0.7708\n",
            "Epoch 512/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3190 - accuracy: 0.8524 - val_loss: 0.6022 - val_accuracy: 0.7500\n",
            "Epoch 513/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3028 - accuracy: 0.8798 - val_loss: 0.6025 - val_accuracy: 0.7292\n",
            "Epoch 514/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3328 - accuracy: 0.8392 - val_loss: 0.6029 - val_accuracy: 0.7292\n",
            "Epoch 515/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3005 - accuracy: 0.8871 - val_loss: 0.6021 - val_accuracy: 0.7500\n",
            "Epoch 516/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3102 - accuracy: 0.8587 - val_loss: 0.6007 - val_accuracy: 0.7708\n",
            "Epoch 517/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3584 - accuracy: 0.8517 - val_loss: 0.6012 - val_accuracy: 0.7708\n",
            "Epoch 518/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3705 - accuracy: 0.8047 - val_loss: 0.6015 - val_accuracy: 0.7708\n",
            "Epoch 519/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3028 - accuracy: 0.8793 - val_loss: 0.6006 - val_accuracy: 0.7708\n",
            "Epoch 520/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2776 - accuracy: 0.8906 - val_loss: 0.6007 - val_accuracy: 0.7708\n",
            "Epoch 521/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3289 - accuracy: 0.8589 - val_loss: 0.5997 - val_accuracy: 0.7708\n",
            "Epoch 522/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2908 - accuracy: 0.8883 - val_loss: 0.5983 - val_accuracy: 0.7708\n",
            "Epoch 523/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3124 - accuracy: 0.8718 - val_loss: 0.5994 - val_accuracy: 0.7708\n",
            "Epoch 524/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3090 - accuracy: 0.8703 - val_loss: 0.5992 - val_accuracy: 0.7708\n",
            "Epoch 525/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3081 - accuracy: 0.8701 - val_loss: 0.6001 - val_accuracy: 0.7708\n",
            "Epoch 526/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2934 - accuracy: 0.8664 - val_loss: 0.6018 - val_accuracy: 0.7500\n",
            "Epoch 527/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3278 - accuracy: 0.8608 - val_loss: 0.6009 - val_accuracy: 0.7708\n",
            "Epoch 528/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2872 - accuracy: 0.8697 - val_loss: 0.6011 - val_accuracy: 0.7708\n",
            "Epoch 529/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3370 - accuracy: 0.8509 - val_loss: 0.6023 - val_accuracy: 0.7292\n",
            "Epoch 530/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3024 - accuracy: 0.8841 - val_loss: 0.6025 - val_accuracy: 0.7292\n",
            "Epoch 531/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3497 - accuracy: 0.8507 - val_loss: 0.6033 - val_accuracy: 0.7292\n",
            "Epoch 532/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3780 - accuracy: 0.8267 - val_loss: 0.6042 - val_accuracy: 0.7292\n",
            "Epoch 533/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3109 - accuracy: 0.8603 - val_loss: 0.6024 - val_accuracy: 0.7292\n",
            "Epoch 534/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2901 - accuracy: 0.8730 - val_loss: 0.6018 - val_accuracy: 0.7292\n",
            "Epoch 535/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2979 - accuracy: 0.8758 - val_loss: 0.6016 - val_accuracy: 0.7292\n",
            "Epoch 536/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3177 - accuracy: 0.8602 - val_loss: 0.6011 - val_accuracy: 0.7500\n",
            "Epoch 537/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3408 - accuracy: 0.8366 - val_loss: 0.6012 - val_accuracy: 0.7500\n",
            "Epoch 538/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3168 - accuracy: 0.8618 - val_loss: 0.6007 - val_accuracy: 0.7500\n",
            "Epoch 539/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3080 - accuracy: 0.8694 - val_loss: 0.6003 - val_accuracy: 0.7500\n",
            "Epoch 540/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3128 - accuracy: 0.8516 - val_loss: 0.6009 - val_accuracy: 0.7500\n",
            "Epoch 541/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2992 - accuracy: 0.8679 - val_loss: 0.6025 - val_accuracy: 0.7292\n",
            "Epoch 542/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3402 - accuracy: 0.8389 - val_loss: 0.6015 - val_accuracy: 0.7292\n",
            "Epoch 543/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3677 - accuracy: 0.8125 - val_loss: 0.6014 - val_accuracy: 0.7500\n",
            "Epoch 544/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3233 - accuracy: 0.8635 - val_loss: 0.6015 - val_accuracy: 0.7292\n",
            "Epoch 545/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2908 - accuracy: 0.8808 - val_loss: 0.5998 - val_accuracy: 0.7708\n",
            "Epoch 546/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2612 - accuracy: 0.8925 - val_loss: 0.6016 - val_accuracy: 0.7292\n",
            "Epoch 547/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2866 - accuracy: 0.8912 - val_loss: 0.6017 - val_accuracy: 0.7292\n",
            "Epoch 548/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3352 - accuracy: 0.8479 - val_loss: 0.6022 - val_accuracy: 0.7292\n",
            "Epoch 549/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3032 - accuracy: 0.8723 - val_loss: 0.6006 - val_accuracy: 0.7500\n",
            "Epoch 550/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2895 - accuracy: 0.8968 - val_loss: 0.6010 - val_accuracy: 0.7500\n",
            "Epoch 551/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3269 - accuracy: 0.8655 - val_loss: 0.6008 - val_accuracy: 0.7500\n",
            "Epoch 552/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2934 - accuracy: 0.8739 - val_loss: 0.6026 - val_accuracy: 0.7292\n",
            "Epoch 553/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3439 - accuracy: 0.8434 - val_loss: 0.6014 - val_accuracy: 0.7292\n",
            "Epoch 554/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2835 - accuracy: 0.8865 - val_loss: 0.6010 - val_accuracy: 0.7500\n",
            "Epoch 555/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3085 - accuracy: 0.8412 - val_loss: 0.5991 - val_accuracy: 0.7708\n",
            "Epoch 556/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3281 - accuracy: 0.8342 - val_loss: 0.6015 - val_accuracy: 0.7292\n",
            "Epoch 557/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3098 - accuracy: 0.8612 - val_loss: 0.6020 - val_accuracy: 0.7292\n",
            "Epoch 558/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3310 - accuracy: 0.8589 - val_loss: 0.6037 - val_accuracy: 0.7292\n",
            "Epoch 559/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3436 - accuracy: 0.8452 - val_loss: 0.6042 - val_accuracy: 0.7292\n",
            "Epoch 560/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3122 - accuracy: 0.8559 - val_loss: 0.6018 - val_accuracy: 0.7292\n",
            "Epoch 561/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3068 - accuracy: 0.8587 - val_loss: 0.6021 - val_accuracy: 0.7292\n",
            "Epoch 562/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3097 - accuracy: 0.8580 - val_loss: 0.6001 - val_accuracy: 0.7500\n",
            "Epoch 563/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3258 - accuracy: 0.8611 - val_loss: 0.6027 - val_accuracy: 0.7292\n",
            "Epoch 564/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3273 - accuracy: 0.8499 - val_loss: 0.6016 - val_accuracy: 0.7292\n",
            "Epoch 565/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3413 - accuracy: 0.8403 - val_loss: 0.5998 - val_accuracy: 0.7500\n",
            "Epoch 566/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3449 - accuracy: 0.8458 - val_loss: 0.6001 - val_accuracy: 0.7500\n",
            "Epoch 567/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3227 - accuracy: 0.8630 - val_loss: 0.5988 - val_accuracy: 0.7708\n",
            "Epoch 568/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3290 - accuracy: 0.8460 - val_loss: 0.6004 - val_accuracy: 0.7500\n",
            "Epoch 569/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3148 - accuracy: 0.8605 - val_loss: 0.6022 - val_accuracy: 0.7292\n",
            "Epoch 570/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3297 - accuracy: 0.8429 - val_loss: 0.6020 - val_accuracy: 0.7292\n",
            "Epoch 571/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3627 - accuracy: 0.8487 - val_loss: 0.6038 - val_accuracy: 0.7292\n",
            "Epoch 572/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3178 - accuracy: 0.8511 - val_loss: 0.6013 - val_accuracy: 0.7292\n",
            "Epoch 573/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3397 - accuracy: 0.8478 - val_loss: 0.6011 - val_accuracy: 0.7292\n",
            "Epoch 574/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2877 - accuracy: 0.8829 - val_loss: 0.6001 - val_accuracy: 0.7500\n",
            "Epoch 575/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2775 - accuracy: 0.8831 - val_loss: 0.5988 - val_accuracy: 0.7500\n",
            "Epoch 576/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3096 - accuracy: 0.8489 - val_loss: 0.6000 - val_accuracy: 0.7500\n",
            "Epoch 577/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3732 - accuracy: 0.8011 - val_loss: 0.6013 - val_accuracy: 0.7292\n",
            "Epoch 578/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2757 - accuracy: 0.8792 - val_loss: 0.6001 - val_accuracy: 0.7500\n",
            "Epoch 579/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2989 - accuracy: 0.8634 - val_loss: 0.5994 - val_accuracy: 0.7500\n",
            "Epoch 580/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3502 - accuracy: 0.8306 - val_loss: 0.5989 - val_accuracy: 0.7500\n",
            "Epoch 581/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2957 - accuracy: 0.8636 - val_loss: 0.5987 - val_accuracy: 0.7500\n",
            "Epoch 582/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3334 - accuracy: 0.8301 - val_loss: 0.6007 - val_accuracy: 0.7500\n",
            "Epoch 583/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3317 - accuracy: 0.8304 - val_loss: 0.6021 - val_accuracy: 0.7292\n",
            "Epoch 584/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3325 - accuracy: 0.8490 - val_loss: 0.6027 - val_accuracy: 0.7292\n",
            "Epoch 585/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2907 - accuracy: 0.8678 - val_loss: 0.6023 - val_accuracy: 0.7292\n",
            "Epoch 586/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3375 - accuracy: 0.8559 - val_loss: 0.6018 - val_accuracy: 0.7292\n",
            "Epoch 587/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3199 - accuracy: 0.8504 - val_loss: 0.6001 - val_accuracy: 0.7500\n",
            "Epoch 588/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2863 - accuracy: 0.8819 - val_loss: 0.6013 - val_accuracy: 0.7292\n",
            "Epoch 589/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3416 - accuracy: 0.8303 - val_loss: 0.6020 - val_accuracy: 0.7292\n",
            "Epoch 590/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3240 - accuracy: 0.8403 - val_loss: 0.6033 - val_accuracy: 0.7292\n",
            "Epoch 591/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3692 - accuracy: 0.8361 - val_loss: 0.6026 - val_accuracy: 0.7292\n",
            "Epoch 592/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3540 - accuracy: 0.8284 - val_loss: 0.6025 - val_accuracy: 0.7292\n",
            "Epoch 593/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3054 - accuracy: 0.8543 - val_loss: 0.6011 - val_accuracy: 0.7292\n",
            "Epoch 594/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3234 - accuracy: 0.8417 - val_loss: 0.6033 - val_accuracy: 0.7292\n",
            "Epoch 595/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2882 - accuracy: 0.8835 - val_loss: 0.6001 - val_accuracy: 0.7500\n",
            "Epoch 596/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3164 - accuracy: 0.8380 - val_loss: 0.6024 - val_accuracy: 0.7292\n",
            "Epoch 597/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2837 - accuracy: 0.8843 - val_loss: 0.6018 - val_accuracy: 0.7292\n",
            "Epoch 598/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3411 - accuracy: 0.8382 - val_loss: 0.6035 - val_accuracy: 0.7292\n",
            "Epoch 599/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2958 - accuracy: 0.8691 - val_loss: 0.6012 - val_accuracy: 0.7292\n",
            "Epoch 600/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3199 - accuracy: 0.8298 - val_loss: 0.6020 - val_accuracy: 0.7292\n",
            "Epoch 601/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3043 - accuracy: 0.8716 - val_loss: 0.6002 - val_accuracy: 0.7500\n",
            "Epoch 602/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3177 - accuracy: 0.8394 - val_loss: 0.6011 - val_accuracy: 0.7292\n",
            "Epoch 603/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2886 - accuracy: 0.8716 - val_loss: 0.6020 - val_accuracy: 0.7292\n",
            "Epoch 604/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3611 - accuracy: 0.8171 - val_loss: 0.6028 - val_accuracy: 0.7292\n",
            "Epoch 605/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3596 - accuracy: 0.8257 - val_loss: 0.6010 - val_accuracy: 0.7292\n",
            "Epoch 606/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3327 - accuracy: 0.8584 - val_loss: 0.6027 - val_accuracy: 0.7292\n",
            "Epoch 607/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2891 - accuracy: 0.8631 - val_loss: 0.6005 - val_accuracy: 0.7292\n",
            "Epoch 608/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3354 - accuracy: 0.8374 - val_loss: 0.6026 - val_accuracy: 0.7292\n",
            "Epoch 609/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3097 - accuracy: 0.8362 - val_loss: 0.6006 - val_accuracy: 0.7292\n",
            "Epoch 610/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3200 - accuracy: 0.8630 - val_loss: 0.6002 - val_accuracy: 0.7500\n",
            "Epoch 611/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3344 - accuracy: 0.8378 - val_loss: 0.6037 - val_accuracy: 0.7292\n",
            "Epoch 612/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3488 - accuracy: 0.8360 - val_loss: 0.6016 - val_accuracy: 0.7292\n",
            "Epoch 613/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3079 - accuracy: 0.8521 - val_loss: 0.6041 - val_accuracy: 0.7292\n",
            "Epoch 614/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2608 - accuracy: 0.8854 - val_loss: 0.6040 - val_accuracy: 0.7292\n",
            "Epoch 615/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3000 - accuracy: 0.8743 - val_loss: 0.6046 - val_accuracy: 0.7292\n",
            "Epoch 616/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3578 - accuracy: 0.8192 - val_loss: 0.6016 - val_accuracy: 0.7292\n",
            "Epoch 617/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3281 - accuracy: 0.8496 - val_loss: 0.6042 - val_accuracy: 0.7292\n",
            "Epoch 618/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3305 - accuracy: 0.8254 - val_loss: 0.6045 - val_accuracy: 0.7292\n",
            "Epoch 619/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3590 - accuracy: 0.8389 - val_loss: 0.6023 - val_accuracy: 0.7292\n",
            "Epoch 620/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3538 - accuracy: 0.8150 - val_loss: 0.6046 - val_accuracy: 0.7292\n",
            "Epoch 621/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3263 - accuracy: 0.8376 - val_loss: 0.6017 - val_accuracy: 0.7292\n",
            "Epoch 622/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3039 - accuracy: 0.8690 - val_loss: 0.6012 - val_accuracy: 0.7292\n",
            "Epoch 623/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3406 - accuracy: 0.8426 - val_loss: 0.6029 - val_accuracy: 0.7292\n",
            "Epoch 624/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2983 - accuracy: 0.8578 - val_loss: 0.6027 - val_accuracy: 0.7292\n",
            "Epoch 625/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3038 - accuracy: 0.8657 - val_loss: 0.6028 - val_accuracy: 0.7292\n",
            "Epoch 626/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3013 - accuracy: 0.8684 - val_loss: 0.6009 - val_accuracy: 0.7292\n",
            "Epoch 627/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3041 - accuracy: 0.8554 - val_loss: 0.6012 - val_accuracy: 0.7292\n",
            "Epoch 628/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2762 - accuracy: 0.8769 - val_loss: 0.6003 - val_accuracy: 0.7292\n",
            "Epoch 629/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3545 - accuracy: 0.8154 - val_loss: 0.6017 - val_accuracy: 0.7292\n",
            "Epoch 630/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2916 - accuracy: 0.8530 - val_loss: 0.6018 - val_accuracy: 0.7292\n",
            "Epoch 631/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3002 - accuracy: 0.8542 - val_loss: 0.6045 - val_accuracy: 0.7292\n",
            "Epoch 632/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3420 - accuracy: 0.8443 - val_loss: 0.6036 - val_accuracy: 0.7292\n",
            "Epoch 633/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2858 - accuracy: 0.8571 - val_loss: 0.6063 - val_accuracy: 0.7292\n",
            "Epoch 634/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2816 - accuracy: 0.8730 - val_loss: 0.6032 - val_accuracy: 0.7292\n",
            "Epoch 635/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3106 - accuracy: 0.8591 - val_loss: 0.6034 - val_accuracy: 0.7292\n",
            "Epoch 636/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3194 - accuracy: 0.8538 - val_loss: 0.6016 - val_accuracy: 0.7292\n",
            "Epoch 637/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2635 - accuracy: 0.8777 - val_loss: 0.5996 - val_accuracy: 0.7500\n",
            "Epoch 638/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3079 - accuracy: 0.8463 - val_loss: 0.5984 - val_accuracy: 0.7708\n",
            "Epoch 639/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2915 - accuracy: 0.8559 - val_loss: 0.6010 - val_accuracy: 0.7292\n",
            "Epoch 640/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2946 - accuracy: 0.8644 - val_loss: 0.6005 - val_accuracy: 0.7292\n",
            "Epoch 641/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3002 - accuracy: 0.8582 - val_loss: 0.6036 - val_accuracy: 0.7292\n",
            "Epoch 642/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3163 - accuracy: 0.8508 - val_loss: 0.6008 - val_accuracy: 0.7292\n",
            "Epoch 643/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3155 - accuracy: 0.8705 - val_loss: 0.6016 - val_accuracy: 0.7292\n",
            "Epoch 644/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3025 - accuracy: 0.8625 - val_loss: 0.5999 - val_accuracy: 0.7292\n",
            "Epoch 645/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3118 - accuracy: 0.8368 - val_loss: 0.6035 - val_accuracy: 0.7292\n",
            "Epoch 646/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2829 - accuracy: 0.8909 - val_loss: 0.6020 - val_accuracy: 0.7292\n",
            "Epoch 647/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3439 - accuracy: 0.8449 - val_loss: 0.6026 - val_accuracy: 0.7292\n",
            "Epoch 648/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3189 - accuracy: 0.8397 - val_loss: 0.6028 - val_accuracy: 0.7292\n",
            "Epoch 649/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2932 - accuracy: 0.8523 - val_loss: 0.6023 - val_accuracy: 0.7292\n",
            "Epoch 650/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3204 - accuracy: 0.8519 - val_loss: 0.6012 - val_accuracy: 0.7292\n",
            "Epoch 651/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3733 - accuracy: 0.8134 - val_loss: 0.6024 - val_accuracy: 0.7292\n",
            "Epoch 652/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3275 - accuracy: 0.8288 - val_loss: 0.6018 - val_accuracy: 0.7292\n",
            "Epoch 653/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3092 - accuracy: 0.8545 - val_loss: 0.6023 - val_accuracy: 0.7292\n",
            "Epoch 654/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3107 - accuracy: 0.8455 - val_loss: 0.6029 - val_accuracy: 0.7292\n",
            "Epoch 655/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3238 - accuracy: 0.8403 - val_loss: 0.6032 - val_accuracy: 0.7292\n",
            "Epoch 656/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2786 - accuracy: 0.8702 - val_loss: 0.6019 - val_accuracy: 0.7292\n",
            "Epoch 657/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2871 - accuracy: 0.8810 - val_loss: 0.6010 - val_accuracy: 0.7292\n",
            "Epoch 658/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3001 - accuracy: 0.8512 - val_loss: 0.6033 - val_accuracy: 0.7292\n",
            "Epoch 659/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3237 - accuracy: 0.8330 - val_loss: 0.6033 - val_accuracy: 0.7292\n",
            "Epoch 660/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3033 - accuracy: 0.8531 - val_loss: 0.6054 - val_accuracy: 0.7292\n",
            "Epoch 661/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3086 - accuracy: 0.8542 - val_loss: 0.6039 - val_accuracy: 0.7292\n",
            "Epoch 662/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3040 - accuracy: 0.8635 - val_loss: 0.6044 - val_accuracy: 0.7292\n",
            "Epoch 663/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3285 - accuracy: 0.8471 - val_loss: 0.6058 - val_accuracy: 0.7292\n",
            "Epoch 664/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3225 - accuracy: 0.8414 - val_loss: 0.6038 - val_accuracy: 0.7292\n",
            "Epoch 665/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3185 - accuracy: 0.8501 - val_loss: 0.6051 - val_accuracy: 0.7292\n",
            "Epoch 666/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2853 - accuracy: 0.8711 - val_loss: 0.6048 - val_accuracy: 0.7292\n",
            "Epoch 667/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2762 - accuracy: 0.8706 - val_loss: 0.6048 - val_accuracy: 0.7292\n",
            "Epoch 668/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3480 - accuracy: 0.8227 - val_loss: 0.6036 - val_accuracy: 0.7292\n",
            "Epoch 669/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2820 - accuracy: 0.8766 - val_loss: 0.6045 - val_accuracy: 0.7292\n",
            "Epoch 670/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2756 - accuracy: 0.8720 - val_loss: 0.6052 - val_accuracy: 0.7292\n",
            "Epoch 671/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2998 - accuracy: 0.8583 - val_loss: 0.6044 - val_accuracy: 0.7292\n",
            "Epoch 672/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3075 - accuracy: 0.8378 - val_loss: 0.6025 - val_accuracy: 0.7292\n",
            "Epoch 673/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3116 - accuracy: 0.8562 - val_loss: 0.6015 - val_accuracy: 0.7500\n",
            "Epoch 674/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2902 - accuracy: 0.8598 - val_loss: 0.6025 - val_accuracy: 0.7292\n",
            "Epoch 675/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2894 - accuracy: 0.8670 - val_loss: 0.6047 - val_accuracy: 0.7292\n",
            "Epoch 676/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2945 - accuracy: 0.8666 - val_loss: 0.6016 - val_accuracy: 0.7500\n",
            "Epoch 677/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3198 - accuracy: 0.8431 - val_loss: 0.6052 - val_accuracy: 0.7292\n",
            "Epoch 678/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2805 - accuracy: 0.8746 - val_loss: 0.6023 - val_accuracy: 0.7500\n",
            "Epoch 679/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3130 - accuracy: 0.8465 - val_loss: 0.6048 - val_accuracy: 0.7292\n",
            "Epoch 680/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3370 - accuracy: 0.8294 - val_loss: 0.6045 - val_accuracy: 0.7292\n",
            "Epoch 681/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2892 - accuracy: 0.8634 - val_loss: 0.6043 - val_accuracy: 0.7292\n",
            "Epoch 682/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2947 - accuracy: 0.8629 - val_loss: 0.6041 - val_accuracy: 0.7292\n",
            "Epoch 683/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3092 - accuracy: 0.8580 - val_loss: 0.6021 - val_accuracy: 0.7500\n",
            "Epoch 684/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3394 - accuracy: 0.8147 - val_loss: 0.6054 - val_accuracy: 0.7292\n",
            "Epoch 685/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3063 - accuracy: 0.8414 - val_loss: 0.6076 - val_accuracy: 0.7292\n",
            "Epoch 686/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2922 - accuracy: 0.8511 - val_loss: 0.6043 - val_accuracy: 0.7292\n",
            "Epoch 687/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3065 - accuracy: 0.8337 - val_loss: 0.6037 - val_accuracy: 0.7292\n",
            "Epoch 688/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3376 - accuracy: 0.8403 - val_loss: 0.6050 - val_accuracy: 0.7292\n",
            "Epoch 689/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2887 - accuracy: 0.8666 - val_loss: 0.6046 - val_accuracy: 0.7292\n",
            "Epoch 690/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2955 - accuracy: 0.8632 - val_loss: 0.6068 - val_accuracy: 0.7292\n",
            "Epoch 691/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3303 - accuracy: 0.8607 - val_loss: 0.6050 - val_accuracy: 0.7292\n",
            "Epoch 692/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2939 - accuracy: 0.8464 - val_loss: 0.6035 - val_accuracy: 0.7500\n",
            "Epoch 693/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2987 - accuracy: 0.8515 - val_loss: 0.6030 - val_accuracy: 0.7500\n",
            "Epoch 694/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2885 - accuracy: 0.8628 - val_loss: 0.6048 - val_accuracy: 0.7292\n",
            "Epoch 695/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2853 - accuracy: 0.8822 - val_loss: 0.6043 - val_accuracy: 0.7500\n",
            "Epoch 696/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3010 - accuracy: 0.8569 - val_loss: 0.6048 - val_accuracy: 0.7500\n",
            "Epoch 697/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3178 - accuracy: 0.8357 - val_loss: 0.6024 - val_accuracy: 0.7500\n",
            "Epoch 698/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2975 - accuracy: 0.8609 - val_loss: 0.6038 - val_accuracy: 0.7500\n",
            "Epoch 699/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3240 - accuracy: 0.8551 - val_loss: 0.6045 - val_accuracy: 0.7500\n",
            "Epoch 700/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2934 - accuracy: 0.8468 - val_loss: 0.6031 - val_accuracy: 0.7500\n",
            "Epoch 701/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3163 - accuracy: 0.8450 - val_loss: 0.6038 - val_accuracy: 0.7500\n",
            "Epoch 702/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3118 - accuracy: 0.8531 - val_loss: 0.6048 - val_accuracy: 0.7500\n",
            "Epoch 703/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3032 - accuracy: 0.8470 - val_loss: 0.6066 - val_accuracy: 0.7292\n",
            "Epoch 704/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3034 - accuracy: 0.8493 - val_loss: 0.6085 - val_accuracy: 0.7292\n",
            "Epoch 705/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3202 - accuracy: 0.8545 - val_loss: 0.6089 - val_accuracy: 0.7292\n",
            "Epoch 706/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3096 - accuracy: 0.8510 - val_loss: 0.6056 - val_accuracy: 0.7500\n",
            "Epoch 707/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3050 - accuracy: 0.8429 - val_loss: 0.6076 - val_accuracy: 0.7292\n",
            "Epoch 708/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2915 - accuracy: 0.8615 - val_loss: 0.6051 - val_accuracy: 0.7500\n",
            "Epoch 709/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3363 - accuracy: 0.8262 - val_loss: 0.6046 - val_accuracy: 0.7500\n",
            "Epoch 710/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2995 - accuracy: 0.8635 - val_loss: 0.6019 - val_accuracy: 0.7708\n",
            "Epoch 711/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3141 - accuracy: 0.8443 - val_loss: 0.6039 - val_accuracy: 0.7500\n",
            "Epoch 712/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2561 - accuracy: 0.8944 - val_loss: 0.6039 - val_accuracy: 0.7500\n",
            "Epoch 713/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3204 - accuracy: 0.8330 - val_loss: 0.6060 - val_accuracy: 0.7500\n",
            "Epoch 714/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3234 - accuracy: 0.8455 - val_loss: 0.6085 - val_accuracy: 0.7292\n",
            "Epoch 715/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3320 - accuracy: 0.8394 - val_loss: 0.6050 - val_accuracy: 0.7500\n",
            "Epoch 716/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2944 - accuracy: 0.8403 - val_loss: 0.6036 - val_accuracy: 0.7500\n",
            "Epoch 717/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3521 - accuracy: 0.8162 - val_loss: 0.6091 - val_accuracy: 0.7292\n",
            "Epoch 718/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2849 - accuracy: 0.8667 - val_loss: 0.6039 - val_accuracy: 0.7500\n",
            "Epoch 719/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2794 - accuracy: 0.8701 - val_loss: 0.6040 - val_accuracy: 0.7500\n",
            "Epoch 720/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3145 - accuracy: 0.8524 - val_loss: 0.6070 - val_accuracy: 0.7500\n",
            "Epoch 721/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2847 - accuracy: 0.8684 - val_loss: 0.6088 - val_accuracy: 0.7292\n",
            "Epoch 722/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2919 - accuracy: 0.8692 - val_loss: 0.6022 - val_accuracy: 0.7708\n",
            "Epoch 723/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3125 - accuracy: 0.8388 - val_loss: 0.6049 - val_accuracy: 0.7500\n",
            "Epoch 724/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3014 - accuracy: 0.8568 - val_loss: 0.6047 - val_accuracy: 0.7500\n",
            "Epoch 725/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3177 - accuracy: 0.8486 - val_loss: 0.6045 - val_accuracy: 0.7500\n",
            "Epoch 726/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2965 - accuracy: 0.8604 - val_loss: 0.6032 - val_accuracy: 0.7708\n",
            "Epoch 727/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2984 - accuracy: 0.8548 - val_loss: 0.6065 - val_accuracy: 0.7500\n",
            "Epoch 728/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2855 - accuracy: 0.8577 - val_loss: 0.6040 - val_accuracy: 0.7500\n",
            "Epoch 729/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2995 - accuracy: 0.8464 - val_loss: 0.6093 - val_accuracy: 0.7292\n",
            "Epoch 730/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3491 - accuracy: 0.8184 - val_loss: 0.6095 - val_accuracy: 0.7292\n",
            "Epoch 731/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3320 - accuracy: 0.8199 - val_loss: 0.6116 - val_accuracy: 0.7292\n",
            "Epoch 732/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3313 - accuracy: 0.8271 - val_loss: 0.6118 - val_accuracy: 0.7292\n",
            "Epoch 733/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2906 - accuracy: 0.8805 - val_loss: 0.6074 - val_accuracy: 0.7500\n",
            "Epoch 734/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3174 - accuracy: 0.8470 - val_loss: 0.6095 - val_accuracy: 0.7292\n",
            "Epoch 735/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3215 - accuracy: 0.8407 - val_loss: 0.6083 - val_accuracy: 0.7500\n",
            "Epoch 736/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2985 - accuracy: 0.8651 - val_loss: 0.6074 - val_accuracy: 0.7500\n",
            "Epoch 737/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3432 - accuracy: 0.8203 - val_loss: 0.6053 - val_accuracy: 0.7500\n",
            "Epoch 738/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3299 - accuracy: 0.8383 - val_loss: 0.6112 - val_accuracy: 0.7292\n",
            "Epoch 739/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3360 - accuracy: 0.8387 - val_loss: 0.6060 - val_accuracy: 0.7500\n",
            "Epoch 740/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3580 - accuracy: 0.7905 - val_loss: 0.6051 - val_accuracy: 0.7708\n",
            "Epoch 741/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3341 - accuracy: 0.8353 - val_loss: 0.6055 - val_accuracy: 0.7708\n",
            "Epoch 742/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2929 - accuracy: 0.8619 - val_loss: 0.6061 - val_accuracy: 0.7500\n",
            "Epoch 743/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3117 - accuracy: 0.8457 - val_loss: 0.6061 - val_accuracy: 0.7500\n",
            "Epoch 744/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2787 - accuracy: 0.8598 - val_loss: 0.6066 - val_accuracy: 0.7500\n",
            "Epoch 745/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2941 - accuracy: 0.8635 - val_loss: 0.6055 - val_accuracy: 0.7708\n",
            "Epoch 746/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3016 - accuracy: 0.8283 - val_loss: 0.6055 - val_accuracy: 0.7708\n",
            "Epoch 747/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3400 - accuracy: 0.8231 - val_loss: 0.6056 - val_accuracy: 0.7708\n",
            "Epoch 748/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3066 - accuracy: 0.8574 - val_loss: 0.6070 - val_accuracy: 0.7500\n",
            "Epoch 749/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3064 - accuracy: 0.8342 - val_loss: 0.6049 - val_accuracy: 0.7708\n",
            "Epoch 750/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2922 - accuracy: 0.8724 - val_loss: 0.6050 - val_accuracy: 0.7708\n",
            "Epoch 751/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3129 - accuracy: 0.8347 - val_loss: 0.6057 - val_accuracy: 0.7708\n",
            "Epoch 752/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3037 - accuracy: 0.8595 - val_loss: 0.6034 - val_accuracy: 0.7708\n",
            "Epoch 753/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3045 - accuracy: 0.8591 - val_loss: 0.6066 - val_accuracy: 0.7500\n",
            "Epoch 754/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2937 - accuracy: 0.8663 - val_loss: 0.6076 - val_accuracy: 0.7500\n",
            "Epoch 755/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3464 - accuracy: 0.8268 - val_loss: 0.6086 - val_accuracy: 0.7500\n",
            "Epoch 756/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3605 - accuracy: 0.8139 - val_loss: 0.6070 - val_accuracy: 0.7500\n",
            "Epoch 757/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2916 - accuracy: 0.8474 - val_loss: 0.6061 - val_accuracy: 0.7708\n",
            "Epoch 758/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2795 - accuracy: 0.8670 - val_loss: 0.6071 - val_accuracy: 0.7708\n",
            "Epoch 759/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3022 - accuracy: 0.8608 - val_loss: 0.6114 - val_accuracy: 0.7500\n",
            "Epoch 760/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2679 - accuracy: 0.8762 - val_loss: 0.6115 - val_accuracy: 0.7500\n",
            "Epoch 761/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3123 - accuracy: 0.8568 - val_loss: 0.6114 - val_accuracy: 0.7500\n",
            "Epoch 762/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2685 - accuracy: 0.8691 - val_loss: 0.6132 - val_accuracy: 0.7292\n",
            "Epoch 763/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3162 - accuracy: 0.8467 - val_loss: 0.6125 - val_accuracy: 0.7500\n",
            "Epoch 764/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2995 - accuracy: 0.8493 - val_loss: 0.6127 - val_accuracy: 0.7292\n",
            "Epoch 765/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2965 - accuracy: 0.8361 - val_loss: 0.6094 - val_accuracy: 0.7500\n",
            "Epoch 766/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2904 - accuracy: 0.8662 - val_loss: 0.6056 - val_accuracy: 0.7708\n",
            "Epoch 767/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2893 - accuracy: 0.8530 - val_loss: 0.6054 - val_accuracy: 0.7708\n",
            "Epoch 768/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2900 - accuracy: 0.8697 - val_loss: 0.6078 - val_accuracy: 0.7708\n",
            "Epoch 769/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2941 - accuracy: 0.8455 - val_loss: 0.6058 - val_accuracy: 0.7708\n",
            "Epoch 770/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2861 - accuracy: 0.8641 - val_loss: 0.6066 - val_accuracy: 0.7708\n",
            "Epoch 771/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2910 - accuracy: 0.8539 - val_loss: 0.6044 - val_accuracy: 0.7708\n",
            "Epoch 772/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3244 - accuracy: 0.8518 - val_loss: 0.6084 - val_accuracy: 0.7500\n",
            "Epoch 773/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2756 - accuracy: 0.8526 - val_loss: 0.6096 - val_accuracy: 0.7500\n",
            "Epoch 774/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2871 - accuracy: 0.8561 - val_loss: 0.6094 - val_accuracy: 0.7500\n",
            "Epoch 775/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2766 - accuracy: 0.8784 - val_loss: 0.6105 - val_accuracy: 0.7500\n",
            "Epoch 776/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3187 - accuracy: 0.8556 - val_loss: 0.6129 - val_accuracy: 0.7500\n",
            "Epoch 777/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3047 - accuracy: 0.8624 - val_loss: 0.6132 - val_accuracy: 0.7500\n",
            "Epoch 778/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2428 - accuracy: 0.8946 - val_loss: 0.6083 - val_accuracy: 0.7708\n",
            "Epoch 779/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3305 - accuracy: 0.8556 - val_loss: 0.6125 - val_accuracy: 0.7500\n",
            "Epoch 780/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3337 - accuracy: 0.8379 - val_loss: 0.6117 - val_accuracy: 0.7500\n",
            "Epoch 781/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2935 - accuracy: 0.8441 - val_loss: 0.6118 - val_accuracy: 0.7500\n",
            "Epoch 782/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2865 - accuracy: 0.8664 - val_loss: 0.6064 - val_accuracy: 0.7708\n",
            "Epoch 783/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2839 - accuracy: 0.8597 - val_loss: 0.6074 - val_accuracy: 0.7708\n",
            "Epoch 784/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2898 - accuracy: 0.8694 - val_loss: 0.6082 - val_accuracy: 0.7708\n",
            "Epoch 785/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3370 - accuracy: 0.8473 - val_loss: 0.6108 - val_accuracy: 0.7500\n",
            "Epoch 786/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3260 - accuracy: 0.8504 - val_loss: 0.6106 - val_accuracy: 0.7500\n",
            "Epoch 787/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3080 - accuracy: 0.8675 - val_loss: 0.6127 - val_accuracy: 0.7500\n",
            "Epoch 788/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3169 - accuracy: 0.8528 - val_loss: 0.6132 - val_accuracy: 0.7500\n",
            "Epoch 789/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3147 - accuracy: 0.8508 - val_loss: 0.6128 - val_accuracy: 0.7500\n",
            "Epoch 790/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3028 - accuracy: 0.8609 - val_loss: 0.6105 - val_accuracy: 0.7500\n",
            "Epoch 791/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3168 - accuracy: 0.8433 - val_loss: 0.6067 - val_accuracy: 0.7708\n",
            "Epoch 792/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3334 - accuracy: 0.8377 - val_loss: 0.6105 - val_accuracy: 0.7708\n",
            "Epoch 793/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2952 - accuracy: 0.8525 - val_loss: 0.6078 - val_accuracy: 0.7708\n",
            "Epoch 794/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2702 - accuracy: 0.8695 - val_loss: 0.6127 - val_accuracy: 0.7500\n",
            "Epoch 795/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2925 - accuracy: 0.8617 - val_loss: 0.6117 - val_accuracy: 0.7500\n",
            "Epoch 796/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2738 - accuracy: 0.8723 - val_loss: 0.6120 - val_accuracy: 0.7500\n",
            "Epoch 797/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3026 - accuracy: 0.8500 - val_loss: 0.6114 - val_accuracy: 0.7708\n",
            "Epoch 798/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3017 - accuracy: 0.8576 - val_loss: 0.6136 - val_accuracy: 0.7500\n",
            "Epoch 799/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2772 - accuracy: 0.8748 - val_loss: 0.6094 - val_accuracy: 0.7708\n",
            "Epoch 800/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2874 - accuracy: 0.8689 - val_loss: 0.6096 - val_accuracy: 0.7708\n",
            "Epoch 801/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3054 - accuracy: 0.8634 - val_loss: 0.6109 - val_accuracy: 0.7708\n",
            "Epoch 802/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3033 - accuracy: 0.8596 - val_loss: 0.6142 - val_accuracy: 0.7500\n",
            "Epoch 803/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3186 - accuracy: 0.8345 - val_loss: 0.6139 - val_accuracy: 0.7500\n",
            "Epoch 804/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2956 - accuracy: 0.8399 - val_loss: 0.6135 - val_accuracy: 0.7500\n",
            "Epoch 805/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2598 - accuracy: 0.8857 - val_loss: 0.6100 - val_accuracy: 0.7708\n",
            "Epoch 806/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3012 - accuracy: 0.8736 - val_loss: 0.6105 - val_accuracy: 0.7708\n",
            "Epoch 807/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2816 - accuracy: 0.8721 - val_loss: 0.6092 - val_accuracy: 0.7708\n",
            "Epoch 808/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2624 - accuracy: 0.8813 - val_loss: 0.6076 - val_accuracy: 0.7708\n",
            "Epoch 809/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3344 - accuracy: 0.8356 - val_loss: 0.6098 - val_accuracy: 0.7708\n",
            "Epoch 810/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3009 - accuracy: 0.8695 - val_loss: 0.6140 - val_accuracy: 0.7500\n",
            "Epoch 811/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3168 - accuracy: 0.8622 - val_loss: 0.6097 - val_accuracy: 0.7708\n",
            "Epoch 812/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3334 - accuracy: 0.8452 - val_loss: 0.6116 - val_accuracy: 0.7708\n",
            "Epoch 813/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3073 - accuracy: 0.8461 - val_loss: 0.6096 - val_accuracy: 0.7708\n",
            "Epoch 814/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3405 - accuracy: 0.8277 - val_loss: 0.6135 - val_accuracy: 0.7708\n",
            "Epoch 815/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3322 - accuracy: 0.8218 - val_loss: 0.6124 - val_accuracy: 0.7708\n",
            "Epoch 816/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2971 - accuracy: 0.8618 - val_loss: 0.6124 - val_accuracy: 0.7708\n",
            "Epoch 817/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3088 - accuracy: 0.8602 - val_loss: 0.6088 - val_accuracy: 0.7708\n",
            "Epoch 818/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3112 - accuracy: 0.8384 - val_loss: 0.6103 - val_accuracy: 0.7708\n",
            "Epoch 819/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3078 - accuracy: 0.8637 - val_loss: 0.6148 - val_accuracy: 0.7500\n",
            "Epoch 820/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2941 - accuracy: 0.8624 - val_loss: 0.6129 - val_accuracy: 0.7708\n",
            "Epoch 821/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2616 - accuracy: 0.8669 - val_loss: 0.6170 - val_accuracy: 0.7500\n",
            "Epoch 822/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2678 - accuracy: 0.8827 - val_loss: 0.6125 - val_accuracy: 0.7708\n",
            "Epoch 823/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3134 - accuracy: 0.8623 - val_loss: 0.6159 - val_accuracy: 0.7500\n",
            "Epoch 824/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3361 - accuracy: 0.8255 - val_loss: 0.6165 - val_accuracy: 0.7500\n",
            "Epoch 825/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3198 - accuracy: 0.8310 - val_loss: 0.6147 - val_accuracy: 0.7708\n",
            "Epoch 826/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2648 - accuracy: 0.8679 - val_loss: 0.6107 - val_accuracy: 0.7708\n",
            "Epoch 827/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2586 - accuracy: 0.8994 - val_loss: 0.6137 - val_accuracy: 0.7708\n",
            "Epoch 828/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3207 - accuracy: 0.8617 - val_loss: 0.6149 - val_accuracy: 0.7708\n",
            "Epoch 829/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2707 - accuracy: 0.8662 - val_loss: 0.6113 - val_accuracy: 0.7708\n",
            "Epoch 830/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3053 - accuracy: 0.8576 - val_loss: 0.6166 - val_accuracy: 0.7500\n",
            "Epoch 831/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2785 - accuracy: 0.8672 - val_loss: 0.6110 - val_accuracy: 0.7708\n",
            "Epoch 832/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2892 - accuracy: 0.8828 - val_loss: 0.6144 - val_accuracy: 0.7708\n",
            "Epoch 833/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3131 - accuracy: 0.8472 - val_loss: 0.6112 - val_accuracy: 0.7708\n",
            "Epoch 834/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3218 - accuracy: 0.8332 - val_loss: 0.6126 - val_accuracy: 0.7708\n",
            "Epoch 835/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3197 - accuracy: 0.8420 - val_loss: 0.6125 - val_accuracy: 0.7708\n",
            "Epoch 836/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2769 - accuracy: 0.8705 - val_loss: 0.6124 - val_accuracy: 0.7708\n",
            "Epoch 837/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2892 - accuracy: 0.8624 - val_loss: 0.6149 - val_accuracy: 0.7708\n",
            "Epoch 838/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2683 - accuracy: 0.8723 - val_loss: 0.6164 - val_accuracy: 0.7708\n",
            "Epoch 839/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3035 - accuracy: 0.8580 - val_loss: 0.6128 - val_accuracy: 0.7708\n",
            "Epoch 840/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3132 - accuracy: 0.8432 - val_loss: 0.6128 - val_accuracy: 0.7708\n",
            "Epoch 841/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2930 - accuracy: 0.8743 - val_loss: 0.6153 - val_accuracy: 0.7708\n",
            "Epoch 842/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3497 - accuracy: 0.8247 - val_loss: 0.6174 - val_accuracy: 0.7708\n",
            "Epoch 843/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3639 - accuracy: 0.8270 - val_loss: 0.6170 - val_accuracy: 0.7708\n",
            "Epoch 844/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3238 - accuracy: 0.8570 - val_loss: 0.6162 - val_accuracy: 0.7708\n",
            "Epoch 845/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3264 - accuracy: 0.8430 - val_loss: 0.6168 - val_accuracy: 0.7708\n",
            "Epoch 846/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3230 - accuracy: 0.8406 - val_loss: 0.6165 - val_accuracy: 0.7708\n",
            "Epoch 847/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2633 - accuracy: 0.8878 - val_loss: 0.6137 - val_accuracy: 0.7708\n",
            "Epoch 848/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3119 - accuracy: 0.8492 - val_loss: 0.6126 - val_accuracy: 0.7708\n",
            "Epoch 849/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2943 - accuracy: 0.8677 - val_loss: 0.6141 - val_accuracy: 0.7708\n",
            "Epoch 850/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3289 - accuracy: 0.8450 - val_loss: 0.6168 - val_accuracy: 0.7708\n",
            "Epoch 851/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2909 - accuracy: 0.8738 - val_loss: 0.6176 - val_accuracy: 0.7708\n",
            "Epoch 852/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3082 - accuracy: 0.8506 - val_loss: 0.6166 - val_accuracy: 0.7708\n",
            "Epoch 853/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2584 - accuracy: 0.8863 - val_loss: 0.6166 - val_accuracy: 0.7708\n",
            "Epoch 854/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2639 - accuracy: 0.8782 - val_loss: 0.6129 - val_accuracy: 0.7708\n",
            "Epoch 855/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2854 - accuracy: 0.8658 - val_loss: 0.6155 - val_accuracy: 0.7708\n",
            "Epoch 856/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2925 - accuracy: 0.8611 - val_loss: 0.6142 - val_accuracy: 0.7708\n",
            "Epoch 857/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2797 - accuracy: 0.8698 - val_loss: 0.6152 - val_accuracy: 0.7708\n",
            "Epoch 858/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3198 - accuracy: 0.8502 - val_loss: 0.6216 - val_accuracy: 0.7500\n",
            "Epoch 859/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3078 - accuracy: 0.8604 - val_loss: 0.6211 - val_accuracy: 0.7500\n",
            "Epoch 860/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3022 - accuracy: 0.8639 - val_loss: 0.6172 - val_accuracy: 0.7708\n",
            "Epoch 861/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3290 - accuracy: 0.8301 - val_loss: 0.6159 - val_accuracy: 0.7708\n",
            "Epoch 862/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3022 - accuracy: 0.8546 - val_loss: 0.6129 - val_accuracy: 0.7708\n",
            "Epoch 863/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2711 - accuracy: 0.8745 - val_loss: 0.6118 - val_accuracy: 0.7708\n",
            "Epoch 864/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3102 - accuracy: 0.8423 - val_loss: 0.6132 - val_accuracy: 0.7708\n",
            "Epoch 865/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2910 - accuracy: 0.8522 - val_loss: 0.6113 - val_accuracy: 0.7708\n",
            "Epoch 866/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3108 - accuracy: 0.8629 - val_loss: 0.6154 - val_accuracy: 0.7708\n",
            "Epoch 867/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3365 - accuracy: 0.8290 - val_loss: 0.6164 - val_accuracy: 0.7708\n",
            "Epoch 868/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2939 - accuracy: 0.8760 - val_loss: 0.6174 - val_accuracy: 0.7708\n",
            "Epoch 869/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3138 - accuracy: 0.8618 - val_loss: 0.6212 - val_accuracy: 0.7500\n",
            "Epoch 870/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3103 - accuracy: 0.8401 - val_loss: 0.6188 - val_accuracy: 0.7708\n",
            "Epoch 871/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3172 - accuracy: 0.8458 - val_loss: 0.6175 - val_accuracy: 0.7708\n",
            "Epoch 872/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2909 - accuracy: 0.8661 - val_loss: 0.6144 - val_accuracy: 0.7708\n",
            "Epoch 873/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3244 - accuracy: 0.8416 - val_loss: 0.6176 - val_accuracy: 0.7708\n",
            "Epoch 874/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2635 - accuracy: 0.8865 - val_loss: 0.6142 - val_accuracy: 0.7708\n",
            "Epoch 875/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2710 - accuracy: 0.8787 - val_loss: 0.6176 - val_accuracy: 0.7708\n",
            "Epoch 876/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2919 - accuracy: 0.8847 - val_loss: 0.6210 - val_accuracy: 0.7708\n",
            "Epoch 877/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3017 - accuracy: 0.8529 - val_loss: 0.6182 - val_accuracy: 0.7708\n",
            "Epoch 878/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2905 - accuracy: 0.8662 - val_loss: 0.6172 - val_accuracy: 0.7708\n",
            "Epoch 879/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3140 - accuracy: 0.8459 - val_loss: 0.6161 - val_accuracy: 0.7708\n",
            "Epoch 880/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3175 - accuracy: 0.8434 - val_loss: 0.6171 - val_accuracy: 0.7708\n",
            "Epoch 881/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2788 - accuracy: 0.8750 - val_loss: 0.6195 - val_accuracy: 0.7708\n",
            "Epoch 882/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2868 - accuracy: 0.8824 - val_loss: 0.6248 - val_accuracy: 0.7500\n",
            "Epoch 883/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3178 - accuracy: 0.8191 - val_loss: 0.6179 - val_accuracy: 0.7708\n",
            "Epoch 884/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2624 - accuracy: 0.8965 - val_loss: 0.6182 - val_accuracy: 0.7708\n",
            "Epoch 885/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2698 - accuracy: 0.8743 - val_loss: 0.6201 - val_accuracy: 0.7708\n",
            "Epoch 886/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3337 - accuracy: 0.8528 - val_loss: 0.6214 - val_accuracy: 0.7708\n",
            "Epoch 887/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3145 - accuracy: 0.8481 - val_loss: 0.6218 - val_accuracy: 0.7708\n",
            "Epoch 888/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2869 - accuracy: 0.8609 - val_loss: 0.6158 - val_accuracy: 0.7708\n",
            "Epoch 889/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3119 - accuracy: 0.8522 - val_loss: 0.6196 - val_accuracy: 0.7708\n",
            "Epoch 890/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2918 - accuracy: 0.8417 - val_loss: 0.6164 - val_accuracy: 0.7708\n",
            "Epoch 891/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2676 - accuracy: 0.8860 - val_loss: 0.6188 - val_accuracy: 0.7708\n",
            "Epoch 892/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2612 - accuracy: 0.8825 - val_loss: 0.6175 - val_accuracy: 0.7708\n",
            "Epoch 893/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2913 - accuracy: 0.8544 - val_loss: 0.6191 - val_accuracy: 0.7708\n",
            "Epoch 894/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2741 - accuracy: 0.8581 - val_loss: 0.6186 - val_accuracy: 0.7708\n",
            "Epoch 895/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3321 - accuracy: 0.8370 - val_loss: 0.6189 - val_accuracy: 0.7708\n",
            "Epoch 896/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2888 - accuracy: 0.8568 - val_loss: 0.6173 - val_accuracy: 0.7708\n",
            "Epoch 897/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2723 - accuracy: 0.8638 - val_loss: 0.6202 - val_accuracy: 0.7708\n",
            "Epoch 898/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2658 - accuracy: 0.8717 - val_loss: 0.6180 - val_accuracy: 0.7708\n",
            "Epoch 899/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2853 - accuracy: 0.8656 - val_loss: 0.6161 - val_accuracy: 0.7708\n",
            "Epoch 900/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2802 - accuracy: 0.8757 - val_loss: 0.6192 - val_accuracy: 0.7708\n",
            "Epoch 901/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2657 - accuracy: 0.8812 - val_loss: 0.6198 - val_accuracy: 0.7708\n",
            "Epoch 902/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2572 - accuracy: 0.8866 - val_loss: 0.6187 - val_accuracy: 0.7708\n",
            "Epoch 903/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3211 - accuracy: 0.8325 - val_loss: 0.6236 - val_accuracy: 0.7708\n",
            "Epoch 904/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2861 - accuracy: 0.8697 - val_loss: 0.6175 - val_accuracy: 0.7708\n",
            "Epoch 905/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2875 - accuracy: 0.8667 - val_loss: 0.6227 - val_accuracy: 0.7708\n",
            "Epoch 906/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3002 - accuracy: 0.8487 - val_loss: 0.6180 - val_accuracy: 0.7708\n",
            "Epoch 907/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3388 - accuracy: 0.8251 - val_loss: 0.6214 - val_accuracy: 0.7708\n",
            "Epoch 908/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2583 - accuracy: 0.8868 - val_loss: 0.6210 - val_accuracy: 0.7708\n",
            "Epoch 909/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2860 - accuracy: 0.8785 - val_loss: 0.6165 - val_accuracy: 0.7708\n",
            "Epoch 910/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3149 - accuracy: 0.8430 - val_loss: 0.6184 - val_accuracy: 0.7708\n",
            "Epoch 911/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3029 - accuracy: 0.8473 - val_loss: 0.6156 - val_accuracy: 0.7708\n",
            "Epoch 912/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2731 - accuracy: 0.8816 - val_loss: 0.6180 - val_accuracy: 0.7708\n",
            "Epoch 913/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2763 - accuracy: 0.8678 - val_loss: 0.6127 - val_accuracy: 0.7708\n",
            "Epoch 914/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3109 - accuracy: 0.8461 - val_loss: 0.6152 - val_accuracy: 0.7708\n",
            "Epoch 915/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3088 - accuracy: 0.8592 - val_loss: 0.6173 - val_accuracy: 0.7708\n",
            "Epoch 916/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2853 - accuracy: 0.8492 - val_loss: 0.6230 - val_accuracy: 0.7708\n",
            "Epoch 917/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2892 - accuracy: 0.8854 - val_loss: 0.6253 - val_accuracy: 0.7708\n",
            "Epoch 918/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2701 - accuracy: 0.8860 - val_loss: 0.6211 - val_accuracy: 0.7708\n",
            "Epoch 919/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2803 - accuracy: 0.8663 - val_loss: 0.6243 - val_accuracy: 0.7708\n",
            "Epoch 920/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2912 - accuracy: 0.8774 - val_loss: 0.6226 - val_accuracy: 0.7708\n",
            "Epoch 921/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3097 - accuracy: 0.8526 - val_loss: 0.6277 - val_accuracy: 0.7500\n",
            "Epoch 922/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3497 - accuracy: 0.8273 - val_loss: 0.6237 - val_accuracy: 0.7708\n",
            "Epoch 923/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2696 - accuracy: 0.8633 - val_loss: 0.6240 - val_accuracy: 0.7708\n",
            "Epoch 924/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2949 - accuracy: 0.8672 - val_loss: 0.6222 - val_accuracy: 0.7708\n",
            "Epoch 925/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3127 - accuracy: 0.8550 - val_loss: 0.6230 - val_accuracy: 0.7708\n",
            "Epoch 926/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3157 - accuracy: 0.8322 - val_loss: 0.6197 - val_accuracy: 0.7708\n",
            "Epoch 927/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3156 - accuracy: 0.8445 - val_loss: 0.6210 - val_accuracy: 0.7708\n",
            "Epoch 928/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2772 - accuracy: 0.8800 - val_loss: 0.6222 - val_accuracy: 0.7708\n",
            "Epoch 929/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2803 - accuracy: 0.8743 - val_loss: 0.6245 - val_accuracy: 0.7708\n",
            "Epoch 930/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2886 - accuracy: 0.8600 - val_loss: 0.6265 - val_accuracy: 0.7708\n",
            "Epoch 931/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2687 - accuracy: 0.8743 - val_loss: 0.6199 - val_accuracy: 0.7708\n",
            "Epoch 932/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2712 - accuracy: 0.8941 - val_loss: 0.6200 - val_accuracy: 0.7708\n",
            "Epoch 933/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2822 - accuracy: 0.8681 - val_loss: 0.6205 - val_accuracy: 0.7708\n",
            "Epoch 934/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2518 - accuracy: 0.8790 - val_loss: 0.6229 - val_accuracy: 0.7708\n",
            "Epoch 935/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2951 - accuracy: 0.8711 - val_loss: 0.6233 - val_accuracy: 0.7708\n",
            "Epoch 936/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3020 - accuracy: 0.8531 - val_loss: 0.6203 - val_accuracy: 0.7708\n",
            "Epoch 937/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2740 - accuracy: 0.8741 - val_loss: 0.6245 - val_accuracy: 0.7708\n",
            "Epoch 938/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2993 - accuracy: 0.8683 - val_loss: 0.6254 - val_accuracy: 0.7708\n",
            "Epoch 939/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2853 - accuracy: 0.8712 - val_loss: 0.6253 - val_accuracy: 0.7708\n",
            "Epoch 940/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2804 - accuracy: 0.8662 - val_loss: 0.6243 - val_accuracy: 0.7708\n",
            "Epoch 941/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2832 - accuracy: 0.8780 - val_loss: 0.6234 - val_accuracy: 0.7708\n",
            "Epoch 942/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2728 - accuracy: 0.8621 - val_loss: 0.6252 - val_accuracy: 0.7708\n",
            "Epoch 943/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2996 - accuracy: 0.8443 - val_loss: 0.6255 - val_accuracy: 0.7708\n",
            "Epoch 944/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2762 - accuracy: 0.8670 - val_loss: 0.6256 - val_accuracy: 0.7708\n",
            "Epoch 945/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2821 - accuracy: 0.8719 - val_loss: 0.6257 - val_accuracy: 0.7708\n",
            "Epoch 946/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3104 - accuracy: 0.8483 - val_loss: 0.6291 - val_accuracy: 0.7708\n",
            "Epoch 947/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3052 - accuracy: 0.8525 - val_loss: 0.6271 - val_accuracy: 0.7708\n",
            "Epoch 948/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3044 - accuracy: 0.8558 - val_loss: 0.6245 - val_accuracy: 0.7708\n",
            "Epoch 949/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2805 - accuracy: 0.8683 - val_loss: 0.6206 - val_accuracy: 0.7708\n",
            "Epoch 950/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3192 - accuracy: 0.8518 - val_loss: 0.6203 - val_accuracy: 0.7708\n",
            "Epoch 951/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3015 - accuracy: 0.8665 - val_loss: 0.6226 - val_accuracy: 0.7708\n",
            "Epoch 952/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2858 - accuracy: 0.8597 - val_loss: 0.6262 - val_accuracy: 0.7708\n",
            "Epoch 953/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2596 - accuracy: 0.8804 - val_loss: 0.6225 - val_accuracy: 0.7708\n",
            "Epoch 954/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2796 - accuracy: 0.8722 - val_loss: 0.6183 - val_accuracy: 0.7708\n",
            "Epoch 955/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2583 - accuracy: 0.8773 - val_loss: 0.6245 - val_accuracy: 0.7708\n",
            "Epoch 956/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2969 - accuracy: 0.8509 - val_loss: 0.6268 - val_accuracy: 0.7708\n",
            "Epoch 957/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2998 - accuracy: 0.8606 - val_loss: 0.6294 - val_accuracy: 0.7708\n",
            "Epoch 958/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2679 - accuracy: 0.8840 - val_loss: 0.6280 - val_accuracy: 0.7708\n",
            "Epoch 959/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3185 - accuracy: 0.8403 - val_loss: 0.6261 - val_accuracy: 0.7708\n",
            "Epoch 960/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2820 - accuracy: 0.8699 - val_loss: 0.6312 - val_accuracy: 0.7708\n",
            "Epoch 961/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2637 - accuracy: 0.8939 - val_loss: 0.6282 - val_accuracy: 0.7708\n",
            "Epoch 962/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2939 - accuracy: 0.8590 - val_loss: 0.6272 - val_accuracy: 0.7708\n",
            "Epoch 963/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2612 - accuracy: 0.8844 - val_loss: 0.6243 - val_accuracy: 0.7708\n",
            "Epoch 964/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3534 - accuracy: 0.8349 - val_loss: 0.6285 - val_accuracy: 0.7708\n",
            "Epoch 965/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2887 - accuracy: 0.8603 - val_loss: 0.6233 - val_accuracy: 0.7708\n",
            "Epoch 966/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2913 - accuracy: 0.8395 - val_loss: 0.6263 - val_accuracy: 0.7708\n",
            "Epoch 967/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2679 - accuracy: 0.8782 - val_loss: 0.6257 - val_accuracy: 0.7708\n",
            "Epoch 968/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3100 - accuracy: 0.8472 - val_loss: 0.6281 - val_accuracy: 0.7708\n",
            "Epoch 969/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3013 - accuracy: 0.8546 - val_loss: 0.6275 - val_accuracy: 0.7708\n",
            "Epoch 970/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3245 - accuracy: 0.8482 - val_loss: 0.6271 - val_accuracy: 0.7708\n",
            "Epoch 971/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3038 - accuracy: 0.8639 - val_loss: 0.6304 - val_accuracy: 0.7708\n",
            "Epoch 972/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2775 - accuracy: 0.8642 - val_loss: 0.6316 - val_accuracy: 0.7708\n",
            "Epoch 973/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2565 - accuracy: 0.8915 - val_loss: 0.6233 - val_accuracy: 0.7708\n",
            "Epoch 974/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3144 - accuracy: 0.8587 - val_loss: 0.6265 - val_accuracy: 0.7708\n",
            "Epoch 975/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2896 - accuracy: 0.8709 - val_loss: 0.6246 - val_accuracy: 0.7708\n",
            "Epoch 976/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2927 - accuracy: 0.8439 - val_loss: 0.6292 - val_accuracy: 0.7708\n",
            "Epoch 977/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2680 - accuracy: 0.8828 - val_loss: 0.6260 - val_accuracy: 0.7708\n",
            "Epoch 978/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2872 - accuracy: 0.8726 - val_loss: 0.6291 - val_accuracy: 0.7708\n",
            "Epoch 979/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3139 - accuracy: 0.8370 - val_loss: 0.6339 - val_accuracy: 0.7708\n",
            "Epoch 980/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3112 - accuracy: 0.8594 - val_loss: 0.6287 - val_accuracy: 0.7708\n",
            "Epoch 981/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2756 - accuracy: 0.8691 - val_loss: 0.6239 - val_accuracy: 0.7708\n",
            "Epoch 982/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2807 - accuracy: 0.8585 - val_loss: 0.6231 - val_accuracy: 0.7708\n",
            "Epoch 983/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2443 - accuracy: 0.8772 - val_loss: 0.6187 - val_accuracy: 0.7708\n",
            "Epoch 984/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3118 - accuracy: 0.8541 - val_loss: 0.6254 - val_accuracy: 0.7708\n",
            "Epoch 985/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2855 - accuracy: 0.8635 - val_loss: 0.6253 - val_accuracy: 0.7708\n",
            "Epoch 986/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2789 - accuracy: 0.8606 - val_loss: 0.6231 - val_accuracy: 0.7708\n",
            "Epoch 987/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2575 - accuracy: 0.8775 - val_loss: 0.6266 - val_accuracy: 0.7708\n",
            "Epoch 988/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2714 - accuracy: 0.8627 - val_loss: 0.6288 - val_accuracy: 0.7708\n",
            "Epoch 989/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3054 - accuracy: 0.8482 - val_loss: 0.6216 - val_accuracy: 0.7708\n",
            "Epoch 990/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3451 - accuracy: 0.8209 - val_loss: 0.6217 - val_accuracy: 0.7708\n",
            "Epoch 991/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3400 - accuracy: 0.8185 - val_loss: 0.6211 - val_accuracy: 0.7708\n",
            "Epoch 992/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2591 - accuracy: 0.8828 - val_loss: 0.6243 - val_accuracy: 0.7708\n",
            "Epoch 993/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2850 - accuracy: 0.8613 - val_loss: 0.6258 - val_accuracy: 0.7708\n",
            "Epoch 994/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3040 - accuracy: 0.8437 - val_loss: 0.6317 - val_accuracy: 0.7708\n",
            "Epoch 995/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3052 - accuracy: 0.8523 - val_loss: 0.6294 - val_accuracy: 0.7708\n",
            "Epoch 996/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2936 - accuracy: 0.8606 - val_loss: 0.6314 - val_accuracy: 0.7708\n",
            "Epoch 997/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3274 - accuracy: 0.8163 - val_loss: 0.6274 - val_accuracy: 0.7708\n",
            "Epoch 998/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2746 - accuracy: 0.8749 - val_loss: 0.6285 - val_accuracy: 0.7708\n",
            "Epoch 999/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2569 - accuracy: 0.8738 - val_loss: 0.6247 - val_accuracy: 0.7708\n",
            "Epoch 1000/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2680 - accuracy: 0.8746 - val_loss: 0.6294 - val_accuracy: 0.7708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "iu8N41GtjbOb",
        "outputId": "e94d637c-481b-4c3f-f48e-9ec5ecc85226"
      },
      "source": [
        "# visualize the training loss and the validation loss to see if the model is overfitting\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'])\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "21mG2C8PkC6H",
        "outputId": "09a42f4e-126b-40f9-c3e4-3fd44caba242"
      },
      "source": [
        "# visualize the training accuracy and the validation accuracy to see if the model is overfitting\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'])\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uic0gZc5koml",
        "outputId": "1b454803-4e6d-427c-c5f5-0b1fbb40096c"
      },
      "source": [
        "# make a prediction and print the actual values\n",
        "prediction = model.predict(X_test)\n",
        "prediction = [1 if y >= 0.5 else 0 for y in prediction]\n",
        "print(prediction)\n",
        "print(y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
            "[1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtwOXiJ6leS5",
        "outputId": "bfc74fa3-bc34-4a09-f4cf-f1afbe704558"
      },
      "source": [
        "# evaluate the model on the training data\n",
        "from sklearn.metrics import  classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "pred = model.predict(X_train)\n",
        "pred = [1 if y >= 0.5 else 0 for y in pred]\n",
        "print(classification_report(y_train, pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_train, pred))\n",
        "print()\n",
        "print('Accuracy: ', accuracy_score(y_train, pred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.92      0.89       161\n",
            "         1.0       0.81      0.69      0.74        78\n",
            "\n",
            "    accuracy                           0.85       239\n",
            "   macro avg       0.83      0.81      0.82       239\n",
            "weighted avg       0.84      0.85      0.84       239\n",
            "\n",
            "Confusion Matrix: \n",
            " [[148  13]\n",
            " [ 24  54]]\n",
            "\n",
            "Accuracy:  0.8451882845188284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xolzWGG3ilLY"
      },
      "source": [
        "After 1000 epochs the neural network will be trained. We can see that the training accuracy is reached 84.5%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Mp4XxsAmfRB",
        "outputId": "6ae17ec2-44a5-44c8-895f-9fb9b5c28212"
      },
      "source": [
        "# evaluate the model on the test data\n",
        "from sklearn.metrics import  classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "pred = [1 if y >= 0.5 else 0 for y in pred]\n",
        "print(classification_report(y_test, pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, pred))\n",
        "print()\n",
        "print('Accuracy: ', accuracy_score(y_test, pred))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.95      0.88        42\n",
            "         1.0       0.82      0.50      0.62        18\n",
            "\n",
            "    accuracy                           0.82        60\n",
            "   macro avg       0.82      0.73      0.75        60\n",
            "weighted avg       0.82      0.82      0.80        60\n",
            "\n",
            "Confusion Matrix: \n",
            " [[40  2]\n",
            " [ 9  9]]\n",
            "\n",
            "Accuracy:  0.8166666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHlyOM5ak4Kl"
      },
      "source": [
        "We can see that the model's performance on the test data is not bad, the accuracy is reached 81.6%, but I want to make it better. So I am gonna use random forest to choose top 5 important features, then predict it again. Let's see what gonna happen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6J-hHOUm-L9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bdb0d3f-0360-4941-b57e-b4d8724d7392"
      },
      "source": [
        "# use Random forest to select important features\n",
        "# Create a random forest classifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size = 0.2, random_state = 4)\n",
        "rf = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)\n",
        "\n",
        "# Train the classifier\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Print the name and gini importance of each feature\n",
        "rf.feature_importances_\n",
        "feat_label = ['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time','anaemia','diabetes','high_blood_pressure','sex','smoking']\n",
        "\n",
        "for feature in zip(feat_label, rf.feature_importances_):\n",
        "    print(feature)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('age', 0.0952320559650102)\n",
            "('creatinine_phosphokinase', 0.0816989272449362)\n",
            "('ejection_fraction', 0.11926093309205274)\n",
            "('platelets', 0.07414341108168321)\n",
            "('serum_creatinine', 0.14198751381703306)\n",
            "('serum_sodium', 0.07524342086922703)\n",
            "('time', 0.3516852867085501)\n",
            "('anaemia', 0.012882395603792984)\n",
            "('diabetes', 0.012169047319983558)\n",
            "('high_blood_pressure', 0.011930261461692192)\n",
            "('sex', 0.011253927855970534)\n",
            "('smoking', 0.012512818980068232)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "Sj900GcT2Hcs",
        "outputId": "aabd624c-22c8-471c-eb69-bc63f4dcce95"
      },
      "source": [
        "#Plot Feature Importance in RandomForest Model\n",
        "importancesRF = rf.feature_importances_\n",
        "indicesRF = np.argsort(importancesRF)[::-1]\n",
        "\n",
        "Header = ['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time','anaemia','diabetes','high_blood_pressure','sex','smoking']\n",
        "n = len(Header)\n",
        "\n",
        "# Sort by Decreasing order\n",
        "indRf = sorted(importancesRF) \n",
        "index = np.arange(n)\n",
        "\n",
        "feature_space = []\n",
        "for i in range(n-1, -1, -1):\n",
        "    feature_space.append(Header[indicesRF[i]])\n",
        "\n",
        "f, ax = plt.subplots(figsize=(11, 11))\n",
        "plt.title('Feature importances for Random Forest Model')\n",
        "plt.barh(index, indRf,\n",
        "        align=\"center\", \n",
        "        color = '#875FDB')\n",
        "\n",
        "plt.yticks(index, feature_space)\n",
        "plt.ylim(-1, n)\n",
        "plt.xlim(0, 0.15)\n",
        "plt.xlabel('Information Gain')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 792x792 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xunq7VTqVxmP"
      },
      "source": [
        "Now we know that the top 5 important features are: 'time','serum_creatinine','ejection_fraction','age','creatinine_phosphokinase'. The next step is to construct a new dataset with top 5 important features and use a neural network to predicit death events again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ZOEl59qn3dU9",
        "outputId": "bd5cbb2e-e56f-4ffe-8abb-385467fe0e64"
      },
      "source": [
        "# Consturct a new dataset with only the top 5 important featrues\n",
        "new_dataset = dataset.filter(['time','serum_creatinine','ejection_fraction','age','creatinine_phosphokinase','DEATH_EVENT'], axis=1)\n",
        "new_dataset"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>age</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>1.9</td>\n",
              "      <td>20</td>\n",
              "      <td>75.0</td>\n",
              "      <td>582</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>1.1</td>\n",
              "      <td>38</td>\n",
              "      <td>55.0</td>\n",
              "      <td>7861</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>1.3</td>\n",
              "      <td>20</td>\n",
              "      <td>65.0</td>\n",
              "      <td>146</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>1.9</td>\n",
              "      <td>20</td>\n",
              "      <td>50.0</td>\n",
              "      <td>111</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>2.7</td>\n",
              "      <td>20</td>\n",
              "      <td>65.0</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>270</td>\n",
              "      <td>1.1</td>\n",
              "      <td>38</td>\n",
              "      <td>62.0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>271</td>\n",
              "      <td>1.2</td>\n",
              "      <td>38</td>\n",
              "      <td>55.0</td>\n",
              "      <td>1820</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>278</td>\n",
              "      <td>0.8</td>\n",
              "      <td>60</td>\n",
              "      <td>45.0</td>\n",
              "      <td>2060</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>280</td>\n",
              "      <td>1.4</td>\n",
              "      <td>38</td>\n",
              "      <td>45.0</td>\n",
              "      <td>2413</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>285</td>\n",
              "      <td>1.6</td>\n",
              "      <td>45</td>\n",
              "      <td>50.0</td>\n",
              "      <td>196</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>299 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     time  serum_creatinine  ...  creatinine_phosphokinase  DEATH_EVENT\n",
              "0       4               1.9  ...                       582            1\n",
              "1       6               1.1  ...                      7861            1\n",
              "2       7               1.3  ...                       146            1\n",
              "3       7               1.9  ...                       111            1\n",
              "4       8               2.7  ...                       160            1\n",
              "..    ...               ...  ...                       ...          ...\n",
              "294   270               1.1  ...                        61            0\n",
              "295   271               1.2  ...                      1820            0\n",
              "296   278               0.8  ...                      2060            0\n",
              "297   280               1.4  ...                      2413            0\n",
              "298   285               1.6  ...                       196            0\n",
              "\n",
              "[299 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E119RAB646Se",
        "outputId": "faea5d87-3bb3-4a3b-b1f5-8adfa3f8ea37"
      },
      "source": [
        "# convert the data into an arrray\n",
        "df = new_dataset.values\n",
        "df"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.000e+00, 1.900e+00, 2.000e+01, 7.500e+01, 5.820e+02, 1.000e+00],\n",
              "       [6.000e+00, 1.100e+00, 3.800e+01, 5.500e+01, 7.861e+03, 1.000e+00],\n",
              "       [7.000e+00, 1.300e+00, 2.000e+01, 6.500e+01, 1.460e+02, 1.000e+00],\n",
              "       ...,\n",
              "       [2.780e+02, 8.000e-01, 6.000e+01, 4.500e+01, 2.060e+03, 0.000e+00],\n",
              "       [2.800e+02, 1.400e+00, 3.800e+01, 4.500e+01, 2.413e+03, 0.000e+00],\n",
              "       [2.850e+02, 1.600e+00, 4.500e+01, 5.000e+01, 1.960e+02, 0.000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeaToncq5CQ7"
      },
      "source": [
        "# get all of the rows from the first 5 columns of the dataset\n",
        "X = df[:, 0:5]\n",
        "y = df[:, 5]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRaub4At5xOE",
        "outputId": "590ed6e6-7c3a-4afa-be25-db7d9830b16f"
      },
      "source": [
        "# Process the data\n",
        "from sklearn import  preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.15730337, 0.09090909, 0.63636364, 0.07131921],\n",
              "       [0.00711744, 0.06741573, 0.36363636, 0.27272727, 1.        ],\n",
              "       [0.01067616, 0.08988764, 0.09090909, 0.45454545, 0.01569278],\n",
              "       ...,\n",
              "       [0.97508897, 0.03370787, 0.6969697 , 0.09090909, 0.25988773],\n",
              "       [0.98220641, 0.1011236 , 0.36363636, 0.09090909, 0.30492473],\n",
              "       [1.        , 0.12359551, 0.46969697, 0.18181818, 0.02207196]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAsWGeAS56-_",
        "outputId": "67b8cf73-6f01-4728-cb1a-6c24a47aed6a"
      },
      "source": [
        "# split the data into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size = 0.2, random_state = 4)\n",
        "y_test"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       1., 0., 1., 0., 0., 0., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zyHrf3OYE9R"
      },
      "source": [
        "Using two hidden layers of 5 and 8 neurons respectively. The input shape will be 5 (features) and output will be 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejrowA566BUM"
      },
      "source": [
        "# build the model\n",
        "model = Sequential([\n",
        "        Dense(5, activation='relu', input_shape=(5,)),\n",
        "        Dense(8, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')                   \n",
        "]    \n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN1I1Kqk6IRS"
      },
      "source": [
        "# compile the model\n",
        "model.compile(\n",
        "      optimizer = 'sgd',\n",
        "      loss = 'binary_crossentropy',\n",
        "      metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gEiECWV6NBi",
        "outputId": "3519fe45-aeac-4119-bafd-7f5f189baac8"
      },
      "source": [
        "# Train the model, set 1000 epochs and break up our data into 20% validation dataset.\n",
        "hist = model.fit(X_train, y_train, epochs=1000, validation_split=0.2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "6/6 [==============================] - 1s 43ms/step - loss: 0.6912 - accuracy: 0.5835 - val_loss: 0.6915 - val_accuracy: 0.6250\n",
            "Epoch 2/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6868 - accuracy: 0.7421 - val_loss: 0.6888 - val_accuracy: 0.6458\n",
            "Epoch 3/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6840 - accuracy: 0.6905 - val_loss: 0.6860 - val_accuracy: 0.6250\n",
            "Epoch 4/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6789 - accuracy: 0.7214 - val_loss: 0.6833 - val_accuracy: 0.6250\n",
            "Epoch 5/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6764 - accuracy: 0.6774 - val_loss: 0.6807 - val_accuracy: 0.6250\n",
            "Epoch 6/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6745 - accuracy: 0.6791 - val_loss: 0.6782 - val_accuracy: 0.6250\n",
            "Epoch 7/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6715 - accuracy: 0.6609 - val_loss: 0.6758 - val_accuracy: 0.6250\n",
            "Epoch 8/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6669 - accuracy: 0.6762 - val_loss: 0.6737 - val_accuracy: 0.6250\n",
            "Epoch 9/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6625 - accuracy: 0.6879 - val_loss: 0.6717 - val_accuracy: 0.6250\n",
            "Epoch 10/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6597 - accuracy: 0.6856 - val_loss: 0.6697 - val_accuracy: 0.6250\n",
            "Epoch 11/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6513 - accuracy: 0.7136 - val_loss: 0.6677 - val_accuracy: 0.6250\n",
            "Epoch 12/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6588 - accuracy: 0.6568 - val_loss: 0.6658 - val_accuracy: 0.6250\n",
            "Epoch 13/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6547 - accuracy: 0.6544 - val_loss: 0.6640 - val_accuracy: 0.6250\n",
            "Epoch 14/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6490 - accuracy: 0.6869 - val_loss: 0.6622 - val_accuracy: 0.6250\n",
            "Epoch 15/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6394 - accuracy: 0.7121 - val_loss: 0.6604 - val_accuracy: 0.6250\n",
            "Epoch 16/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6430 - accuracy: 0.6786 - val_loss: 0.6585 - val_accuracy: 0.6250\n",
            "Epoch 17/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6323 - accuracy: 0.7129 - val_loss: 0.6567 - val_accuracy: 0.6250\n",
            "Epoch 18/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6364 - accuracy: 0.6849 - val_loss: 0.6550 - val_accuracy: 0.6250\n",
            "Epoch 19/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6311 - accuracy: 0.6932 - val_loss: 0.6535 - val_accuracy: 0.6250\n",
            "Epoch 20/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6342 - accuracy: 0.6716 - val_loss: 0.6519 - val_accuracy: 0.6250\n",
            "Epoch 21/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6271 - accuracy: 0.6864 - val_loss: 0.6505 - val_accuracy: 0.6250\n",
            "Epoch 22/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6265 - accuracy: 0.6910 - val_loss: 0.6491 - val_accuracy: 0.6250\n",
            "Epoch 23/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6144 - accuracy: 0.7086 - val_loss: 0.6479 - val_accuracy: 0.6250\n",
            "Epoch 24/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6336 - accuracy: 0.6420 - val_loss: 0.6466 - val_accuracy: 0.6250\n",
            "Epoch 25/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6148 - accuracy: 0.6953 - val_loss: 0.6454 - val_accuracy: 0.6250\n",
            "Epoch 26/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6285 - accuracy: 0.6481 - val_loss: 0.6443 - val_accuracy: 0.6250\n",
            "Epoch 27/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5881 - accuracy: 0.7550 - val_loss: 0.6432 - val_accuracy: 0.6250\n",
            "Epoch 28/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6218 - accuracy: 0.6625 - val_loss: 0.6422 - val_accuracy: 0.6250\n",
            "Epoch 29/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6009 - accuracy: 0.7046 - val_loss: 0.6413 - val_accuracy: 0.6250\n",
            "Epoch 30/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6078 - accuracy: 0.6838 - val_loss: 0.6404 - val_accuracy: 0.6250\n",
            "Epoch 31/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6021 - accuracy: 0.6934 - val_loss: 0.6395 - val_accuracy: 0.6250\n",
            "Epoch 32/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5959 - accuracy: 0.7124 - val_loss: 0.6387 - val_accuracy: 0.6250\n",
            "Epoch 33/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6073 - accuracy: 0.6742 - val_loss: 0.6378 - val_accuracy: 0.6250\n",
            "Epoch 34/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5896 - accuracy: 0.7128 - val_loss: 0.6370 - val_accuracy: 0.6250\n",
            "Epoch 35/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6025 - accuracy: 0.6752 - val_loss: 0.6362 - val_accuracy: 0.6250\n",
            "Epoch 36/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5926 - accuracy: 0.6876 - val_loss: 0.6353 - val_accuracy: 0.6250\n",
            "Epoch 37/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6037 - accuracy: 0.6800 - val_loss: 0.6345 - val_accuracy: 0.6250\n",
            "Epoch 38/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6131 - accuracy: 0.6431 - val_loss: 0.6338 - val_accuracy: 0.6250\n",
            "Epoch 39/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6054 - accuracy: 0.6644 - val_loss: 0.6332 - val_accuracy: 0.6250\n",
            "Epoch 40/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5934 - accuracy: 0.6949 - val_loss: 0.6327 - val_accuracy: 0.6250\n",
            "Epoch 41/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6057 - accuracy: 0.6568 - val_loss: 0.6322 - val_accuracy: 0.6250\n",
            "Epoch 42/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6055 - accuracy: 0.6546 - val_loss: 0.6318 - val_accuracy: 0.6250\n",
            "Epoch 43/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6011 - accuracy: 0.6674 - val_loss: 0.6314 - val_accuracy: 0.6250\n",
            "Epoch 44/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6025 - accuracy: 0.6661 - val_loss: 0.6310 - val_accuracy: 0.6250\n",
            "Epoch 45/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5740 - accuracy: 0.7068 - val_loss: 0.6307 - val_accuracy: 0.6250\n",
            "Epoch 46/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5963 - accuracy: 0.6599 - val_loss: 0.6303 - val_accuracy: 0.6250\n",
            "Epoch 47/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5801 - accuracy: 0.6915 - val_loss: 0.6300 - val_accuracy: 0.6250\n",
            "Epoch 48/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5792 - accuracy: 0.6907 - val_loss: 0.6296 - val_accuracy: 0.6250\n",
            "Epoch 49/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5599 - accuracy: 0.7151 - val_loss: 0.6294 - val_accuracy: 0.6250\n",
            "Epoch 50/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6053 - accuracy: 0.6481 - val_loss: 0.6291 - val_accuracy: 0.6250\n",
            "Epoch 51/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5822 - accuracy: 0.6905 - val_loss: 0.6288 - val_accuracy: 0.6250\n",
            "Epoch 52/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5907 - accuracy: 0.6676 - val_loss: 0.6286 - val_accuracy: 0.6250\n",
            "Epoch 53/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5896 - accuracy: 0.6639 - val_loss: 0.6283 - val_accuracy: 0.6250\n",
            "Epoch 54/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5421 - accuracy: 0.7506 - val_loss: 0.6281 - val_accuracy: 0.6250\n",
            "Epoch 55/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5702 - accuracy: 0.7013 - val_loss: 0.6279 - val_accuracy: 0.6250\n",
            "Epoch 56/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5754 - accuracy: 0.6797 - val_loss: 0.6276 - val_accuracy: 0.6250\n",
            "Epoch 57/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5573 - accuracy: 0.7106 - val_loss: 0.6274 - val_accuracy: 0.6250\n",
            "Epoch 58/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5877 - accuracy: 0.6564 - val_loss: 0.6272 - val_accuracy: 0.6250\n",
            "Epoch 59/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5912 - accuracy: 0.6663 - val_loss: 0.6270 - val_accuracy: 0.6250\n",
            "Epoch 60/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5721 - accuracy: 0.6870 - val_loss: 0.6268 - val_accuracy: 0.6250\n",
            "Epoch 61/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5764 - accuracy: 0.6669 - val_loss: 0.6265 - val_accuracy: 0.6250\n",
            "Epoch 62/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5543 - accuracy: 0.7078 - val_loss: 0.6263 - val_accuracy: 0.6250\n",
            "Epoch 63/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5743 - accuracy: 0.6713 - val_loss: 0.6260 - val_accuracy: 0.6250\n",
            "Epoch 64/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5368 - accuracy: 0.7257 - val_loss: 0.6258 - val_accuracy: 0.6250\n",
            "Epoch 65/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5574 - accuracy: 0.6956 - val_loss: 0.6256 - val_accuracy: 0.6250\n",
            "Epoch 66/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5358 - accuracy: 0.7182 - val_loss: 0.6253 - val_accuracy: 0.6250\n",
            "Epoch 67/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5660 - accuracy: 0.6900 - val_loss: 0.6251 - val_accuracy: 0.6250\n",
            "Epoch 68/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5834 - accuracy: 0.6630 - val_loss: 0.6249 - val_accuracy: 0.6250\n",
            "Epoch 69/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5484 - accuracy: 0.7018 - val_loss: 0.6246 - val_accuracy: 0.6250\n",
            "Epoch 70/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5441 - accuracy: 0.7010 - val_loss: 0.6244 - val_accuracy: 0.6250\n",
            "Epoch 71/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5885 - accuracy: 0.6397 - val_loss: 0.6242 - val_accuracy: 0.6250\n",
            "Epoch 72/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5559 - accuracy: 0.6867 - val_loss: 0.6240 - val_accuracy: 0.6250\n",
            "Epoch 73/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5580 - accuracy: 0.7003 - val_loss: 0.6237 - val_accuracy: 0.6250\n",
            "Epoch 74/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5620 - accuracy: 0.6837 - val_loss: 0.6234 - val_accuracy: 0.6250\n",
            "Epoch 75/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5545 - accuracy: 0.6794 - val_loss: 0.6232 - val_accuracy: 0.6250\n",
            "Epoch 76/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5701 - accuracy: 0.6609 - val_loss: 0.6229 - val_accuracy: 0.6250\n",
            "Epoch 77/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5481 - accuracy: 0.6940 - val_loss: 0.6226 - val_accuracy: 0.6250\n",
            "Epoch 78/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5666 - accuracy: 0.6644 - val_loss: 0.6223 - val_accuracy: 0.6250\n",
            "Epoch 79/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5411 - accuracy: 0.7052 - val_loss: 0.6221 - val_accuracy: 0.6250\n",
            "Epoch 80/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5325 - accuracy: 0.7233 - val_loss: 0.6218 - val_accuracy: 0.6250\n",
            "Epoch 81/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5333 - accuracy: 0.7058 - val_loss: 0.6215 - val_accuracy: 0.6250\n",
            "Epoch 82/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5574 - accuracy: 0.6812 - val_loss: 0.6212 - val_accuracy: 0.6250\n",
            "Epoch 83/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5517 - accuracy: 0.6914 - val_loss: 0.6209 - val_accuracy: 0.6250\n",
            "Epoch 84/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5321 - accuracy: 0.7125 - val_loss: 0.6206 - val_accuracy: 0.6250\n",
            "Epoch 85/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5521 - accuracy: 0.6884 - val_loss: 0.6202 - val_accuracy: 0.6250\n",
            "Epoch 86/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5629 - accuracy: 0.6721 - val_loss: 0.6200 - val_accuracy: 0.6250\n",
            "Epoch 87/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5645 - accuracy: 0.6591 - val_loss: 0.6196 - val_accuracy: 0.6250\n",
            "Epoch 88/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5655 - accuracy: 0.6653 - val_loss: 0.6193 - val_accuracy: 0.6250\n",
            "Epoch 89/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5369 - accuracy: 0.6908 - val_loss: 0.6190 - val_accuracy: 0.6250\n",
            "Epoch 90/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5596 - accuracy: 0.6733 - val_loss: 0.6187 - val_accuracy: 0.6250\n",
            "Epoch 91/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5576 - accuracy: 0.6736 - val_loss: 0.6184 - val_accuracy: 0.6250\n",
            "Epoch 92/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5756 - accuracy: 0.6403 - val_loss: 0.6181 - val_accuracy: 0.6250\n",
            "Epoch 93/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5303 - accuracy: 0.7029 - val_loss: 0.6177 - val_accuracy: 0.6250\n",
            "Epoch 94/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5309 - accuracy: 0.6941 - val_loss: 0.6174 - val_accuracy: 0.6250\n",
            "Epoch 95/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5226 - accuracy: 0.7112 - val_loss: 0.6170 - val_accuracy: 0.6250\n",
            "Epoch 96/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5498 - accuracy: 0.6734 - val_loss: 0.6167 - val_accuracy: 0.6250\n",
            "Epoch 97/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5333 - accuracy: 0.7049 - val_loss: 0.6163 - val_accuracy: 0.6250\n",
            "Epoch 98/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5315 - accuracy: 0.6951 - val_loss: 0.6160 - val_accuracy: 0.6250\n",
            "Epoch 99/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5281 - accuracy: 0.7027 - val_loss: 0.6156 - val_accuracy: 0.6250\n",
            "Epoch 100/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5376 - accuracy: 0.6835 - val_loss: 0.6152 - val_accuracy: 0.6250\n",
            "Epoch 101/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5399 - accuracy: 0.6928 - val_loss: 0.6148 - val_accuracy: 0.6250\n",
            "Epoch 102/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5130 - accuracy: 0.7172 - val_loss: 0.6144 - val_accuracy: 0.6250\n",
            "Epoch 103/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5274 - accuracy: 0.7026 - val_loss: 0.6140 - val_accuracy: 0.6250\n",
            "Epoch 104/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5163 - accuracy: 0.7129 - val_loss: 0.6136 - val_accuracy: 0.6250\n",
            "Epoch 105/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5109 - accuracy: 0.7158 - val_loss: 0.6131 - val_accuracy: 0.6250\n",
            "Epoch 106/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5452 - accuracy: 0.6783 - val_loss: 0.6127 - val_accuracy: 0.6250\n",
            "Epoch 107/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5359 - accuracy: 0.6857 - val_loss: 0.6123 - val_accuracy: 0.6250\n",
            "Epoch 108/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5408 - accuracy: 0.6805 - val_loss: 0.6118 - val_accuracy: 0.6250\n",
            "Epoch 109/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5410 - accuracy: 0.6807 - val_loss: 0.6114 - val_accuracy: 0.6250\n",
            "Epoch 110/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5413 - accuracy: 0.6739 - val_loss: 0.6109 - val_accuracy: 0.6250\n",
            "Epoch 111/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5539 - accuracy: 0.6457 - val_loss: 0.6106 - val_accuracy: 0.6250\n",
            "Epoch 112/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5029 - accuracy: 0.7094 - val_loss: 0.6102 - val_accuracy: 0.6250\n",
            "Epoch 113/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5230 - accuracy: 0.6900 - val_loss: 0.6098 - val_accuracy: 0.6250\n",
            "Epoch 114/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5174 - accuracy: 0.6911 - val_loss: 0.6095 - val_accuracy: 0.6250\n",
            "Epoch 115/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4918 - accuracy: 0.7296 - val_loss: 0.6090 - val_accuracy: 0.6458\n",
            "Epoch 116/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5114 - accuracy: 0.6954 - val_loss: 0.6087 - val_accuracy: 0.6458\n",
            "Epoch 117/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5427 - accuracy: 0.6702 - val_loss: 0.6083 - val_accuracy: 0.6458\n",
            "Epoch 118/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5187 - accuracy: 0.7045 - val_loss: 0.6079 - val_accuracy: 0.6458\n",
            "Epoch 119/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5262 - accuracy: 0.7018 - val_loss: 0.6075 - val_accuracy: 0.6458\n",
            "Epoch 120/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5306 - accuracy: 0.6937 - val_loss: 0.6071 - val_accuracy: 0.6458\n",
            "Epoch 121/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5008 - accuracy: 0.7214 - val_loss: 0.6067 - val_accuracy: 0.6458\n",
            "Epoch 122/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5028 - accuracy: 0.7201 - val_loss: 0.6063 - val_accuracy: 0.6458\n",
            "Epoch 123/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5074 - accuracy: 0.7144 - val_loss: 0.6058 - val_accuracy: 0.6458\n",
            "Epoch 124/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5102 - accuracy: 0.7176 - val_loss: 0.6054 - val_accuracy: 0.6458\n",
            "Epoch 125/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5294 - accuracy: 0.7089 - val_loss: 0.6050 - val_accuracy: 0.6458\n",
            "Epoch 126/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5030 - accuracy: 0.7198 - val_loss: 0.6046 - val_accuracy: 0.6458\n",
            "Epoch 127/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4893 - accuracy: 0.7525 - val_loss: 0.6041 - val_accuracy: 0.6458\n",
            "Epoch 128/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4885 - accuracy: 0.7400 - val_loss: 0.6037 - val_accuracy: 0.6458\n",
            "Epoch 129/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4938 - accuracy: 0.7290 - val_loss: 0.6033 - val_accuracy: 0.6458\n",
            "Epoch 130/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4844 - accuracy: 0.7456 - val_loss: 0.6028 - val_accuracy: 0.6667\n",
            "Epoch 131/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5338 - accuracy: 0.6915 - val_loss: 0.6024 - val_accuracy: 0.6667\n",
            "Epoch 132/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5140 - accuracy: 0.7165 - val_loss: 0.6021 - val_accuracy: 0.6667\n",
            "Epoch 133/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5283 - accuracy: 0.7165 - val_loss: 0.6016 - val_accuracy: 0.6667\n",
            "Epoch 134/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4979 - accuracy: 0.7489 - val_loss: 0.6012 - val_accuracy: 0.6667\n",
            "Epoch 135/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5150 - accuracy: 0.7102 - val_loss: 0.6008 - val_accuracy: 0.6667\n",
            "Epoch 136/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5364 - accuracy: 0.6972 - val_loss: 0.6005 - val_accuracy: 0.6667\n",
            "Epoch 137/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4905 - accuracy: 0.7469 - val_loss: 0.6001 - val_accuracy: 0.6667\n",
            "Epoch 138/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5032 - accuracy: 0.7591 - val_loss: 0.5997 - val_accuracy: 0.6667\n",
            "Epoch 139/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4937 - accuracy: 0.7658 - val_loss: 0.5993 - val_accuracy: 0.6667\n",
            "Epoch 140/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5293 - accuracy: 0.7106 - val_loss: 0.5988 - val_accuracy: 0.6667\n",
            "Epoch 141/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4996 - accuracy: 0.7510 - val_loss: 0.5984 - val_accuracy: 0.6667\n",
            "Epoch 142/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5028 - accuracy: 0.7488 - val_loss: 0.5980 - val_accuracy: 0.6667\n",
            "Epoch 143/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5353 - accuracy: 0.7045 - val_loss: 0.5976 - val_accuracy: 0.6667\n",
            "Epoch 144/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4848 - accuracy: 0.7585 - val_loss: 0.5971 - val_accuracy: 0.6667\n",
            "Epoch 145/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5143 - accuracy: 0.7228 - val_loss: 0.5967 - val_accuracy: 0.6667\n",
            "Epoch 146/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5103 - accuracy: 0.7564 - val_loss: 0.5962 - val_accuracy: 0.6667\n",
            "Epoch 147/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4955 - accuracy: 0.7519 - val_loss: 0.5957 - val_accuracy: 0.6667\n",
            "Epoch 148/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5156 - accuracy: 0.7334 - val_loss: 0.5953 - val_accuracy: 0.6667\n",
            "Epoch 149/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4817 - accuracy: 0.7689 - val_loss: 0.5948 - val_accuracy: 0.6667\n",
            "Epoch 150/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5275 - accuracy: 0.7238 - val_loss: 0.5944 - val_accuracy: 0.6667\n",
            "Epoch 151/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4764 - accuracy: 0.8051 - val_loss: 0.5939 - val_accuracy: 0.6667\n",
            "Epoch 152/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5141 - accuracy: 0.7440 - val_loss: 0.5935 - val_accuracy: 0.6667\n",
            "Epoch 153/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4849 - accuracy: 0.7657 - val_loss: 0.5931 - val_accuracy: 0.6667\n",
            "Epoch 154/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4925 - accuracy: 0.7455 - val_loss: 0.5926 - val_accuracy: 0.6667\n",
            "Epoch 155/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5269 - accuracy: 0.7511 - val_loss: 0.5922 - val_accuracy: 0.6667\n",
            "Epoch 156/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5096 - accuracy: 0.7185 - val_loss: 0.5918 - val_accuracy: 0.6667\n",
            "Epoch 157/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5200 - accuracy: 0.7361 - val_loss: 0.5914 - val_accuracy: 0.6667\n",
            "Epoch 158/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4778 - accuracy: 0.7644 - val_loss: 0.5909 - val_accuracy: 0.6667\n",
            "Epoch 159/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4955 - accuracy: 0.7622 - val_loss: 0.5905 - val_accuracy: 0.6667\n",
            "Epoch 160/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4941 - accuracy: 0.7813 - val_loss: 0.5900 - val_accuracy: 0.6667\n",
            "Epoch 161/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5105 - accuracy: 0.7334 - val_loss: 0.5896 - val_accuracy: 0.6667\n",
            "Epoch 162/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4760 - accuracy: 0.7810 - val_loss: 0.5891 - val_accuracy: 0.6667\n",
            "Epoch 163/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4993 - accuracy: 0.7347 - val_loss: 0.5886 - val_accuracy: 0.6667\n",
            "Epoch 164/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5029 - accuracy: 0.7449 - val_loss: 0.5882 - val_accuracy: 0.6667\n",
            "Epoch 165/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5167 - accuracy: 0.7485 - val_loss: 0.5878 - val_accuracy: 0.6667\n",
            "Epoch 166/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5096 - accuracy: 0.7622 - val_loss: 0.5873 - val_accuracy: 0.6667\n",
            "Epoch 167/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4920 - accuracy: 0.7579 - val_loss: 0.5869 - val_accuracy: 0.6667\n",
            "Epoch 168/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4882 - accuracy: 0.7800 - val_loss: 0.5863 - val_accuracy: 0.6667\n",
            "Epoch 169/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4855 - accuracy: 0.7663 - val_loss: 0.5859 - val_accuracy: 0.6667\n",
            "Epoch 170/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4627 - accuracy: 0.7881 - val_loss: 0.5854 - val_accuracy: 0.6667\n",
            "Epoch 171/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5047 - accuracy: 0.7824 - val_loss: 0.5849 - val_accuracy: 0.6667\n",
            "Epoch 172/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4794 - accuracy: 0.7769 - val_loss: 0.5844 - val_accuracy: 0.6667\n",
            "Epoch 173/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4857 - accuracy: 0.7651 - val_loss: 0.5839 - val_accuracy: 0.6667\n",
            "Epoch 174/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4902 - accuracy: 0.7589 - val_loss: 0.5835 - val_accuracy: 0.6667\n",
            "Epoch 175/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4782 - accuracy: 0.8018 - val_loss: 0.5830 - val_accuracy: 0.6667\n",
            "Epoch 176/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5198 - accuracy: 0.7268 - val_loss: 0.5826 - val_accuracy: 0.6667\n",
            "Epoch 177/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4661 - accuracy: 0.8068 - val_loss: 0.5820 - val_accuracy: 0.6667\n",
            "Epoch 178/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4933 - accuracy: 0.7752 - val_loss: 0.5815 - val_accuracy: 0.6667\n",
            "Epoch 179/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4799 - accuracy: 0.7666 - val_loss: 0.5810 - val_accuracy: 0.6667\n",
            "Epoch 180/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4589 - accuracy: 0.8034 - val_loss: 0.5805 - val_accuracy: 0.6667\n",
            "Epoch 181/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4651 - accuracy: 0.7892 - val_loss: 0.5799 - val_accuracy: 0.6667\n",
            "Epoch 182/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4838 - accuracy: 0.7705 - val_loss: 0.5794 - val_accuracy: 0.6667\n",
            "Epoch 183/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4543 - accuracy: 0.7935 - val_loss: 0.5789 - val_accuracy: 0.6667\n",
            "Epoch 184/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4794 - accuracy: 0.7964 - val_loss: 0.5783 - val_accuracy: 0.6875\n",
            "Epoch 185/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4508 - accuracy: 0.7961 - val_loss: 0.5779 - val_accuracy: 0.6875\n",
            "Epoch 186/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4997 - accuracy: 0.7681 - val_loss: 0.5776 - val_accuracy: 0.6875\n",
            "Epoch 187/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5006 - accuracy: 0.7597 - val_loss: 0.5772 - val_accuracy: 0.6875\n",
            "Epoch 188/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4995 - accuracy: 0.7332 - val_loss: 0.5769 - val_accuracy: 0.6875\n",
            "Epoch 189/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4821 - accuracy: 0.7703 - val_loss: 0.5764 - val_accuracy: 0.6667\n",
            "Epoch 190/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4729 - accuracy: 0.7872 - val_loss: 0.5759 - val_accuracy: 0.6667\n",
            "Epoch 191/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4648 - accuracy: 0.8049 - val_loss: 0.5755 - val_accuracy: 0.6667\n",
            "Epoch 192/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4597 - accuracy: 0.8026 - val_loss: 0.5749 - val_accuracy: 0.6667\n",
            "Epoch 193/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4950 - accuracy: 0.7562 - val_loss: 0.5745 - val_accuracy: 0.6667\n",
            "Epoch 194/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4651 - accuracy: 0.7905 - val_loss: 0.5740 - val_accuracy: 0.7083\n",
            "Epoch 195/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.5735 - val_accuracy: 0.7083\n",
            "Epoch 196/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4672 - accuracy: 0.7916 - val_loss: 0.5730 - val_accuracy: 0.7083\n",
            "Epoch 197/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4610 - accuracy: 0.8105 - val_loss: 0.5725 - val_accuracy: 0.7083\n",
            "Epoch 198/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4657 - accuracy: 0.7764 - val_loss: 0.5720 - val_accuracy: 0.7083\n",
            "Epoch 199/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4414 - accuracy: 0.8052 - val_loss: 0.5715 - val_accuracy: 0.7083\n",
            "Epoch 200/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4905 - accuracy: 0.7541 - val_loss: 0.5712 - val_accuracy: 0.7083\n",
            "Epoch 201/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4589 - accuracy: 0.8070 - val_loss: 0.5706 - val_accuracy: 0.7083\n",
            "Epoch 202/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4616 - accuracy: 0.7954 - val_loss: 0.5701 - val_accuracy: 0.7083\n",
            "Epoch 203/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4569 - accuracy: 0.8044 - val_loss: 0.5697 - val_accuracy: 0.7083\n",
            "Epoch 204/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4755 - accuracy: 0.7695 - val_loss: 0.5694 - val_accuracy: 0.7083\n",
            "Epoch 205/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4425 - accuracy: 0.7974 - val_loss: 0.5690 - val_accuracy: 0.7083\n",
            "Epoch 206/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4883 - accuracy: 0.7644 - val_loss: 0.5687 - val_accuracy: 0.7083\n",
            "Epoch 207/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4510 - accuracy: 0.7727 - val_loss: 0.5681 - val_accuracy: 0.7083\n",
            "Epoch 208/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4590 - accuracy: 0.7851 - val_loss: 0.5675 - val_accuracy: 0.7083\n",
            "Epoch 209/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4538 - accuracy: 0.7963 - val_loss: 0.5671 - val_accuracy: 0.7083\n",
            "Epoch 210/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4643 - accuracy: 0.7816 - val_loss: 0.5665 - val_accuracy: 0.7083\n",
            "Epoch 211/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4689 - accuracy: 0.7570 - val_loss: 0.5662 - val_accuracy: 0.7083\n",
            "Epoch 212/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4579 - accuracy: 0.8045 - val_loss: 0.5657 - val_accuracy: 0.7083\n",
            "Epoch 213/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4674 - accuracy: 0.7806 - val_loss: 0.5654 - val_accuracy: 0.7083\n",
            "Epoch 214/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4389 - accuracy: 0.8049 - val_loss: 0.5650 - val_accuracy: 0.7083\n",
            "Epoch 215/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4410 - accuracy: 0.8168 - val_loss: 0.5644 - val_accuracy: 0.7083\n",
            "Epoch 216/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4572 - accuracy: 0.7982 - val_loss: 0.5641 - val_accuracy: 0.7083\n",
            "Epoch 217/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4121 - accuracy: 0.8422 - val_loss: 0.5635 - val_accuracy: 0.7083\n",
            "Epoch 218/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4819 - accuracy: 0.7905 - val_loss: 0.5631 - val_accuracy: 0.7083\n",
            "Epoch 219/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4269 - accuracy: 0.8194 - val_loss: 0.5625 - val_accuracy: 0.7083\n",
            "Epoch 220/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4395 - accuracy: 0.8197 - val_loss: 0.5621 - val_accuracy: 0.7083\n",
            "Epoch 221/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4532 - accuracy: 0.8041 - val_loss: 0.5617 - val_accuracy: 0.7083\n",
            "Epoch 222/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4230 - accuracy: 0.8324 - val_loss: 0.5612 - val_accuracy: 0.7083\n",
            "Epoch 223/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4513 - accuracy: 0.7953 - val_loss: 0.5608 - val_accuracy: 0.7292\n",
            "Epoch 224/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4380 - accuracy: 0.8106 - val_loss: 0.5604 - val_accuracy: 0.7292\n",
            "Epoch 225/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4291 - accuracy: 0.8189 - val_loss: 0.5600 - val_accuracy: 0.7292\n",
            "Epoch 226/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4284 - accuracy: 0.8121 - val_loss: 0.5594 - val_accuracy: 0.7292\n",
            "Epoch 227/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4355 - accuracy: 0.8169 - val_loss: 0.5589 - val_accuracy: 0.7292\n",
            "Epoch 228/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4481 - accuracy: 0.7968 - val_loss: 0.5586 - val_accuracy: 0.7292\n",
            "Epoch 229/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4776 - accuracy: 0.7968 - val_loss: 0.5582 - val_accuracy: 0.7292\n",
            "Epoch 230/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4395 - accuracy: 0.8214 - val_loss: 0.5578 - val_accuracy: 0.7292\n",
            "Epoch 231/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4697 - accuracy: 0.8005 - val_loss: 0.5575 - val_accuracy: 0.7292\n",
            "Epoch 232/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4253 - accuracy: 0.8282 - val_loss: 0.5569 - val_accuracy: 0.7292\n",
            "Epoch 233/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4471 - accuracy: 0.8237 - val_loss: 0.5564 - val_accuracy: 0.7292\n",
            "Epoch 234/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4507 - accuracy: 0.8151 - val_loss: 0.5560 - val_accuracy: 0.7292\n",
            "Epoch 235/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4463 - accuracy: 0.8104 - val_loss: 0.5557 - val_accuracy: 0.7292\n",
            "Epoch 236/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4038 - accuracy: 0.8507 - val_loss: 0.5552 - val_accuracy: 0.7292\n",
            "Epoch 237/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4292 - accuracy: 0.8394 - val_loss: 0.5548 - val_accuracy: 0.7292\n",
            "Epoch 238/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4380 - accuracy: 0.8215 - val_loss: 0.5544 - val_accuracy: 0.7292\n",
            "Epoch 239/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4329 - accuracy: 0.8133 - val_loss: 0.5539 - val_accuracy: 0.7292\n",
            "Epoch 240/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4246 - accuracy: 0.8275 - val_loss: 0.5536 - val_accuracy: 0.7292\n",
            "Epoch 241/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4436 - accuracy: 0.7983 - val_loss: 0.5533 - val_accuracy: 0.7292\n",
            "Epoch 242/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4569 - accuracy: 0.7797 - val_loss: 0.5531 - val_accuracy: 0.7292\n",
            "Epoch 243/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4384 - accuracy: 0.8157 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
            "Epoch 244/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4619 - accuracy: 0.8031 - val_loss: 0.5524 - val_accuracy: 0.7292\n",
            "Epoch 245/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4249 - accuracy: 0.8087 - val_loss: 0.5518 - val_accuracy: 0.7292\n",
            "Epoch 246/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4413 - accuracy: 0.8115 - val_loss: 0.5515 - val_accuracy: 0.7292\n",
            "Epoch 247/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4401 - accuracy: 0.8079 - val_loss: 0.5510 - val_accuracy: 0.7292\n",
            "Epoch 248/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4291 - accuracy: 0.8130 - val_loss: 0.5505 - val_accuracy: 0.7292\n",
            "Epoch 249/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4472 - accuracy: 0.7952 - val_loss: 0.5502 - val_accuracy: 0.7292\n",
            "Epoch 250/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4533 - accuracy: 0.7907 - val_loss: 0.5499 - val_accuracy: 0.7292\n",
            "Epoch 251/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4502 - accuracy: 0.7853 - val_loss: 0.5497 - val_accuracy: 0.7292\n",
            "Epoch 252/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4167 - accuracy: 0.8231 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 253/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4485 - accuracy: 0.7862 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
            "Epoch 254/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4198 - accuracy: 0.8106 - val_loss: 0.5483 - val_accuracy: 0.7292\n",
            "Epoch 255/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4191 - accuracy: 0.8308 - val_loss: 0.5479 - val_accuracy: 0.7292\n",
            "Epoch 256/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4229 - accuracy: 0.8117 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
            "Epoch 257/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4208 - accuracy: 0.8227 - val_loss: 0.5472 - val_accuracy: 0.7292\n",
            "Epoch 258/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4205 - accuracy: 0.8007 - val_loss: 0.5467 - val_accuracy: 0.7292\n",
            "Epoch 259/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4036 - accuracy: 0.8325 - val_loss: 0.5463 - val_accuracy: 0.7292\n",
            "Epoch 260/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4420 - accuracy: 0.7759 - val_loss: 0.5461 - val_accuracy: 0.7292\n",
            "Epoch 261/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4183 - accuracy: 0.8234 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 262/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4038 - accuracy: 0.8207 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
            "Epoch 263/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4125 - accuracy: 0.8123 - val_loss: 0.5449 - val_accuracy: 0.7292\n",
            "Epoch 264/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4473 - accuracy: 0.7998 - val_loss: 0.5447 - val_accuracy: 0.7292\n",
            "Epoch 265/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4243 - accuracy: 0.7868 - val_loss: 0.5443 - val_accuracy: 0.7292\n",
            "Epoch 266/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4223 - accuracy: 0.7896 - val_loss: 0.5439 - val_accuracy: 0.7292\n",
            "Epoch 267/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4252 - accuracy: 0.7872 - val_loss: 0.5435 - val_accuracy: 0.7292\n",
            "Epoch 268/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4166 - accuracy: 0.8088 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
            "Epoch 269/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4253 - accuracy: 0.7932 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
            "Epoch 270/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4268 - accuracy: 0.7985 - val_loss: 0.5425 - val_accuracy: 0.7292\n",
            "Epoch 271/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4438 - accuracy: 0.7894 - val_loss: 0.5422 - val_accuracy: 0.7292\n",
            "Epoch 272/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4221 - accuracy: 0.8089 - val_loss: 0.5417 - val_accuracy: 0.7292\n",
            "Epoch 273/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4014 - accuracy: 0.8241 - val_loss: 0.5414 - val_accuracy: 0.7292\n",
            "Epoch 274/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4415 - accuracy: 0.8005 - val_loss: 0.5413 - val_accuracy: 0.7292\n",
            "Epoch 275/1000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 0.4255 - accuracy: 0.8044 - val_loss: 0.5411 - val_accuracy: 0.7292\n",
            "Epoch 276/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4074 - accuracy: 0.8304 - val_loss: 0.5407 - val_accuracy: 0.7292\n",
            "Epoch 277/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4284 - accuracy: 0.7926 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
            "Epoch 278/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4417 - accuracy: 0.7993 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
            "Epoch 279/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4136 - accuracy: 0.8249 - val_loss: 0.5397 - val_accuracy: 0.7292\n",
            "Epoch 280/1000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.4382 - accuracy: 0.7915 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
            "Epoch 281/1000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.4300 - accuracy: 0.8315 - val_loss: 0.5391 - val_accuracy: 0.7292\n",
            "Epoch 282/1000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.4302 - accuracy: 0.8090 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
            "Epoch 283/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4188 - accuracy: 0.8036 - val_loss: 0.5385 - val_accuracy: 0.7292\n",
            "Epoch 284/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4245 - accuracy: 0.8107 - val_loss: 0.5382 - val_accuracy: 0.7292\n",
            "Epoch 285/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4567 - accuracy: 0.7839 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
            "Epoch 286/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3998 - accuracy: 0.8301 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
            "Epoch 287/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4072 - accuracy: 0.8249 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
            "Epoch 288/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.4254 - accuracy: 0.8120 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
            "Epoch 289/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.4232 - accuracy: 0.8041 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
            "Epoch 290/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4201 - accuracy: 0.8099 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
            "Epoch 291/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3971 - accuracy: 0.8437 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
            "Epoch 292/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4372 - accuracy: 0.8016 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
            "Epoch 293/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4057 - accuracy: 0.8115 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
            "Epoch 294/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4350 - accuracy: 0.8054 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
            "Epoch 295/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4433 - accuracy: 0.7955 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
            "Epoch 296/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4457 - accuracy: 0.7894 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
            "Epoch 297/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4188 - accuracy: 0.8334 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
            "Epoch 298/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4225 - accuracy: 0.8076 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
            "Epoch 299/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3697 - accuracy: 0.8549 - val_loss: 0.5340 - val_accuracy: 0.7292\n",
            "Epoch 300/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3930 - accuracy: 0.8573 - val_loss: 0.5337 - val_accuracy: 0.7292\n",
            "Epoch 301/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3793 - accuracy: 0.8308 - val_loss: 0.5333 - val_accuracy: 0.7292\n",
            "Epoch 302/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3748 - accuracy: 0.8454 - val_loss: 0.5330 - val_accuracy: 0.7292\n",
            "Epoch 303/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4056 - accuracy: 0.8163 - val_loss: 0.5328 - val_accuracy: 0.7292\n",
            "Epoch 304/1000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.4068 - accuracy: 0.8119 - val_loss: 0.5326 - val_accuracy: 0.7292\n",
            "Epoch 305/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3547 - accuracy: 0.8645 - val_loss: 0.5322 - val_accuracy: 0.7292\n",
            "Epoch 306/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3796 - accuracy: 0.8398 - val_loss: 0.5318 - val_accuracy: 0.7292\n",
            "Epoch 307/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4174 - accuracy: 0.8048 - val_loss: 0.5316 - val_accuracy: 0.7292\n",
            "Epoch 308/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4389 - accuracy: 0.8048 - val_loss: 0.5314 - val_accuracy: 0.7292\n",
            "Epoch 309/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4017 - accuracy: 0.8126 - val_loss: 0.5311 - val_accuracy: 0.7292\n",
            "Epoch 310/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4144 - accuracy: 0.7946 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
            "Epoch 311/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4027 - accuracy: 0.8357 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
            "Epoch 312/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4084 - accuracy: 0.8350 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
            "Epoch 313/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4461 - accuracy: 0.7987 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
            "Epoch 314/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4356 - accuracy: 0.8195 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
            "Epoch 315/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4258 - accuracy: 0.8212 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
            "Epoch 316/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.4112 - accuracy: 0.8093 - val_loss: 0.5295 - val_accuracy: 0.7708\n",
            "Epoch 317/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4175 - accuracy: 0.8044 - val_loss: 0.5292 - val_accuracy: 0.7708\n",
            "Epoch 318/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4230 - accuracy: 0.7880 - val_loss: 0.5291 - val_accuracy: 0.7708\n",
            "Epoch 319/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4014 - accuracy: 0.8218 - val_loss: 0.5285 - val_accuracy: 0.7708\n",
            "Epoch 320/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4138 - accuracy: 0.8012 - val_loss: 0.5284 - val_accuracy: 0.7708\n",
            "Epoch 321/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4009 - accuracy: 0.8264 - val_loss: 0.5280 - val_accuracy: 0.7708\n",
            "Epoch 322/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4232 - accuracy: 0.7866 - val_loss: 0.5280 - val_accuracy: 0.7708\n",
            "Epoch 323/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3743 - accuracy: 0.8412 - val_loss: 0.5275 - val_accuracy: 0.7708\n",
            "Epoch 324/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3881 - accuracy: 0.8188 - val_loss: 0.5271 - val_accuracy: 0.7917\n",
            "Epoch 325/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4016 - accuracy: 0.8113 - val_loss: 0.5271 - val_accuracy: 0.7917\n",
            "Epoch 326/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4168 - accuracy: 0.8015 - val_loss: 0.5269 - val_accuracy: 0.7917\n",
            "Epoch 327/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4219 - accuracy: 0.7843 - val_loss: 0.5269 - val_accuracy: 0.7917\n",
            "Epoch 328/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4248 - accuracy: 0.8060 - val_loss: 0.5267 - val_accuracy: 0.7917\n",
            "Epoch 329/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.4300 - accuracy: 0.7924 - val_loss: 0.5267 - val_accuracy: 0.7917\n",
            "Epoch 330/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3642 - accuracy: 0.8286 - val_loss: 0.5262 - val_accuracy: 0.7917\n",
            "Epoch 331/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4540 - accuracy: 0.7783 - val_loss: 0.5261 - val_accuracy: 0.7917\n",
            "Epoch 332/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3885 - accuracy: 0.8025 - val_loss: 0.5258 - val_accuracy: 0.7917\n",
            "Epoch 333/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4144 - accuracy: 0.7895 - val_loss: 0.5255 - val_accuracy: 0.7917\n",
            "Epoch 334/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4132 - accuracy: 0.8170 - val_loss: 0.5253 - val_accuracy: 0.7917\n",
            "Epoch 335/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3815 - accuracy: 0.8140 - val_loss: 0.5251 - val_accuracy: 0.7917\n",
            "Epoch 336/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4222 - accuracy: 0.7962 - val_loss: 0.5251 - val_accuracy: 0.7917\n",
            "Epoch 337/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4162 - accuracy: 0.8098 - val_loss: 0.5247 - val_accuracy: 0.7917\n",
            "Epoch 338/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4456 - accuracy: 0.7851 - val_loss: 0.5245 - val_accuracy: 0.7917\n",
            "Epoch 339/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3893 - accuracy: 0.8066 - val_loss: 0.5242 - val_accuracy: 0.7917\n",
            "Epoch 340/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3751 - accuracy: 0.8082 - val_loss: 0.5238 - val_accuracy: 0.7917\n",
            "Epoch 341/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4241 - accuracy: 0.8067 - val_loss: 0.5240 - val_accuracy: 0.7917\n",
            "Epoch 342/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3893 - accuracy: 0.8161 - val_loss: 0.5235 - val_accuracy: 0.7917\n",
            "Epoch 343/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4112 - accuracy: 0.8129 - val_loss: 0.5233 - val_accuracy: 0.7917\n",
            "Epoch 344/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3624 - accuracy: 0.8275 - val_loss: 0.5229 - val_accuracy: 0.7917\n",
            "Epoch 345/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4136 - accuracy: 0.7945 - val_loss: 0.5228 - val_accuracy: 0.7917\n",
            "Epoch 346/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3740 - accuracy: 0.8268 - val_loss: 0.5227 - val_accuracy: 0.7917\n",
            "Epoch 347/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4115 - accuracy: 0.8014 - val_loss: 0.5224 - val_accuracy: 0.7917\n",
            "Epoch 348/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4113 - accuracy: 0.8083 - val_loss: 0.5223 - val_accuracy: 0.7917\n",
            "Epoch 349/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3396 - accuracy: 0.8467 - val_loss: 0.5216 - val_accuracy: 0.7917\n",
            "Epoch 350/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3744 - accuracy: 0.8328 - val_loss: 0.5218 - val_accuracy: 0.7917\n",
            "Epoch 351/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4032 - accuracy: 0.8091 - val_loss: 0.5218 - val_accuracy: 0.7917\n",
            "Epoch 352/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4215 - accuracy: 0.8055 - val_loss: 0.5216 - val_accuracy: 0.7917\n",
            "Epoch 353/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4021 - accuracy: 0.8018 - val_loss: 0.5214 - val_accuracy: 0.7917\n",
            "Epoch 354/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4318 - accuracy: 0.8033 - val_loss: 0.5217 - val_accuracy: 0.7917\n",
            "Epoch 355/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3732 - accuracy: 0.8266 - val_loss: 0.5211 - val_accuracy: 0.7917\n",
            "Epoch 356/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4234 - accuracy: 0.8220 - val_loss: 0.5212 - val_accuracy: 0.7917\n",
            "Epoch 357/1000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.3794 - accuracy: 0.8206 - val_loss: 0.5209 - val_accuracy: 0.7917\n",
            "Epoch 358/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.4215 - accuracy: 0.7823 - val_loss: 0.5207 - val_accuracy: 0.7917\n",
            "Epoch 359/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3780 - accuracy: 0.8406 - val_loss: 0.5206 - val_accuracy: 0.7917\n",
            "Epoch 360/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3958 - accuracy: 0.8200 - val_loss: 0.5204 - val_accuracy: 0.7917\n",
            "Epoch 361/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3512 - accuracy: 0.8457 - val_loss: 0.5199 - val_accuracy: 0.7917\n",
            "Epoch 362/1000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.4182 - accuracy: 0.7976 - val_loss: 0.5200 - val_accuracy: 0.7917\n",
            "Epoch 363/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3853 - accuracy: 0.7994 - val_loss: 0.5198 - val_accuracy: 0.7917\n",
            "Epoch 364/1000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.4151 - accuracy: 0.7848 - val_loss: 0.5198 - val_accuracy: 0.7917\n",
            "Epoch 365/1000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4357 - accuracy: 0.8015 - val_loss: 0.5197 - val_accuracy: 0.7917\n",
            "Epoch 366/1000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.4197 - accuracy: 0.8215 - val_loss: 0.5195 - val_accuracy: 0.7917\n",
            "Epoch 367/1000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.4144 - accuracy: 0.8130 - val_loss: 0.5194 - val_accuracy: 0.7917\n",
            "Epoch 368/1000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3625 - accuracy: 0.8392 - val_loss: 0.5191 - val_accuracy: 0.7917\n",
            "Epoch 369/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3787 - accuracy: 0.8078 - val_loss: 0.5187 - val_accuracy: 0.7917\n",
            "Epoch 370/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3866 - accuracy: 0.8357 - val_loss: 0.5184 - val_accuracy: 0.7917\n",
            "Epoch 371/1000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.4076 - accuracy: 0.8110 - val_loss: 0.5185 - val_accuracy: 0.7917\n",
            "Epoch 372/1000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.4444 - accuracy: 0.7955 - val_loss: 0.5186 - val_accuracy: 0.7917\n",
            "Epoch 373/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3693 - accuracy: 0.8404 - val_loss: 0.5182 - val_accuracy: 0.7917\n",
            "Epoch 374/1000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.4244 - accuracy: 0.8083 - val_loss: 0.5185 - val_accuracy: 0.7917\n",
            "Epoch 375/1000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.4007 - accuracy: 0.8296 - val_loss: 0.5186 - val_accuracy: 0.7917\n",
            "Epoch 376/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3506 - accuracy: 0.8511 - val_loss: 0.5182 - val_accuracy: 0.7917\n",
            "Epoch 377/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4036 - accuracy: 0.8046 - val_loss: 0.5181 - val_accuracy: 0.7917\n",
            "Epoch 378/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3762 - accuracy: 0.8492 - val_loss: 0.5181 - val_accuracy: 0.7917\n",
            "Epoch 379/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3804 - accuracy: 0.8234 - val_loss: 0.5179 - val_accuracy: 0.7917\n",
            "Epoch 380/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4111 - accuracy: 0.8052 - val_loss: 0.5178 - val_accuracy: 0.7917\n",
            "Epoch 381/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3958 - accuracy: 0.8316 - val_loss: 0.5179 - val_accuracy: 0.7917\n",
            "Epoch 382/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4146 - accuracy: 0.7959 - val_loss: 0.5178 - val_accuracy: 0.7917\n",
            "Epoch 383/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3839 - accuracy: 0.8166 - val_loss: 0.5175 - val_accuracy: 0.7917\n",
            "Epoch 384/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4026 - accuracy: 0.8181 - val_loss: 0.5171 - val_accuracy: 0.7917\n",
            "Epoch 385/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3635 - accuracy: 0.8474 - val_loss: 0.5166 - val_accuracy: 0.7917\n",
            "Epoch 386/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3836 - accuracy: 0.8364 - val_loss: 0.5165 - val_accuracy: 0.7917\n",
            "Epoch 387/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3773 - accuracy: 0.8352 - val_loss: 0.5166 - val_accuracy: 0.7917\n",
            "Epoch 388/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4169 - accuracy: 0.7875 - val_loss: 0.5166 - val_accuracy: 0.7917\n",
            "Epoch 389/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3519 - accuracy: 0.8436 - val_loss: 0.5162 - val_accuracy: 0.7917\n",
            "Epoch 390/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3545 - accuracy: 0.8493 - val_loss: 0.5158 - val_accuracy: 0.7917\n",
            "Epoch 391/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3955 - accuracy: 0.8208 - val_loss: 0.5156 - val_accuracy: 0.7917\n",
            "Epoch 392/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3785 - accuracy: 0.8226 - val_loss: 0.5155 - val_accuracy: 0.7917\n",
            "Epoch 393/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4057 - accuracy: 0.7965 - val_loss: 0.5153 - val_accuracy: 0.7917\n",
            "Epoch 394/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3763 - accuracy: 0.8166 - val_loss: 0.5149 - val_accuracy: 0.7917\n",
            "Epoch 395/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3585 - accuracy: 0.8529 - val_loss: 0.5147 - val_accuracy: 0.8125\n",
            "Epoch 396/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3539 - accuracy: 0.8476 - val_loss: 0.5147 - val_accuracy: 0.8125\n",
            "Epoch 397/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4339 - accuracy: 0.8116 - val_loss: 0.5148 - val_accuracy: 0.8125\n",
            "Epoch 398/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3609 - accuracy: 0.8283 - val_loss: 0.5146 - val_accuracy: 0.8125\n",
            "Epoch 399/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4031 - accuracy: 0.8062 - val_loss: 0.5145 - val_accuracy: 0.8125\n",
            "Epoch 400/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3475 - accuracy: 0.8520 - val_loss: 0.5141 - val_accuracy: 0.8125\n",
            "Epoch 401/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4203 - accuracy: 0.8235 - val_loss: 0.5140 - val_accuracy: 0.8125\n",
            "Epoch 402/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4023 - accuracy: 0.8308 - val_loss: 0.5139 - val_accuracy: 0.8125\n",
            "Epoch 403/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3858 - accuracy: 0.8295 - val_loss: 0.5136 - val_accuracy: 0.8125\n",
            "Epoch 404/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3505 - accuracy: 0.8528 - val_loss: 0.5133 - val_accuracy: 0.8125\n",
            "Epoch 405/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3622 - accuracy: 0.8536 - val_loss: 0.5129 - val_accuracy: 0.8125\n",
            "Epoch 406/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3778 - accuracy: 0.8372 - val_loss: 0.5124 - val_accuracy: 0.8125\n",
            "Epoch 407/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3784 - accuracy: 0.8423 - val_loss: 0.5123 - val_accuracy: 0.8125\n",
            "Epoch 408/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3879 - accuracy: 0.8403 - val_loss: 0.5122 - val_accuracy: 0.8125\n",
            "Epoch 409/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4020 - accuracy: 0.8233 - val_loss: 0.5118 - val_accuracy: 0.8125\n",
            "Epoch 410/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3732 - accuracy: 0.8321 - val_loss: 0.5117 - val_accuracy: 0.8125\n",
            "Epoch 411/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3349 - accuracy: 0.8464 - val_loss: 0.5117 - val_accuracy: 0.8125\n",
            "Epoch 412/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3759 - accuracy: 0.8201 - val_loss: 0.5117 - val_accuracy: 0.8125\n",
            "Epoch 413/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3939 - accuracy: 0.8319 - val_loss: 0.5118 - val_accuracy: 0.8125\n",
            "Epoch 414/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3527 - accuracy: 0.8381 - val_loss: 0.5113 - val_accuracy: 0.8125\n",
            "Epoch 415/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3724 - accuracy: 0.8187 - val_loss: 0.5111 - val_accuracy: 0.8125\n",
            "Epoch 416/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3813 - accuracy: 0.8413 - val_loss: 0.5111 - val_accuracy: 0.8125\n",
            "Epoch 417/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3745 - accuracy: 0.8390 - val_loss: 0.5109 - val_accuracy: 0.8125\n",
            "Epoch 418/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3833 - accuracy: 0.8293 - val_loss: 0.5110 - val_accuracy: 0.8125\n",
            "Epoch 419/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4282 - accuracy: 0.8152 - val_loss: 0.5110 - val_accuracy: 0.8125\n",
            "Epoch 420/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3464 - accuracy: 0.8523 - val_loss: 0.5106 - val_accuracy: 0.8125\n",
            "Epoch 421/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3552 - accuracy: 0.8378 - val_loss: 0.5100 - val_accuracy: 0.8125\n",
            "Epoch 422/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3446 - accuracy: 0.8634 - val_loss: 0.5096 - val_accuracy: 0.8125\n",
            "Epoch 423/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3333 - accuracy: 0.8503 - val_loss: 0.5094 - val_accuracy: 0.8125\n",
            "Epoch 424/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3964 - accuracy: 0.8334 - val_loss: 0.5093 - val_accuracy: 0.8125\n",
            "Epoch 425/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3888 - accuracy: 0.8248 - val_loss: 0.5094 - val_accuracy: 0.8125\n",
            "Epoch 426/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3620 - accuracy: 0.8510 - val_loss: 0.5093 - val_accuracy: 0.8125\n",
            "Epoch 427/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3840 - accuracy: 0.8317 - val_loss: 0.5091 - val_accuracy: 0.8125\n",
            "Epoch 428/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4062 - accuracy: 0.8098 - val_loss: 0.5088 - val_accuracy: 0.8125\n",
            "Epoch 429/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3845 - accuracy: 0.8158 - val_loss: 0.5087 - val_accuracy: 0.8125\n",
            "Epoch 430/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4090 - accuracy: 0.8106 - val_loss: 0.5087 - val_accuracy: 0.8125\n",
            "Epoch 431/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3742 - accuracy: 0.8237 - val_loss: 0.5087 - val_accuracy: 0.8125\n",
            "Epoch 432/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3462 - accuracy: 0.8600 - val_loss: 0.5081 - val_accuracy: 0.7917\n",
            "Epoch 433/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3563 - accuracy: 0.8524 - val_loss: 0.5078 - val_accuracy: 0.7917\n",
            "Epoch 434/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3634 - accuracy: 0.8474 - val_loss: 0.5075 - val_accuracy: 0.7917\n",
            "Epoch 435/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3408 - accuracy: 0.8398 - val_loss: 0.5074 - val_accuracy: 0.7917\n",
            "Epoch 436/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4051 - accuracy: 0.8285 - val_loss: 0.5073 - val_accuracy: 0.7917\n",
            "Epoch 437/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3519 - accuracy: 0.8586 - val_loss: 0.5070 - val_accuracy: 0.7917\n",
            "Epoch 438/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3657 - accuracy: 0.8430 - val_loss: 0.5066 - val_accuracy: 0.7917\n",
            "Epoch 439/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3943 - accuracy: 0.8352 - val_loss: 0.5065 - val_accuracy: 0.7917\n",
            "Epoch 440/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3364 - accuracy: 0.8412 - val_loss: 0.5062 - val_accuracy: 0.7917\n",
            "Epoch 441/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3769 - accuracy: 0.8261 - val_loss: 0.5065 - val_accuracy: 0.7917\n",
            "Epoch 442/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3642 - accuracy: 0.8366 - val_loss: 0.5063 - val_accuracy: 0.7917\n",
            "Epoch 443/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3473 - accuracy: 0.8413 - val_loss: 0.5058 - val_accuracy: 0.7917\n",
            "Epoch 444/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3466 - accuracy: 0.8585 - val_loss: 0.5058 - val_accuracy: 0.7917\n",
            "Epoch 445/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3443 - accuracy: 0.8499 - val_loss: 0.5051 - val_accuracy: 0.7917\n",
            "Epoch 446/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3523 - accuracy: 0.8458 - val_loss: 0.5053 - val_accuracy: 0.7917\n",
            "Epoch 447/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3622 - accuracy: 0.8455 - val_loss: 0.5057 - val_accuracy: 0.7917\n",
            "Epoch 448/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3607 - accuracy: 0.8535 - val_loss: 0.5055 - val_accuracy: 0.7917\n",
            "Epoch 449/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3457 - accuracy: 0.8527 - val_loss: 0.5051 - val_accuracy: 0.7917\n",
            "Epoch 450/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3763 - accuracy: 0.8447 - val_loss: 0.5049 - val_accuracy: 0.7917\n",
            "Epoch 451/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3694 - accuracy: 0.8392 - val_loss: 0.5051 - val_accuracy: 0.7917\n",
            "Epoch 452/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3730 - accuracy: 0.8349 - val_loss: 0.5050 - val_accuracy: 0.7917\n",
            "Epoch 453/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3922 - accuracy: 0.8108 - val_loss: 0.5048 - val_accuracy: 0.7917\n",
            "Epoch 454/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3985 - accuracy: 0.8327 - val_loss: 0.5048 - val_accuracy: 0.7917\n",
            "Epoch 455/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3794 - accuracy: 0.8181 - val_loss: 0.5048 - val_accuracy: 0.7917\n",
            "Epoch 456/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3758 - accuracy: 0.8338 - val_loss: 0.5042 - val_accuracy: 0.7917\n",
            "Epoch 457/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3274 - accuracy: 0.8595 - val_loss: 0.5038 - val_accuracy: 0.7917\n",
            "Epoch 458/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3576 - accuracy: 0.8352 - val_loss: 0.5039 - val_accuracy: 0.7917\n",
            "Epoch 459/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4076 - accuracy: 0.8123 - val_loss: 0.5043 - val_accuracy: 0.7917\n",
            "Epoch 460/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3948 - accuracy: 0.8258 - val_loss: 0.5041 - val_accuracy: 0.7917\n",
            "Epoch 461/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4103 - accuracy: 0.7972 - val_loss: 0.5043 - val_accuracy: 0.7917\n",
            "Epoch 462/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4149 - accuracy: 0.8186 - val_loss: 0.5043 - val_accuracy: 0.7917\n",
            "Epoch 463/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3918 - accuracy: 0.8053 - val_loss: 0.5040 - val_accuracy: 0.7917\n",
            "Epoch 464/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3576 - accuracy: 0.8328 - val_loss: 0.5035 - val_accuracy: 0.7917\n",
            "Epoch 465/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4069 - accuracy: 0.8070 - val_loss: 0.5033 - val_accuracy: 0.7917\n",
            "Epoch 466/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3532 - accuracy: 0.8483 - val_loss: 0.5030 - val_accuracy: 0.7917\n",
            "Epoch 467/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3890 - accuracy: 0.8094 - val_loss: 0.5028 - val_accuracy: 0.7917\n",
            "Epoch 468/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3601 - accuracy: 0.8479 - val_loss: 0.5028 - val_accuracy: 0.7917\n",
            "Epoch 469/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3292 - accuracy: 0.8593 - val_loss: 0.5023 - val_accuracy: 0.7917\n",
            "Epoch 470/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3829 - accuracy: 0.8287 - val_loss: 0.5020 - val_accuracy: 0.7917\n",
            "Epoch 471/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3926 - accuracy: 0.8254 - val_loss: 0.5022 - val_accuracy: 0.7917\n",
            "Epoch 472/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3908 - accuracy: 0.8257 - val_loss: 0.5021 - val_accuracy: 0.7917\n",
            "Epoch 473/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3655 - accuracy: 0.8348 - val_loss: 0.5018 - val_accuracy: 0.7917\n",
            "Epoch 474/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3743 - accuracy: 0.8430 - val_loss: 0.5017 - val_accuracy: 0.7917\n",
            "Epoch 475/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3720 - accuracy: 0.8352 - val_loss: 0.5017 - val_accuracy: 0.7917\n",
            "Epoch 476/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3872 - accuracy: 0.8396 - val_loss: 0.5016 - val_accuracy: 0.7917\n",
            "Epoch 477/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3327 - accuracy: 0.8456 - val_loss: 0.5013 - val_accuracy: 0.7917\n",
            "Epoch 478/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3575 - accuracy: 0.8498 - val_loss: 0.5007 - val_accuracy: 0.7917\n",
            "Epoch 479/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3338 - accuracy: 0.8575 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
            "Epoch 480/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4069 - accuracy: 0.8117 - val_loss: 0.5005 - val_accuracy: 0.7917\n",
            "Epoch 481/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3794 - accuracy: 0.8482 - val_loss: 0.5006 - val_accuracy: 0.7917\n",
            "Epoch 482/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4042 - accuracy: 0.8012 - val_loss: 0.5004 - val_accuracy: 0.7917\n",
            "Epoch 483/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3811 - accuracy: 0.8280 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
            "Epoch 484/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3832 - accuracy: 0.8418 - val_loss: 0.4999 - val_accuracy: 0.7917\n",
            "Epoch 485/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3982 - accuracy: 0.8210 - val_loss: 0.5001 - val_accuracy: 0.7917\n",
            "Epoch 486/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3627 - accuracy: 0.8285 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
            "Epoch 487/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4008 - accuracy: 0.8152 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
            "Epoch 488/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3665 - accuracy: 0.8176 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
            "Epoch 489/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4132 - accuracy: 0.8047 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
            "Epoch 490/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3553 - accuracy: 0.8475 - val_loss: 0.4994 - val_accuracy: 0.7917\n",
            "Epoch 491/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3661 - accuracy: 0.8528 - val_loss: 0.4993 - val_accuracy: 0.7917\n",
            "Epoch 492/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3719 - accuracy: 0.8312 - val_loss: 0.4993 - val_accuracy: 0.7917\n",
            "Epoch 493/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3503 - accuracy: 0.8378 - val_loss: 0.4988 - val_accuracy: 0.7917\n",
            "Epoch 494/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3681 - accuracy: 0.8493 - val_loss: 0.4992 - val_accuracy: 0.7917\n",
            "Epoch 495/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3851 - accuracy: 0.8132 - val_loss: 0.4992 - val_accuracy: 0.7917\n",
            "Epoch 496/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3775 - accuracy: 0.8257 - val_loss: 0.4989 - val_accuracy: 0.7917\n",
            "Epoch 497/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3687 - accuracy: 0.8443 - val_loss: 0.4983 - val_accuracy: 0.7917\n",
            "Epoch 498/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3685 - accuracy: 0.8413 - val_loss: 0.4985 - val_accuracy: 0.7917\n",
            "Epoch 499/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3477 - accuracy: 0.8533 - val_loss: 0.4983 - val_accuracy: 0.7917\n",
            "Epoch 500/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3855 - accuracy: 0.8338 - val_loss: 0.4984 - val_accuracy: 0.7917\n",
            "Epoch 501/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3543 - accuracy: 0.8620 - val_loss: 0.4982 - val_accuracy: 0.7917\n",
            "Epoch 502/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3446 - accuracy: 0.8582 - val_loss: 0.4979 - val_accuracy: 0.7917\n",
            "Epoch 503/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3758 - accuracy: 0.8106 - val_loss: 0.4977 - val_accuracy: 0.7917\n",
            "Epoch 504/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3573 - accuracy: 0.8541 - val_loss: 0.4973 - val_accuracy: 0.7917\n",
            "Epoch 505/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4064 - accuracy: 0.8155 - val_loss: 0.4976 - val_accuracy: 0.7917\n",
            "Epoch 506/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3534 - accuracy: 0.8399 - val_loss: 0.4976 - val_accuracy: 0.7917\n",
            "Epoch 507/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3227 - accuracy: 0.8822 - val_loss: 0.4973 - val_accuracy: 0.7917\n",
            "Epoch 508/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3445 - accuracy: 0.8664 - val_loss: 0.4970 - val_accuracy: 0.7917\n",
            "Epoch 509/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3743 - accuracy: 0.8477 - val_loss: 0.4970 - val_accuracy: 0.7917\n",
            "Epoch 510/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3827 - accuracy: 0.8373 - val_loss: 0.4967 - val_accuracy: 0.7917\n",
            "Epoch 511/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3666 - accuracy: 0.8289 - val_loss: 0.4970 - val_accuracy: 0.7917\n",
            "Epoch 512/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3738 - accuracy: 0.8502 - val_loss: 0.4969 - val_accuracy: 0.7917\n",
            "Epoch 513/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3830 - accuracy: 0.8200 - val_loss: 0.4966 - val_accuracy: 0.7917\n",
            "Epoch 514/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4166 - accuracy: 0.8158 - val_loss: 0.4962 - val_accuracy: 0.7917\n",
            "Epoch 515/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3190 - accuracy: 0.8681 - val_loss: 0.4961 - val_accuracy: 0.7917\n",
            "Epoch 516/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3458 - accuracy: 0.8663 - val_loss: 0.4958 - val_accuracy: 0.7917\n",
            "Epoch 517/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4343 - accuracy: 0.8196 - val_loss: 0.4961 - val_accuracy: 0.7917\n",
            "Epoch 518/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3176 - accuracy: 0.8656 - val_loss: 0.4959 - val_accuracy: 0.7917\n",
            "Epoch 519/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3714 - accuracy: 0.8401 - val_loss: 0.4959 - val_accuracy: 0.7917\n",
            "Epoch 520/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4073 - accuracy: 0.8075 - val_loss: 0.4962 - val_accuracy: 0.7917\n",
            "Epoch 521/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3494 - accuracy: 0.8517 - val_loss: 0.4959 - val_accuracy: 0.7917\n",
            "Epoch 522/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3711 - accuracy: 0.8253 - val_loss: 0.4961 - val_accuracy: 0.7917\n",
            "Epoch 523/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3514 - accuracy: 0.8481 - val_loss: 0.4960 - val_accuracy: 0.7917\n",
            "Epoch 524/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3566 - accuracy: 0.8612 - val_loss: 0.4956 - val_accuracy: 0.7917\n",
            "Epoch 525/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3867 - accuracy: 0.8386 - val_loss: 0.4961 - val_accuracy: 0.7917\n",
            "Epoch 526/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3195 - accuracy: 0.8777 - val_loss: 0.4957 - val_accuracy: 0.7917\n",
            "Epoch 527/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3438 - accuracy: 0.8554 - val_loss: 0.4954 - val_accuracy: 0.7917\n",
            "Epoch 528/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3641 - accuracy: 0.8580 - val_loss: 0.4956 - val_accuracy: 0.7917\n",
            "Epoch 529/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3919 - accuracy: 0.8242 - val_loss: 0.4959 - val_accuracy: 0.7917\n",
            "Epoch 530/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3573 - accuracy: 0.8467 - val_loss: 0.4956 - val_accuracy: 0.7917\n",
            "Epoch 531/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3822 - accuracy: 0.8373 - val_loss: 0.4952 - val_accuracy: 0.7917\n",
            "Epoch 532/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4194 - accuracy: 0.8035 - val_loss: 0.4948 - val_accuracy: 0.7917\n",
            "Epoch 533/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3497 - accuracy: 0.8497 - val_loss: 0.4947 - val_accuracy: 0.7917\n",
            "Epoch 534/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3529 - accuracy: 0.8506 - val_loss: 0.4946 - val_accuracy: 0.7917\n",
            "Epoch 535/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3693 - accuracy: 0.8554 - val_loss: 0.4944 - val_accuracy: 0.7917\n",
            "Epoch 536/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3485 - accuracy: 0.8480 - val_loss: 0.4942 - val_accuracy: 0.7917\n",
            "Epoch 537/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3466 - accuracy: 0.8441 - val_loss: 0.4944 - val_accuracy: 0.7917\n",
            "Epoch 538/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3662 - accuracy: 0.8498 - val_loss: 0.4946 - val_accuracy: 0.7917\n",
            "Epoch 539/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3566 - accuracy: 0.8513 - val_loss: 0.4945 - val_accuracy: 0.7917\n",
            "Epoch 540/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3475 - accuracy: 0.8549 - val_loss: 0.4945 - val_accuracy: 0.7917\n",
            "Epoch 541/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3362 - accuracy: 0.8711 - val_loss: 0.4946 - val_accuracy: 0.7917\n",
            "Epoch 542/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3406 - accuracy: 0.8809 - val_loss: 0.4943 - val_accuracy: 0.7917\n",
            "Epoch 543/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3552 - accuracy: 0.8511 - val_loss: 0.4940 - val_accuracy: 0.7917\n",
            "Epoch 544/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3939 - accuracy: 0.8399 - val_loss: 0.4940 - val_accuracy: 0.7917\n",
            "Epoch 545/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3755 - accuracy: 0.8367 - val_loss: 0.4941 - val_accuracy: 0.7917\n",
            "Epoch 546/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3565 - accuracy: 0.8385 - val_loss: 0.4937 - val_accuracy: 0.7917\n",
            "Epoch 547/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3654 - accuracy: 0.8540 - val_loss: 0.4938 - val_accuracy: 0.7917\n",
            "Epoch 548/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3538 - accuracy: 0.8579 - val_loss: 0.4934 - val_accuracy: 0.7917\n",
            "Epoch 549/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3514 - accuracy: 0.8584 - val_loss: 0.4935 - val_accuracy: 0.7917\n",
            "Epoch 550/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3860 - accuracy: 0.8254 - val_loss: 0.4936 - val_accuracy: 0.7917\n",
            "Epoch 551/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4042 - accuracy: 0.8202 - val_loss: 0.4934 - val_accuracy: 0.7917\n",
            "Epoch 552/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3814 - accuracy: 0.8257 - val_loss: 0.4932 - val_accuracy: 0.7917\n",
            "Epoch 553/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3819 - accuracy: 0.8173 - val_loss: 0.4927 - val_accuracy: 0.7917\n",
            "Epoch 554/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3795 - accuracy: 0.8308 - val_loss: 0.4932 - val_accuracy: 0.7917\n",
            "Epoch 555/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3683 - accuracy: 0.8577 - val_loss: 0.4935 - val_accuracy: 0.7917\n",
            "Epoch 556/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3716 - accuracy: 0.8277 - val_loss: 0.4933 - val_accuracy: 0.7917\n",
            "Epoch 557/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3658 - accuracy: 0.8577 - val_loss: 0.4934 - val_accuracy: 0.7917\n",
            "Epoch 558/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3081 - accuracy: 0.8927 - val_loss: 0.4930 - val_accuracy: 0.7917\n",
            "Epoch 559/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3580 - accuracy: 0.8526 - val_loss: 0.4928 - val_accuracy: 0.7917\n",
            "Epoch 560/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4556 - accuracy: 0.7876 - val_loss: 0.4929 - val_accuracy: 0.7917\n",
            "Epoch 561/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3630 - accuracy: 0.8247 - val_loss: 0.4927 - val_accuracy: 0.7917\n",
            "Epoch 562/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3654 - accuracy: 0.8440 - val_loss: 0.4930 - val_accuracy: 0.7917\n",
            "Epoch 563/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3322 - accuracy: 0.8527 - val_loss: 0.4925 - val_accuracy: 0.7917\n",
            "Epoch 564/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3349 - accuracy: 0.8690 - val_loss: 0.4924 - val_accuracy: 0.7917\n",
            "Epoch 565/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3527 - accuracy: 0.8551 - val_loss: 0.4924 - val_accuracy: 0.7917\n",
            "Epoch 566/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3366 - accuracy: 0.8896 - val_loss: 0.4923 - val_accuracy: 0.7917\n",
            "Epoch 567/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3445 - accuracy: 0.8536 - val_loss: 0.4919 - val_accuracy: 0.7917\n",
            "Epoch 568/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3552 - accuracy: 0.8388 - val_loss: 0.4916 - val_accuracy: 0.7917\n",
            "Epoch 569/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3691 - accuracy: 0.8372 - val_loss: 0.4915 - val_accuracy: 0.7917\n",
            "Epoch 570/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3895 - accuracy: 0.8318 - val_loss: 0.4916 - val_accuracy: 0.7917\n",
            "Epoch 571/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3912 - accuracy: 0.8467 - val_loss: 0.4918 - val_accuracy: 0.7917\n",
            "Epoch 572/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3346 - accuracy: 0.8542 - val_loss: 0.4915 - val_accuracy: 0.7917\n",
            "Epoch 573/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3211 - accuracy: 0.8807 - val_loss: 0.4915 - val_accuracy: 0.7917\n",
            "Epoch 574/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3725 - accuracy: 0.8449 - val_loss: 0.4914 - val_accuracy: 0.7917\n",
            "Epoch 575/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3865 - accuracy: 0.8268 - val_loss: 0.4916 - val_accuracy: 0.7917\n",
            "Epoch 576/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3296 - accuracy: 0.8644 - val_loss: 0.4916 - val_accuracy: 0.7917\n",
            "Epoch 577/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3878 - accuracy: 0.8532 - val_loss: 0.4919 - val_accuracy: 0.7917\n",
            "Epoch 578/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3596 - accuracy: 0.8505 - val_loss: 0.4917 - val_accuracy: 0.7917\n",
            "Epoch 579/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3413 - accuracy: 0.8502 - val_loss: 0.4914 - val_accuracy: 0.7917\n",
            "Epoch 580/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3517 - accuracy: 0.8535 - val_loss: 0.4914 - val_accuracy: 0.7917\n",
            "Epoch 581/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3665 - accuracy: 0.8260 - val_loss: 0.4912 - val_accuracy: 0.7917\n",
            "Epoch 582/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3678 - accuracy: 0.8272 - val_loss: 0.4915 - val_accuracy: 0.7917\n",
            "Epoch 583/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3399 - accuracy: 0.8533 - val_loss: 0.4911 - val_accuracy: 0.7917\n",
            "Epoch 584/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3964 - accuracy: 0.8174 - val_loss: 0.4910 - val_accuracy: 0.7917\n",
            "Epoch 585/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3879 - accuracy: 0.8207 - val_loss: 0.4908 - val_accuracy: 0.7917\n",
            "Epoch 586/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3663 - accuracy: 0.8405 - val_loss: 0.4911 - val_accuracy: 0.7917\n",
            "Epoch 587/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3778 - accuracy: 0.8453 - val_loss: 0.4911 - val_accuracy: 0.7917\n",
            "Epoch 588/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3403 - accuracy: 0.8661 - val_loss: 0.4908 - val_accuracy: 0.7917\n",
            "Epoch 589/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4113 - accuracy: 0.8167 - val_loss: 0.4907 - val_accuracy: 0.7917\n",
            "Epoch 590/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3358 - accuracy: 0.8552 - val_loss: 0.4907 - val_accuracy: 0.7917\n",
            "Epoch 591/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3507 - accuracy: 0.8678 - val_loss: 0.4904 - val_accuracy: 0.7917\n",
            "Epoch 592/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3808 - accuracy: 0.8416 - val_loss: 0.4907 - val_accuracy: 0.7917\n",
            "Epoch 593/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3729 - accuracy: 0.8332 - val_loss: 0.4911 - val_accuracy: 0.7917\n",
            "Epoch 594/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3606 - accuracy: 0.8378 - val_loss: 0.4908 - val_accuracy: 0.7917\n",
            "Epoch 595/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3571 - accuracy: 0.8621 - val_loss: 0.4906 - val_accuracy: 0.7917\n",
            "Epoch 596/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3702 - accuracy: 0.8388 - val_loss: 0.4904 - val_accuracy: 0.7917\n",
            "Epoch 597/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3225 - accuracy: 0.8765 - val_loss: 0.4900 - val_accuracy: 0.7917\n",
            "Epoch 598/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3609 - accuracy: 0.8544 - val_loss: 0.4895 - val_accuracy: 0.7917\n",
            "Epoch 599/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3662 - accuracy: 0.8428 - val_loss: 0.4898 - val_accuracy: 0.7917\n",
            "Epoch 600/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3858 - accuracy: 0.8302 - val_loss: 0.4897 - val_accuracy: 0.7917\n",
            "Epoch 601/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3388 - accuracy: 0.8571 - val_loss: 0.4898 - val_accuracy: 0.7917\n",
            "Epoch 602/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3637 - accuracy: 0.8286 - val_loss: 0.4897 - val_accuracy: 0.7917\n",
            "Epoch 603/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3439 - accuracy: 0.8629 - val_loss: 0.4894 - val_accuracy: 0.7917\n",
            "Epoch 604/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3723 - accuracy: 0.8455 - val_loss: 0.4896 - val_accuracy: 0.7917\n",
            "Epoch 605/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3371 - accuracy: 0.8517 - val_loss: 0.4893 - val_accuracy: 0.7917\n",
            "Epoch 606/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3381 - accuracy: 0.8485 - val_loss: 0.4891 - val_accuracy: 0.7917\n",
            "Epoch 607/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3479 - accuracy: 0.8567 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
            "Epoch 608/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3695 - accuracy: 0.8261 - val_loss: 0.4885 - val_accuracy: 0.7917\n",
            "Epoch 609/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3255 - accuracy: 0.8542 - val_loss: 0.4885 - val_accuracy: 0.7917\n",
            "Epoch 610/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3624 - accuracy: 0.8451 - val_loss: 0.4885 - val_accuracy: 0.7917\n",
            "Epoch 611/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3374 - accuracy: 0.8524 - val_loss: 0.4882 - val_accuracy: 0.7917\n",
            "Epoch 612/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3668 - accuracy: 0.8366 - val_loss: 0.4883 - val_accuracy: 0.7917\n",
            "Epoch 613/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3978 - accuracy: 0.8274 - val_loss: 0.4883 - val_accuracy: 0.7917\n",
            "Epoch 614/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3914 - accuracy: 0.8263 - val_loss: 0.4885 - val_accuracy: 0.7917\n",
            "Epoch 615/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3689 - accuracy: 0.8559 - val_loss: 0.4885 - val_accuracy: 0.7917\n",
            "Epoch 616/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3603 - accuracy: 0.8489 - val_loss: 0.4883 - val_accuracy: 0.7917\n",
            "Epoch 617/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3655 - accuracy: 0.8280 - val_loss: 0.4883 - val_accuracy: 0.7917\n",
            "Epoch 618/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3063 - accuracy: 0.8713 - val_loss: 0.4882 - val_accuracy: 0.7917\n",
            "Epoch 619/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3560 - accuracy: 0.8591 - val_loss: 0.4885 - val_accuracy: 0.7917\n",
            "Epoch 620/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3429 - accuracy: 0.8612 - val_loss: 0.4883 - val_accuracy: 0.7917\n",
            "Epoch 621/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3607 - accuracy: 0.8323 - val_loss: 0.4881 - val_accuracy: 0.7917\n",
            "Epoch 622/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3854 - accuracy: 0.8300 - val_loss: 0.4880 - val_accuracy: 0.7917\n",
            "Epoch 623/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3639 - accuracy: 0.8557 - val_loss: 0.4886 - val_accuracy: 0.7917\n",
            "Epoch 624/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3688 - accuracy: 0.8542 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
            "Epoch 625/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3900 - accuracy: 0.8314 - val_loss: 0.4885 - val_accuracy: 0.7917\n",
            "Epoch 626/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3801 - accuracy: 0.8237 - val_loss: 0.4883 - val_accuracy: 0.7917\n",
            "Epoch 627/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3132 - accuracy: 0.8732 - val_loss: 0.4879 - val_accuracy: 0.7917\n",
            "Epoch 628/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3599 - accuracy: 0.8521 - val_loss: 0.4873 - val_accuracy: 0.7917\n",
            "Epoch 629/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3405 - accuracy: 0.8576 - val_loss: 0.4871 - val_accuracy: 0.7917\n",
            "Epoch 630/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3779 - accuracy: 0.8323 - val_loss: 0.4869 - val_accuracy: 0.7917\n",
            "Epoch 631/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3837 - accuracy: 0.8414 - val_loss: 0.4868 - val_accuracy: 0.7917\n",
            "Epoch 632/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3636 - accuracy: 0.8550 - val_loss: 0.4865 - val_accuracy: 0.7917\n",
            "Epoch 633/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3690 - accuracy: 0.8467 - val_loss: 0.4864 - val_accuracy: 0.7917\n",
            "Epoch 634/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3510 - accuracy: 0.8487 - val_loss: 0.4864 - val_accuracy: 0.7917\n",
            "Epoch 635/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3373 - accuracy: 0.8587 - val_loss: 0.4863 - val_accuracy: 0.7917\n",
            "Epoch 636/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3915 - accuracy: 0.8183 - val_loss: 0.4861 - val_accuracy: 0.7917\n",
            "Epoch 637/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3705 - accuracy: 0.8293 - val_loss: 0.4858 - val_accuracy: 0.7917\n",
            "Epoch 638/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3453 - accuracy: 0.8329 - val_loss: 0.4856 - val_accuracy: 0.7917\n",
            "Epoch 639/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3372 - accuracy: 0.8632 - val_loss: 0.4855 - val_accuracy: 0.7917\n",
            "Epoch 640/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3239 - accuracy: 0.8753 - val_loss: 0.4853 - val_accuracy: 0.7917\n",
            "Epoch 641/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3854 - accuracy: 0.8209 - val_loss: 0.4855 - val_accuracy: 0.7917\n",
            "Epoch 642/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3696 - accuracy: 0.8387 - val_loss: 0.4854 - val_accuracy: 0.7917\n",
            "Epoch 643/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3672 - accuracy: 0.8298 - val_loss: 0.4854 - val_accuracy: 0.7917\n",
            "Epoch 644/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3648 - accuracy: 0.8214 - val_loss: 0.4851 - val_accuracy: 0.7917\n",
            "Epoch 645/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3293 - accuracy: 0.8612 - val_loss: 0.4847 - val_accuracy: 0.7917\n",
            "Epoch 646/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3535 - accuracy: 0.8586 - val_loss: 0.4843 - val_accuracy: 0.7917\n",
            "Epoch 647/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3707 - accuracy: 0.8441 - val_loss: 0.4842 - val_accuracy: 0.7917\n",
            "Epoch 648/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4077 - accuracy: 0.8200 - val_loss: 0.4840 - val_accuracy: 0.7917\n",
            "Epoch 649/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3913 - accuracy: 0.8225 - val_loss: 0.4837 - val_accuracy: 0.7917\n",
            "Epoch 650/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3538 - accuracy: 0.8428 - val_loss: 0.4836 - val_accuracy: 0.7917\n",
            "Epoch 651/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3851 - accuracy: 0.8417 - val_loss: 0.4836 - val_accuracy: 0.7917\n",
            "Epoch 652/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3318 - accuracy: 0.8577 - val_loss: 0.4832 - val_accuracy: 0.7917\n",
            "Epoch 653/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3936 - accuracy: 0.8198 - val_loss: 0.4833 - val_accuracy: 0.7917\n",
            "Epoch 654/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3450 - accuracy: 0.8339 - val_loss: 0.4830 - val_accuracy: 0.7917\n",
            "Epoch 655/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3601 - accuracy: 0.8395 - val_loss: 0.4826 - val_accuracy: 0.7917\n",
            "Epoch 656/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3691 - accuracy: 0.8477 - val_loss: 0.4824 - val_accuracy: 0.7917\n",
            "Epoch 657/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3434 - accuracy: 0.8515 - val_loss: 0.4823 - val_accuracy: 0.7917\n",
            "Epoch 658/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3534 - accuracy: 0.8507 - val_loss: 0.4820 - val_accuracy: 0.7917\n",
            "Epoch 659/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3699 - accuracy: 0.8489 - val_loss: 0.4816 - val_accuracy: 0.7917\n",
            "Epoch 660/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4219 - accuracy: 0.8080 - val_loss: 0.4817 - val_accuracy: 0.7917\n",
            "Epoch 661/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3288 - accuracy: 0.8565 - val_loss: 0.4818 - val_accuracy: 0.7917\n",
            "Epoch 662/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3724 - accuracy: 0.8345 - val_loss: 0.4816 - val_accuracy: 0.7917\n",
            "Epoch 663/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3387 - accuracy: 0.8468 - val_loss: 0.4814 - val_accuracy: 0.7917\n",
            "Epoch 664/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4291 - accuracy: 0.8131 - val_loss: 0.4814 - val_accuracy: 0.7917\n",
            "Epoch 665/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3586 - accuracy: 0.8465 - val_loss: 0.4816 - val_accuracy: 0.7917\n",
            "Epoch 666/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3567 - accuracy: 0.8502 - val_loss: 0.4816 - val_accuracy: 0.7917\n",
            "Epoch 667/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3919 - accuracy: 0.8199 - val_loss: 0.4815 - val_accuracy: 0.7917\n",
            "Epoch 668/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3784 - accuracy: 0.8501 - val_loss: 0.4816 - val_accuracy: 0.7917\n",
            "Epoch 669/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3385 - accuracy: 0.8597 - val_loss: 0.4813 - val_accuracy: 0.7917\n",
            "Epoch 670/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3668 - accuracy: 0.8401 - val_loss: 0.4812 - val_accuracy: 0.7917\n",
            "Epoch 671/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3849 - accuracy: 0.8397 - val_loss: 0.4812 - val_accuracy: 0.7917\n",
            "Epoch 672/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3582 - accuracy: 0.8478 - val_loss: 0.4807 - val_accuracy: 0.7917\n",
            "Epoch 673/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3449 - accuracy: 0.8564 - val_loss: 0.4803 - val_accuracy: 0.7917\n",
            "Epoch 674/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3581 - accuracy: 0.8379 - val_loss: 0.4802 - val_accuracy: 0.7917\n",
            "Epoch 675/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3031 - accuracy: 0.8755 - val_loss: 0.4801 - val_accuracy: 0.7917\n",
            "Epoch 676/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3979 - accuracy: 0.8133 - val_loss: 0.4801 - val_accuracy: 0.7917\n",
            "Epoch 677/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3846 - accuracy: 0.8471 - val_loss: 0.4799 - val_accuracy: 0.7917\n",
            "Epoch 678/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3270 - accuracy: 0.8637 - val_loss: 0.4791 - val_accuracy: 0.7917\n",
            "Epoch 679/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3367 - accuracy: 0.8727 - val_loss: 0.4791 - val_accuracy: 0.7917\n",
            "Epoch 680/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4133 - accuracy: 0.8019 - val_loss: 0.4793 - val_accuracy: 0.7917\n",
            "Epoch 681/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3753 - accuracy: 0.8271 - val_loss: 0.4793 - val_accuracy: 0.7917\n",
            "Epoch 682/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3493 - accuracy: 0.8403 - val_loss: 0.4789 - val_accuracy: 0.7917\n",
            "Epoch 683/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3539 - accuracy: 0.8315 - val_loss: 0.4792 - val_accuracy: 0.7917\n",
            "Epoch 684/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4108 - accuracy: 0.8086 - val_loss: 0.4790 - val_accuracy: 0.7917\n",
            "Epoch 685/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3710 - accuracy: 0.8441 - val_loss: 0.4789 - val_accuracy: 0.7917\n",
            "Epoch 686/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4111 - accuracy: 0.8244 - val_loss: 0.4786 - val_accuracy: 0.7917\n",
            "Epoch 687/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3644 - accuracy: 0.8391 - val_loss: 0.4783 - val_accuracy: 0.7917\n",
            "Epoch 688/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3652 - accuracy: 0.8341 - val_loss: 0.4774 - val_accuracy: 0.7917\n",
            "Epoch 689/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4048 - accuracy: 0.8055 - val_loss: 0.4772 - val_accuracy: 0.7917\n",
            "Epoch 690/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3838 - accuracy: 0.8408 - val_loss: 0.4768 - val_accuracy: 0.7917\n",
            "Epoch 691/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3652 - accuracy: 0.8405 - val_loss: 0.4765 - val_accuracy: 0.7917\n",
            "Epoch 692/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3691 - accuracy: 0.8345 - val_loss: 0.4766 - val_accuracy: 0.7917\n",
            "Epoch 693/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3593 - accuracy: 0.8429 - val_loss: 0.4764 - val_accuracy: 0.7917\n",
            "Epoch 694/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4041 - accuracy: 0.8301 - val_loss: 0.4758 - val_accuracy: 0.7917\n",
            "Epoch 695/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3357 - accuracy: 0.8552 - val_loss: 0.4752 - val_accuracy: 0.7917\n",
            "Epoch 696/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3109 - accuracy: 0.8635 - val_loss: 0.4747 - val_accuracy: 0.7917\n",
            "Epoch 697/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3869 - accuracy: 0.8156 - val_loss: 0.4745 - val_accuracy: 0.7917\n",
            "Epoch 698/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3416 - accuracy: 0.8622 - val_loss: 0.4744 - val_accuracy: 0.7917\n",
            "Epoch 699/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3125 - accuracy: 0.8880 - val_loss: 0.4740 - val_accuracy: 0.7917\n",
            "Epoch 700/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3431 - accuracy: 0.8461 - val_loss: 0.4741 - val_accuracy: 0.7917\n",
            "Epoch 701/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3599 - accuracy: 0.8367 - val_loss: 0.4741 - val_accuracy: 0.7917\n",
            "Epoch 702/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3793 - accuracy: 0.8335 - val_loss: 0.4739 - val_accuracy: 0.7917\n",
            "Epoch 703/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3610 - accuracy: 0.8471 - val_loss: 0.4738 - val_accuracy: 0.7917\n",
            "Epoch 704/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3436 - accuracy: 0.8506 - val_loss: 0.4734 - val_accuracy: 0.7917\n",
            "Epoch 705/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3407 - accuracy: 0.8536 - val_loss: 0.4731 - val_accuracy: 0.7917\n",
            "Epoch 706/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3915 - accuracy: 0.8257 - val_loss: 0.4731 - val_accuracy: 0.7917\n",
            "Epoch 707/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3574 - accuracy: 0.8328 - val_loss: 0.4729 - val_accuracy: 0.7917\n",
            "Epoch 708/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3509 - accuracy: 0.8528 - val_loss: 0.4726 - val_accuracy: 0.7917\n",
            "Epoch 709/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3749 - accuracy: 0.8393 - val_loss: 0.4724 - val_accuracy: 0.7917\n",
            "Epoch 710/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3905 - accuracy: 0.8164 - val_loss: 0.4725 - val_accuracy: 0.7917\n",
            "Epoch 711/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3435 - accuracy: 0.8491 - val_loss: 0.4718 - val_accuracy: 0.7917\n",
            "Epoch 712/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3645 - accuracy: 0.8255 - val_loss: 0.4715 - val_accuracy: 0.7917\n",
            "Epoch 713/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3274 - accuracy: 0.8460 - val_loss: 0.4715 - val_accuracy: 0.7917\n",
            "Epoch 714/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3801 - accuracy: 0.8410 - val_loss: 0.4713 - val_accuracy: 0.7917\n",
            "Epoch 715/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3544 - accuracy: 0.8367 - val_loss: 0.4713 - val_accuracy: 0.7917\n",
            "Epoch 716/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3608 - accuracy: 0.8324 - val_loss: 0.4712 - val_accuracy: 0.7917\n",
            "Epoch 717/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3802 - accuracy: 0.8368 - val_loss: 0.4712 - val_accuracy: 0.7917\n",
            "Epoch 718/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3523 - accuracy: 0.8427 - val_loss: 0.4713 - val_accuracy: 0.7917\n",
            "Epoch 719/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4108 - accuracy: 0.8120 - val_loss: 0.4714 - val_accuracy: 0.7917\n",
            "Epoch 720/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3497 - accuracy: 0.8412 - val_loss: 0.4704 - val_accuracy: 0.7917\n",
            "Epoch 721/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3760 - accuracy: 0.8439 - val_loss: 0.4703 - val_accuracy: 0.7917\n",
            "Epoch 722/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3555 - accuracy: 0.8250 - val_loss: 0.4703 - val_accuracy: 0.7917\n",
            "Epoch 723/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3338 - accuracy: 0.8365 - val_loss: 0.4700 - val_accuracy: 0.7917\n",
            "Epoch 724/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3547 - accuracy: 0.8472 - val_loss: 0.4700 - val_accuracy: 0.7917\n",
            "Epoch 725/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3628 - accuracy: 0.8328 - val_loss: 0.4696 - val_accuracy: 0.7917\n",
            "Epoch 726/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3281 - accuracy: 0.8561 - val_loss: 0.4692 - val_accuracy: 0.7917\n",
            "Epoch 727/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3423 - accuracy: 0.8431 - val_loss: 0.4689 - val_accuracy: 0.7917\n",
            "Epoch 728/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3304 - accuracy: 0.8756 - val_loss: 0.4684 - val_accuracy: 0.7917\n",
            "Epoch 729/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3772 - accuracy: 0.8183 - val_loss: 0.4682 - val_accuracy: 0.7917\n",
            "Epoch 730/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3658 - accuracy: 0.8338 - val_loss: 0.4678 - val_accuracy: 0.7917\n",
            "Epoch 731/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3291 - accuracy: 0.8669 - val_loss: 0.4675 - val_accuracy: 0.7917\n",
            "Epoch 732/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3081 - accuracy: 0.8749 - val_loss: 0.4671 - val_accuracy: 0.7917\n",
            "Epoch 733/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3451 - accuracy: 0.8637 - val_loss: 0.4666 - val_accuracy: 0.7917\n",
            "Epoch 734/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3218 - accuracy: 0.8612 - val_loss: 0.4662 - val_accuracy: 0.7917\n",
            "Epoch 735/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3863 - accuracy: 0.8461 - val_loss: 0.4664 - val_accuracy: 0.7917\n",
            "Epoch 736/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4103 - accuracy: 0.8181 - val_loss: 0.4659 - val_accuracy: 0.7917\n",
            "Epoch 737/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3539 - accuracy: 0.8527 - val_loss: 0.4659 - val_accuracy: 0.7917\n",
            "Epoch 738/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3739 - accuracy: 0.8223 - val_loss: 0.4655 - val_accuracy: 0.7917\n",
            "Epoch 739/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3475 - accuracy: 0.8359 - val_loss: 0.4650 - val_accuracy: 0.7917\n",
            "Epoch 740/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3670 - accuracy: 0.8533 - val_loss: 0.4646 - val_accuracy: 0.7917\n",
            "Epoch 741/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3569 - accuracy: 0.8573 - val_loss: 0.4646 - val_accuracy: 0.7917\n",
            "Epoch 742/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3362 - accuracy: 0.8457 - val_loss: 0.4643 - val_accuracy: 0.7917\n",
            "Epoch 743/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3428 - accuracy: 0.8524 - val_loss: 0.4637 - val_accuracy: 0.7917\n",
            "Epoch 744/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3436 - accuracy: 0.8529 - val_loss: 0.4635 - val_accuracy: 0.7917\n",
            "Epoch 745/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3415 - accuracy: 0.8414 - val_loss: 0.4630 - val_accuracy: 0.7917\n",
            "Epoch 746/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3035 - accuracy: 0.8827 - val_loss: 0.4622 - val_accuracy: 0.7917\n",
            "Epoch 747/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3483 - accuracy: 0.8562 - val_loss: 0.4619 - val_accuracy: 0.7917\n",
            "Epoch 748/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3806 - accuracy: 0.8394 - val_loss: 0.4619 - val_accuracy: 0.7917\n",
            "Epoch 749/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3635 - accuracy: 0.8344 - val_loss: 0.4622 - val_accuracy: 0.7917\n",
            "Epoch 750/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3257 - accuracy: 0.8367 - val_loss: 0.4619 - val_accuracy: 0.7917\n",
            "Epoch 751/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3219 - accuracy: 0.8537 - val_loss: 0.4616 - val_accuracy: 0.7917\n",
            "Epoch 752/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3455 - accuracy: 0.8342 - val_loss: 0.4614 - val_accuracy: 0.7917\n",
            "Epoch 753/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4033 - accuracy: 0.8196 - val_loss: 0.4617 - val_accuracy: 0.7917\n",
            "Epoch 754/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3455 - accuracy: 0.8606 - val_loss: 0.4618 - val_accuracy: 0.7917\n",
            "Epoch 755/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3565 - accuracy: 0.8414 - val_loss: 0.4615 - val_accuracy: 0.7917\n",
            "Epoch 756/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3588 - accuracy: 0.8338 - val_loss: 0.4611 - val_accuracy: 0.7917\n",
            "Epoch 757/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3892 - accuracy: 0.8035 - val_loss: 0.4610 - val_accuracy: 0.7917\n",
            "Epoch 758/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3503 - accuracy: 0.8312 - val_loss: 0.4605 - val_accuracy: 0.7917\n",
            "Epoch 759/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3162 - accuracy: 0.8780 - val_loss: 0.4603 - val_accuracy: 0.7917\n",
            "Epoch 760/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3467 - accuracy: 0.8362 - val_loss: 0.4599 - val_accuracy: 0.7917\n",
            "Epoch 761/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3469 - accuracy: 0.8586 - val_loss: 0.4599 - val_accuracy: 0.7917\n",
            "Epoch 762/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3124 - accuracy: 0.8762 - val_loss: 0.4598 - val_accuracy: 0.7917\n",
            "Epoch 763/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3759 - accuracy: 0.8412 - val_loss: 0.4594 - val_accuracy: 0.7917\n",
            "Epoch 764/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3678 - accuracy: 0.8385 - val_loss: 0.4594 - val_accuracy: 0.7917\n",
            "Epoch 765/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3458 - accuracy: 0.8563 - val_loss: 0.4593 - val_accuracy: 0.7917\n",
            "Epoch 766/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3502 - accuracy: 0.8395 - val_loss: 0.4589 - val_accuracy: 0.7917\n",
            "Epoch 767/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3920 - accuracy: 0.8044 - val_loss: 0.4589 - val_accuracy: 0.7917\n",
            "Epoch 768/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3303 - accuracy: 0.8784 - val_loss: 0.4583 - val_accuracy: 0.7917\n",
            "Epoch 769/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3469 - accuracy: 0.8469 - val_loss: 0.4581 - val_accuracy: 0.7917\n",
            "Epoch 770/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3296 - accuracy: 0.8749 - val_loss: 0.4577 - val_accuracy: 0.7917\n",
            "Epoch 771/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3835 - accuracy: 0.8175 - val_loss: 0.4577 - val_accuracy: 0.7917\n",
            "Epoch 772/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3347 - accuracy: 0.8498 - val_loss: 0.4578 - val_accuracy: 0.7917\n",
            "Epoch 773/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3261 - accuracy: 0.8605 - val_loss: 0.4573 - val_accuracy: 0.7917\n",
            "Epoch 774/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3429 - accuracy: 0.8471 - val_loss: 0.4570 - val_accuracy: 0.7917\n",
            "Epoch 775/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3427 - accuracy: 0.8475 - val_loss: 0.4572 - val_accuracy: 0.7917\n",
            "Epoch 776/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3208 - accuracy: 0.8798 - val_loss: 0.4568 - val_accuracy: 0.7917\n",
            "Epoch 777/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3674 - accuracy: 0.8359 - val_loss: 0.4566 - val_accuracy: 0.7917\n",
            "Epoch 778/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3524 - accuracy: 0.8326 - val_loss: 0.4566 - val_accuracy: 0.7917\n",
            "Epoch 779/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3540 - accuracy: 0.8403 - val_loss: 0.4564 - val_accuracy: 0.7917\n",
            "Epoch 780/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3451 - accuracy: 0.8539 - val_loss: 0.4560 - val_accuracy: 0.7917\n",
            "Epoch 781/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3210 - accuracy: 0.8667 - val_loss: 0.4557 - val_accuracy: 0.7917\n",
            "Epoch 782/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3466 - accuracy: 0.8312 - val_loss: 0.4558 - val_accuracy: 0.7917\n",
            "Epoch 783/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3774 - accuracy: 0.8153 - val_loss: 0.4557 - val_accuracy: 0.7917\n",
            "Epoch 784/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3299 - accuracy: 0.8624 - val_loss: 0.4555 - val_accuracy: 0.7917\n",
            "Epoch 785/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3711 - accuracy: 0.8520 - val_loss: 0.4553 - val_accuracy: 0.7917\n",
            "Epoch 786/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3720 - accuracy: 0.8339 - val_loss: 0.4557 - val_accuracy: 0.7917\n",
            "Epoch 787/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3179 - accuracy: 0.8540 - val_loss: 0.4553 - val_accuracy: 0.7917\n",
            "Epoch 788/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3438 - accuracy: 0.8441 - val_loss: 0.4554 - val_accuracy: 0.7917\n",
            "Epoch 789/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3631 - accuracy: 0.8548 - val_loss: 0.4553 - val_accuracy: 0.7917\n",
            "Epoch 790/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3528 - accuracy: 0.8466 - val_loss: 0.4553 - val_accuracy: 0.7917\n",
            "Epoch 791/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3729 - accuracy: 0.8371 - val_loss: 0.4552 - val_accuracy: 0.7917\n",
            "Epoch 792/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3833 - accuracy: 0.8229 - val_loss: 0.4555 - val_accuracy: 0.7917\n",
            "Epoch 793/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3519 - accuracy: 0.8557 - val_loss: 0.4555 - val_accuracy: 0.7917\n",
            "Epoch 794/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3772 - accuracy: 0.8414 - val_loss: 0.4551 - val_accuracy: 0.7917\n",
            "Epoch 795/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3697 - accuracy: 0.8314 - val_loss: 0.4552 - val_accuracy: 0.7917\n",
            "Epoch 796/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3496 - accuracy: 0.8465 - val_loss: 0.4550 - val_accuracy: 0.7917\n",
            "Epoch 797/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3754 - accuracy: 0.8376 - val_loss: 0.4550 - val_accuracy: 0.7917\n",
            "Epoch 798/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3578 - accuracy: 0.8352 - val_loss: 0.4550 - val_accuracy: 0.7917\n",
            "Epoch 799/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3777 - accuracy: 0.8343 - val_loss: 0.4547 - val_accuracy: 0.7917\n",
            "Epoch 800/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3146 - accuracy: 0.8725 - val_loss: 0.4544 - val_accuracy: 0.7917\n",
            "Epoch 801/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3527 - accuracy: 0.8467 - val_loss: 0.4547 - val_accuracy: 0.7917\n",
            "Epoch 802/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3551 - accuracy: 0.8315 - val_loss: 0.4548 - val_accuracy: 0.7917\n",
            "Epoch 803/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3706 - accuracy: 0.8461 - val_loss: 0.4546 - val_accuracy: 0.7917\n",
            "Epoch 804/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3491 - accuracy: 0.8475 - val_loss: 0.4546 - val_accuracy: 0.7917\n",
            "Epoch 805/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3423 - accuracy: 0.8418 - val_loss: 0.4545 - val_accuracy: 0.7917\n",
            "Epoch 806/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3691 - accuracy: 0.8344 - val_loss: 0.4546 - val_accuracy: 0.7917\n",
            "Epoch 807/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3058 - accuracy: 0.8601 - val_loss: 0.4541 - val_accuracy: 0.7917\n",
            "Epoch 808/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3446 - accuracy: 0.8571 - val_loss: 0.4537 - val_accuracy: 0.7917\n",
            "Epoch 809/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3742 - accuracy: 0.8246 - val_loss: 0.4536 - val_accuracy: 0.7917\n",
            "Epoch 810/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3665 - accuracy: 0.8225 - val_loss: 0.4537 - val_accuracy: 0.7917\n",
            "Epoch 811/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3385 - accuracy: 0.8568 - val_loss: 0.4535 - val_accuracy: 0.7917\n",
            "Epoch 812/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3095 - accuracy: 0.8596 - val_loss: 0.4533 - val_accuracy: 0.7917\n",
            "Epoch 813/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3326 - accuracy: 0.8501 - val_loss: 0.4537 - val_accuracy: 0.7917\n",
            "Epoch 814/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3295 - accuracy: 0.8571 - val_loss: 0.4534 - val_accuracy: 0.7917\n",
            "Epoch 815/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3359 - accuracy: 0.8575 - val_loss: 0.4532 - val_accuracy: 0.7917\n",
            "Epoch 816/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3449 - accuracy: 0.8374 - val_loss: 0.4532 - val_accuracy: 0.7917\n",
            "Epoch 817/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3546 - accuracy: 0.8558 - val_loss: 0.4534 - val_accuracy: 0.7917\n",
            "Epoch 818/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3460 - accuracy: 0.8563 - val_loss: 0.4529 - val_accuracy: 0.7917\n",
            "Epoch 819/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3010 - accuracy: 0.8936 - val_loss: 0.4524 - val_accuracy: 0.7917\n",
            "Epoch 820/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3351 - accuracy: 0.8593 - val_loss: 0.4526 - val_accuracy: 0.7917\n",
            "Epoch 821/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3435 - accuracy: 0.8592 - val_loss: 0.4523 - val_accuracy: 0.7917\n",
            "Epoch 822/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3092 - accuracy: 0.8568 - val_loss: 0.4524 - val_accuracy: 0.7917\n",
            "Epoch 823/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3455 - accuracy: 0.8529 - val_loss: 0.4526 - val_accuracy: 0.7917\n",
            "Epoch 824/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3339 - accuracy: 0.8558 - val_loss: 0.4525 - val_accuracy: 0.7917\n",
            "Epoch 825/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3435 - accuracy: 0.8645 - val_loss: 0.4524 - val_accuracy: 0.7917\n",
            "Epoch 826/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3218 - accuracy: 0.8769 - val_loss: 0.4523 - val_accuracy: 0.7917\n",
            "Epoch 827/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3511 - accuracy: 0.8385 - val_loss: 0.4523 - val_accuracy: 0.7917\n",
            "Epoch 828/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3729 - accuracy: 0.8432 - val_loss: 0.4518 - val_accuracy: 0.7917\n",
            "Epoch 829/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3521 - accuracy: 0.8512 - val_loss: 0.4514 - val_accuracy: 0.7917\n",
            "Epoch 830/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3312 - accuracy: 0.8587 - val_loss: 0.4513 - val_accuracy: 0.7917\n",
            "Epoch 831/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3311 - accuracy: 0.8675 - val_loss: 0.4511 - val_accuracy: 0.7917\n",
            "Epoch 832/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3340 - accuracy: 0.8556 - val_loss: 0.4509 - val_accuracy: 0.7917\n",
            "Epoch 833/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3170 - accuracy: 0.8601 - val_loss: 0.4502 - val_accuracy: 0.7917\n",
            "Epoch 834/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3555 - accuracy: 0.8313 - val_loss: 0.4506 - val_accuracy: 0.7917\n",
            "Epoch 835/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3755 - accuracy: 0.8399 - val_loss: 0.4506 - val_accuracy: 0.7917\n",
            "Epoch 836/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3221 - accuracy: 0.8639 - val_loss: 0.4506 - val_accuracy: 0.7917\n",
            "Epoch 837/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3612 - accuracy: 0.8352 - val_loss: 0.4507 - val_accuracy: 0.7917\n",
            "Epoch 838/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3700 - accuracy: 0.8212 - val_loss: 0.4506 - val_accuracy: 0.7917\n",
            "Epoch 839/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3530 - accuracy: 0.8324 - val_loss: 0.4505 - val_accuracy: 0.7917\n",
            "Epoch 840/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3485 - accuracy: 0.8490 - val_loss: 0.4501 - val_accuracy: 0.7917\n",
            "Epoch 841/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3568 - accuracy: 0.8248 - val_loss: 0.4503 - val_accuracy: 0.7917\n",
            "Epoch 842/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3183 - accuracy: 0.8615 - val_loss: 0.4498 - val_accuracy: 0.7917\n",
            "Epoch 843/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3147 - accuracy: 0.8600 - val_loss: 0.4500 - val_accuracy: 0.7917\n",
            "Epoch 844/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3642 - accuracy: 0.8233 - val_loss: 0.4503 - val_accuracy: 0.7917\n",
            "Epoch 845/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3180 - accuracy: 0.8586 - val_loss: 0.4504 - val_accuracy: 0.7917\n",
            "Epoch 846/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3356 - accuracy: 0.8489 - val_loss: 0.4498 - val_accuracy: 0.7917\n",
            "Epoch 847/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3618 - accuracy: 0.8281 - val_loss: 0.4502 - val_accuracy: 0.7917\n",
            "Epoch 848/1000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3493 - accuracy: 0.8225 - val_loss: 0.4501 - val_accuracy: 0.7917\n",
            "Epoch 849/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3485 - accuracy: 0.8536 - val_loss: 0.4500 - val_accuracy: 0.7917\n",
            "Epoch 850/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3399 - accuracy: 0.8360 - val_loss: 0.4500 - val_accuracy: 0.7917\n",
            "Epoch 851/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3337 - accuracy: 0.8470 - val_loss: 0.4502 - val_accuracy: 0.7917\n",
            "Epoch 852/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3718 - accuracy: 0.8119 - val_loss: 0.4502 - val_accuracy: 0.7917\n",
            "Epoch 853/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3443 - accuracy: 0.8339 - val_loss: 0.4501 - val_accuracy: 0.7917\n",
            "Epoch 854/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3383 - accuracy: 0.8429 - val_loss: 0.4502 - val_accuracy: 0.7917\n",
            "Epoch 855/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3611 - accuracy: 0.8319 - val_loss: 0.4501 - val_accuracy: 0.7917\n",
            "Epoch 856/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3950 - accuracy: 0.8089 - val_loss: 0.4505 - val_accuracy: 0.7917\n",
            "Epoch 857/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3219 - accuracy: 0.8656 - val_loss: 0.4501 - val_accuracy: 0.7917\n",
            "Epoch 858/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3244 - accuracy: 0.8548 - val_loss: 0.4497 - val_accuracy: 0.7917\n",
            "Epoch 859/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3626 - accuracy: 0.8254 - val_loss: 0.4497 - val_accuracy: 0.7917\n",
            "Epoch 860/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3329 - accuracy: 0.8472 - val_loss: 0.4491 - val_accuracy: 0.7917\n",
            "Epoch 861/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3252 - accuracy: 0.8630 - val_loss: 0.4489 - val_accuracy: 0.7917\n",
            "Epoch 862/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3648 - accuracy: 0.8451 - val_loss: 0.4493 - val_accuracy: 0.7917\n",
            "Epoch 863/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3041 - accuracy: 0.8688 - val_loss: 0.4487 - val_accuracy: 0.7917\n",
            "Epoch 864/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3412 - accuracy: 0.8533 - val_loss: 0.4488 - val_accuracy: 0.7917\n",
            "Epoch 865/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3612 - accuracy: 0.8496 - val_loss: 0.4489 - val_accuracy: 0.7917\n",
            "Epoch 866/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3389 - accuracy: 0.8498 - val_loss: 0.4491 - val_accuracy: 0.7917\n",
            "Epoch 867/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3367 - accuracy: 0.8687 - val_loss: 0.4491 - val_accuracy: 0.7917\n",
            "Epoch 868/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3066 - accuracy: 0.8746 - val_loss: 0.4491 - val_accuracy: 0.7917\n",
            "Epoch 869/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3557 - accuracy: 0.8560 - val_loss: 0.4492 - val_accuracy: 0.7917\n",
            "Epoch 870/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3138 - accuracy: 0.8610 - val_loss: 0.4493 - val_accuracy: 0.7917\n",
            "Epoch 871/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3396 - accuracy: 0.8737 - val_loss: 0.4489 - val_accuracy: 0.7917\n",
            "Epoch 872/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3347 - accuracy: 0.8644 - val_loss: 0.4487 - val_accuracy: 0.8125\n",
            "Epoch 873/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3076 - accuracy: 0.8475 - val_loss: 0.4480 - val_accuracy: 0.8125\n",
            "Epoch 874/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3496 - accuracy: 0.8513 - val_loss: 0.4482 - val_accuracy: 0.8125\n",
            "Epoch 875/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3749 - accuracy: 0.8342 - val_loss: 0.4482 - val_accuracy: 0.8125\n",
            "Epoch 876/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3587 - accuracy: 0.8234 - val_loss: 0.4484 - val_accuracy: 0.8125\n",
            "Epoch 877/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3634 - accuracy: 0.8353 - val_loss: 0.4484 - val_accuracy: 0.8125\n",
            "Epoch 878/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3498 - accuracy: 0.8429 - val_loss: 0.4483 - val_accuracy: 0.8125\n",
            "Epoch 879/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3103 - accuracy: 0.8780 - val_loss: 0.4484 - val_accuracy: 0.8125\n",
            "Epoch 880/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3487 - accuracy: 0.8329 - val_loss: 0.4486 - val_accuracy: 0.8125\n",
            "Epoch 881/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3302 - accuracy: 0.8530 - val_loss: 0.4482 - val_accuracy: 0.8125\n",
            "Epoch 882/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3528 - accuracy: 0.8431 - val_loss: 0.4481 - val_accuracy: 0.8125\n",
            "Epoch 883/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2984 - accuracy: 0.8668 - val_loss: 0.4480 - val_accuracy: 0.8125\n",
            "Epoch 884/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3280 - accuracy: 0.8491 - val_loss: 0.4478 - val_accuracy: 0.8125\n",
            "Epoch 885/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3805 - accuracy: 0.8291 - val_loss: 0.4480 - val_accuracy: 0.8125\n",
            "Epoch 886/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3360 - accuracy: 0.8456 - val_loss: 0.4480 - val_accuracy: 0.8125\n",
            "Epoch 887/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3133 - accuracy: 0.8676 - val_loss: 0.4479 - val_accuracy: 0.8125\n",
            "Epoch 888/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3532 - accuracy: 0.8583 - val_loss: 0.4479 - val_accuracy: 0.8125\n",
            "Epoch 889/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3505 - accuracy: 0.8371 - val_loss: 0.4483 - val_accuracy: 0.8125\n",
            "Epoch 890/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3705 - accuracy: 0.8294 - val_loss: 0.4485 - val_accuracy: 0.8125\n",
            "Epoch 891/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3538 - accuracy: 0.8583 - val_loss: 0.4484 - val_accuracy: 0.8125\n",
            "Epoch 892/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3118 - accuracy: 0.8727 - val_loss: 0.4476 - val_accuracy: 0.8125\n",
            "Epoch 893/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3498 - accuracy: 0.8395 - val_loss: 0.4482 - val_accuracy: 0.8125\n",
            "Epoch 894/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3193 - accuracy: 0.8545 - val_loss: 0.4481 - val_accuracy: 0.8125\n",
            "Epoch 895/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3574 - accuracy: 0.8349 - val_loss: 0.4484 - val_accuracy: 0.8125\n",
            "Epoch 896/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3526 - accuracy: 0.8428 - val_loss: 0.4482 - val_accuracy: 0.8125\n",
            "Epoch 897/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3468 - accuracy: 0.8444 - val_loss: 0.4482 - val_accuracy: 0.8125\n",
            "Epoch 898/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3612 - accuracy: 0.8341 - val_loss: 0.4484 - val_accuracy: 0.8125\n",
            "Epoch 899/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3433 - accuracy: 0.8339 - val_loss: 0.4480 - val_accuracy: 0.8125\n",
            "Epoch 900/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3413 - accuracy: 0.8500 - val_loss: 0.4480 - val_accuracy: 0.8125\n",
            "Epoch 901/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3371 - accuracy: 0.8615 - val_loss: 0.4477 - val_accuracy: 0.8125\n",
            "Epoch 902/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3028 - accuracy: 0.8701 - val_loss: 0.4478 - val_accuracy: 0.8125\n",
            "Epoch 903/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3590 - accuracy: 0.8359 - val_loss: 0.4481 - val_accuracy: 0.8125\n",
            "Epoch 904/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3629 - accuracy: 0.8288 - val_loss: 0.4479 - val_accuracy: 0.8125\n",
            "Epoch 905/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3285 - accuracy: 0.8560 - val_loss: 0.4477 - val_accuracy: 0.8125\n",
            "Epoch 906/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3276 - accuracy: 0.8557 - val_loss: 0.4476 - val_accuracy: 0.8125\n",
            "Epoch 907/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3533 - accuracy: 0.8390 - val_loss: 0.4475 - val_accuracy: 0.8125\n",
            "Epoch 908/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3293 - accuracy: 0.8565 - val_loss: 0.4478 - val_accuracy: 0.8125\n",
            "Epoch 909/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3190 - accuracy: 0.8824 - val_loss: 0.4470 - val_accuracy: 0.8125\n",
            "Epoch 910/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3182 - accuracy: 0.8528 - val_loss: 0.4467 - val_accuracy: 0.8125\n",
            "Epoch 911/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3102 - accuracy: 0.8649 - val_loss: 0.4468 - val_accuracy: 0.8125\n",
            "Epoch 912/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3695 - accuracy: 0.8427 - val_loss: 0.4473 - val_accuracy: 0.8125\n",
            "Epoch 913/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3705 - accuracy: 0.8222 - val_loss: 0.4473 - val_accuracy: 0.8125\n",
            "Epoch 914/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3276 - accuracy: 0.8736 - val_loss: 0.4471 - val_accuracy: 0.8125\n",
            "Epoch 915/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3287 - accuracy: 0.8754 - val_loss: 0.4470 - val_accuracy: 0.8125\n",
            "Epoch 916/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3422 - accuracy: 0.8346 - val_loss: 0.4465 - val_accuracy: 0.8125\n",
            "Epoch 917/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3323 - accuracy: 0.8430 - val_loss: 0.4463 - val_accuracy: 0.8125\n",
            "Epoch 918/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3632 - accuracy: 0.8232 - val_loss: 0.4461 - val_accuracy: 0.8125\n",
            "Epoch 919/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3733 - accuracy: 0.8351 - val_loss: 0.4459 - val_accuracy: 0.8125\n",
            "Epoch 920/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3244 - accuracy: 0.8577 - val_loss: 0.4459 - val_accuracy: 0.8125\n",
            "Epoch 921/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3406 - accuracy: 0.8336 - val_loss: 0.4457 - val_accuracy: 0.8125\n",
            "Epoch 922/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3302 - accuracy: 0.8504 - val_loss: 0.4457 - val_accuracy: 0.8125\n",
            "Epoch 923/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3084 - accuracy: 0.8844 - val_loss: 0.4458 - val_accuracy: 0.8125\n",
            "Epoch 924/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3435 - accuracy: 0.8448 - val_loss: 0.4459 - val_accuracy: 0.8125\n",
            "Epoch 925/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3101 - accuracy: 0.8622 - val_loss: 0.4458 - val_accuracy: 0.8125\n",
            "Epoch 926/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3421 - accuracy: 0.8617 - val_loss: 0.4455 - val_accuracy: 0.8125\n",
            "Epoch 927/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3765 - accuracy: 0.8335 - val_loss: 0.4457 - val_accuracy: 0.8125\n",
            "Epoch 928/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3206 - accuracy: 0.8719 - val_loss: 0.4457 - val_accuracy: 0.8125\n",
            "Epoch 929/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3506 - accuracy: 0.8578 - val_loss: 0.4461 - val_accuracy: 0.8125\n",
            "Epoch 930/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3181 - accuracy: 0.8598 - val_loss: 0.4460 - val_accuracy: 0.8125\n",
            "Epoch 931/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3616 - accuracy: 0.8383 - val_loss: 0.4460 - val_accuracy: 0.8125\n",
            "Epoch 932/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2996 - accuracy: 0.8944 - val_loss: 0.4453 - val_accuracy: 0.8125\n",
            "Epoch 933/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3711 - accuracy: 0.8457 - val_loss: 0.4454 - val_accuracy: 0.8125\n",
            "Epoch 934/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4033 - accuracy: 0.8434 - val_loss: 0.4455 - val_accuracy: 0.8125\n",
            "Epoch 935/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3441 - accuracy: 0.8492 - val_loss: 0.4456 - val_accuracy: 0.8125\n",
            "Epoch 936/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3409 - accuracy: 0.8711 - val_loss: 0.4459 - val_accuracy: 0.8125\n",
            "Epoch 937/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3256 - accuracy: 0.8686 - val_loss: 0.4460 - val_accuracy: 0.8125\n",
            "Epoch 938/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2912 - accuracy: 0.8996 - val_loss: 0.4457 - val_accuracy: 0.8125\n",
            "Epoch 939/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4098 - accuracy: 0.8344 - val_loss: 0.4457 - val_accuracy: 0.8125\n",
            "Epoch 940/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3469 - accuracy: 0.8450 - val_loss: 0.4460 - val_accuracy: 0.8125\n",
            "Epoch 941/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3744 - accuracy: 0.8455 - val_loss: 0.4456 - val_accuracy: 0.8125\n",
            "Epoch 942/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3972 - accuracy: 0.8153 - val_loss: 0.4457 - val_accuracy: 0.8125\n",
            "Epoch 943/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3342 - accuracy: 0.8610 - val_loss: 0.4456 - val_accuracy: 0.8125\n",
            "Epoch 944/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3625 - accuracy: 0.8368 - val_loss: 0.4454 - val_accuracy: 0.8125\n",
            "Epoch 945/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3697 - accuracy: 0.8362 - val_loss: 0.4448 - val_accuracy: 0.8125\n",
            "Epoch 946/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3543 - accuracy: 0.8613 - val_loss: 0.4448 - val_accuracy: 0.8125\n",
            "Epoch 947/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3391 - accuracy: 0.8450 - val_loss: 0.4448 - val_accuracy: 0.8125\n",
            "Epoch 948/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4016 - accuracy: 0.8175 - val_loss: 0.4452 - val_accuracy: 0.8125\n",
            "Epoch 949/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3449 - accuracy: 0.8561 - val_loss: 0.4450 - val_accuracy: 0.8125\n",
            "Epoch 950/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3750 - accuracy: 0.8376 - val_loss: 0.4450 - val_accuracy: 0.8125\n",
            "Epoch 951/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3500 - accuracy: 0.8646 - val_loss: 0.4452 - val_accuracy: 0.8125\n",
            "Epoch 952/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3880 - accuracy: 0.8191 - val_loss: 0.4455 - val_accuracy: 0.8125\n",
            "Epoch 953/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3434 - accuracy: 0.8441 - val_loss: 0.4452 - val_accuracy: 0.8125\n",
            "Epoch 954/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3324 - accuracy: 0.8824 - val_loss: 0.4448 - val_accuracy: 0.8125\n",
            "Epoch 955/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3392 - accuracy: 0.8564 - val_loss: 0.4446 - val_accuracy: 0.8125\n",
            "Epoch 956/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3394 - accuracy: 0.8396 - val_loss: 0.4449 - val_accuracy: 0.8125\n",
            "Epoch 957/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3274 - accuracy: 0.8606 - val_loss: 0.4447 - val_accuracy: 0.8125\n",
            "Epoch 958/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3631 - accuracy: 0.8601 - val_loss: 0.4444 - val_accuracy: 0.8125\n",
            "Epoch 959/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3237 - accuracy: 0.8646 - val_loss: 0.4443 - val_accuracy: 0.8125\n",
            "Epoch 960/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3298 - accuracy: 0.8520 - val_loss: 0.4443 - val_accuracy: 0.8125\n",
            "Epoch 961/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2834 - accuracy: 0.9007 - val_loss: 0.4438 - val_accuracy: 0.8125\n",
            "Epoch 962/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2892 - accuracy: 0.8889 - val_loss: 0.4436 - val_accuracy: 0.8125\n",
            "Epoch 963/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3200 - accuracy: 0.8604 - val_loss: 0.4438 - val_accuracy: 0.8125\n",
            "Epoch 964/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3164 - accuracy: 0.8655 - val_loss: 0.4435 - val_accuracy: 0.8125\n",
            "Epoch 965/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3400 - accuracy: 0.8607 - val_loss: 0.4435 - val_accuracy: 0.8125\n",
            "Epoch 966/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3441 - accuracy: 0.8582 - val_loss: 0.4436 - val_accuracy: 0.8125\n",
            "Epoch 967/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3454 - accuracy: 0.8530 - val_loss: 0.4437 - val_accuracy: 0.8125\n",
            "Epoch 968/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3476 - accuracy: 0.8528 - val_loss: 0.4439 - val_accuracy: 0.8125\n",
            "Epoch 969/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3427 - accuracy: 0.8650 - val_loss: 0.4439 - val_accuracy: 0.8125\n",
            "Epoch 970/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3408 - accuracy: 0.8522 - val_loss: 0.4435 - val_accuracy: 0.8125\n",
            "Epoch 971/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3403 - accuracy: 0.8522 - val_loss: 0.4437 - val_accuracy: 0.8125\n",
            "Epoch 972/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3379 - accuracy: 0.8685 - val_loss: 0.4437 - val_accuracy: 0.8125\n",
            "Epoch 973/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3406 - accuracy: 0.8355 - val_loss: 0.4432 - val_accuracy: 0.8125\n",
            "Epoch 974/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3248 - accuracy: 0.8634 - val_loss: 0.4433 - val_accuracy: 0.8125\n",
            "Epoch 975/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3566 - accuracy: 0.8472 - val_loss: 0.4431 - val_accuracy: 0.8125\n",
            "Epoch 976/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3448 - accuracy: 0.8680 - val_loss: 0.4433 - val_accuracy: 0.8125\n",
            "Epoch 977/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3217 - accuracy: 0.8702 - val_loss: 0.4432 - val_accuracy: 0.8125\n",
            "Epoch 978/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3517 - accuracy: 0.8383 - val_loss: 0.4434 - val_accuracy: 0.8125\n",
            "Epoch 979/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3539 - accuracy: 0.8394 - val_loss: 0.4428 - val_accuracy: 0.8125\n",
            "Epoch 980/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3292 - accuracy: 0.8621 - val_loss: 0.4432 - val_accuracy: 0.8125\n",
            "Epoch 981/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3554 - accuracy: 0.8298 - val_loss: 0.4430 - val_accuracy: 0.8125\n",
            "Epoch 982/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3382 - accuracy: 0.8604 - val_loss: 0.4431 - val_accuracy: 0.8125\n",
            "Epoch 983/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3674 - accuracy: 0.8414 - val_loss: 0.4434 - val_accuracy: 0.8333\n",
            "Epoch 984/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3361 - accuracy: 0.8571 - val_loss: 0.4427 - val_accuracy: 0.8125\n",
            "Epoch 985/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3023 - accuracy: 0.8820 - val_loss: 0.4426 - val_accuracy: 0.8125\n",
            "Epoch 986/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3219 - accuracy: 0.8704 - val_loss: 0.4428 - val_accuracy: 0.8333\n",
            "Epoch 987/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3790 - accuracy: 0.8130 - val_loss: 0.4432 - val_accuracy: 0.8333\n",
            "Epoch 988/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3366 - accuracy: 0.8670 - val_loss: 0.4432 - val_accuracy: 0.8333\n",
            "Epoch 989/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3376 - accuracy: 0.8650 - val_loss: 0.4425 - val_accuracy: 0.8333\n",
            "Epoch 990/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3511 - accuracy: 0.8360 - val_loss: 0.4428 - val_accuracy: 0.8333\n",
            "Epoch 991/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3051 - accuracy: 0.8856 - val_loss: 0.4422 - val_accuracy: 0.8125\n",
            "Epoch 992/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3600 - accuracy: 0.8446 - val_loss: 0.4421 - val_accuracy: 0.8125\n",
            "Epoch 993/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3167 - accuracy: 0.8837 - val_loss: 0.4424 - val_accuracy: 0.8333\n",
            "Epoch 994/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3254 - accuracy: 0.8512 - val_loss: 0.4420 - val_accuracy: 0.8333\n",
            "Epoch 995/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3235 - accuracy: 0.8681 - val_loss: 0.4424 - val_accuracy: 0.8333\n",
            "Epoch 996/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3535 - accuracy: 0.8473 - val_loss: 0.4425 - val_accuracy: 0.8333\n",
            "Epoch 997/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3306 - accuracy: 0.8493 - val_loss: 0.4422 - val_accuracy: 0.8333\n",
            "Epoch 998/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3114 - accuracy: 0.8731 - val_loss: 0.4420 - val_accuracy: 0.8333\n",
            "Epoch 999/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3082 - accuracy: 0.8649 - val_loss: 0.4419 - val_accuracy: 0.8333\n",
            "Epoch 1000/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3250 - accuracy: 0.8617 - val_loss: 0.4417 - val_accuracy: 0.8333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UKXL4C2q6qTc",
        "outputId": "f170422f-78ba-4b5b-8dae-be5d7115805d"
      },
      "source": [
        "# visualize the training loss and the validation loss to see if the model is overfitting\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'])\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "SByeGMLi6zaT",
        "outputId": "4d733f80-9123-4df9-b9cd-48be921e709b"
      },
      "source": [
        "# visualize the training accuracy and the validation accuracy to see if the model is overfitting\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'])\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88Rox6q-64dw",
        "outputId": "0ec3d628-f212-4d42-e7aa-d367c7e10836"
      },
      "source": [
        "# make a prediction and print the actual values\n",
        "prediction = model.predict(X_test)\n",
        "prediction = [1 if y >= 0.5 else 0 for y in prediction]\n",
        "print(prediction)\n",
        "print(y_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
            "[1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmEAa1fo7AUZ",
        "outputId": "9290efd7-7343-4e59-ee8b-c2d4934d3f1c"
      },
      "source": [
        "# evaluate the model on the training data\n",
        "from sklearn.metrics import  classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "pred = model.predict(X_train)\n",
        "pred = [1 if y >= 0.5 else 0 for y in pred]\n",
        "print(classification_report(y_train, pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_train, pred))\n",
        "print()\n",
        "print('Accuracy: ', accuracy_score(y_train, pred))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.93      0.89       161\n",
            "         1.0       0.83      0.68      0.75        78\n",
            "\n",
            "    accuracy                           0.85       239\n",
            "   macro avg       0.84      0.81      0.82       239\n",
            "weighted avg       0.85      0.85      0.85       239\n",
            "\n",
            "Confusion Matrix: \n",
            " [[150  11]\n",
            " [ 25  53]]\n",
            "\n",
            "Accuracy:  0.8493723849372385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpTtBkY_gj7v"
      },
      "source": [
        "After 1000 epochs the neural network will be trained. We can see that the training accuracy is reached 84.9%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEygXn4e7GEu",
        "outputId": "a787e1f2-d61b-4d50-99ad-78dcd6c8247e"
      },
      "source": [
        "# evaluate the model on the test data\n",
        "from sklearn.metrics import  classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "pred = [1 if y >= 0.5 else 0 for y in pred]\n",
        "print(classification_report(y_test, pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, pred))\n",
        "print()\n",
        "print('Accuracy: ', accuracy_score(y_test, pred))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.93      0.91        42\n",
            "         1.0       0.81      0.72      0.76        18\n",
            "\n",
            "    accuracy                           0.87        60\n",
            "   macro avg       0.85      0.83      0.84        60\n",
            "weighted avg       0.86      0.87      0.86        60\n",
            "\n",
            "Confusion Matrix: \n",
            " [[39  3]\n",
            " [ 5 13]]\n",
            "\n",
            "Accuracy:  0.8666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmhogdcouJCG"
      },
      "source": [
        "The model's performance looks good, and the accuracy has been increased to 86.7%, but for anything dealing with people in their lives and medical issues, we really want to the score to be much higher than this report. So may be we can  drop out some columns and/ or add some columns and/ or only keep importmant features in our model to possbily make it better."
      ]
    }
  ]
}